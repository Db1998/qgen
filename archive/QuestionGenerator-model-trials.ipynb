{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!export LC_ALL=en_US.UTF-8\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "from embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "try:\n",
    "    import nltk\n",
    "except:\n",
    "    !pip install nltk\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../train-v1.1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ra2630/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ra2630/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltkStopWords = stopwords.words('english')\n",
    "punctuations = [',', '?', '.', '-',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(data):\n",
    "    contexts = []\n",
    "    qas = []\n",
    "    for i in range(len(data[\"data\"])):\n",
    "        for j in range(len(data[\"data\"][i][\"paragraphs\"])):\n",
    "            contexts.append(data[\"data\"][i][\"paragraphs\"][j][\"context\"])\n",
    "            qas.append(data[\"data\"][i][\"paragraphs\"][j][\"qas\"])\n",
    "    return (contexts,qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapPassage = True\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "contexts,qas = extractor(data)\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            return ind,ind+sll\n",
    "    return (-1,-1)\n",
    "\n",
    "def capPassage(passage,left, right,cap_length = 20):\n",
    "    y = np.zeros(cap_length)\n",
    "    left = max(0,left - int((cap_length - len(answer))/2))\n",
    "    right = min(right + int((cap_length + len(answer))/2), cap_length)\n",
    "    if(left < 0):\n",
    "        left = 0\n",
    "    if(right > len(passage)):\n",
    "        right = len(passage)\n",
    "    return passage[left:right]\n",
    "    \n",
    "def findAnsVec(answer,passage):\n",
    "    ans = np.zeros((len(passage)))\n",
    "    start,end = find_sub_list(answer,passage)\n",
    "    if(start==-1):\n",
    "        start = passage.index(answer[0])\n",
    "        end = start + len(answer)\n",
    "    ans[start:end] = 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429\n"
     ]
    }
   ],
   "source": [
    "n_words = 10\n",
    "X_train_comp_all = []\n",
    "X_train_comp_with_answer_marked_all = []\n",
    "X_train_ans_all = []\n",
    "X_train_comp_answer_label_all = []\n",
    "X_train_sentence_label_all = []\n",
    "Y_train_ques_all = []\n",
    "invalid = 0\n",
    "for i,context in enumerate(contexts):\n",
    "    passage = word_tokenize(context.lower())\n",
    "\n",
    "    for j,_ in enumerate(qas[i]):\n",
    "        try:\n",
    "            question = word_tokenize(qas[i][j]['question'].lower())\n",
    "            answer = word_tokenize(qas[i][j][\"answers\"][0]['text'].lower())\n",
    "            start,end = find_sub_list(answer,passage)\n",
    "            if start == -1:\n",
    "                invalid = invalid+1\n",
    "                continue\n",
    "            marked_comp = np.zeros(len(passage))\n",
    "            marked_comp[start:end] = 1\n",
    "            left = max(0,start - n_words)\n",
    "            right = min(len(passage), end + n_words)\n",
    "            \n",
    "            cappedPassage = passage[left:right]\n",
    "            marked_comp = marked_comp[left:right]\n",
    "            \n",
    "            \n",
    "            X_train_comp_all.append(cappedPassage)\n",
    "            X_train_comp_with_answer_marked_all.append(marked_comp)\n",
    "            X_train_ans_all.append(answer)\n",
    "            Y_train_ques_all.append(question)\n",
    "        except Exception as e:\n",
    "            invalid = invalid+1\n",
    "print(invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X_train_comp_all,X_train_ans_all, Y_train_ques_all,X_train_comp_with_answer_marked_all))\n",
    "np.random.shuffle(c)\n",
    "X_train_comp_all_shuffled,X_train_ans_all_shuffled, Y_train_ques_all_shuffled, X_train_comp_with_answer_marked_all_shuffled = zip(*c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comp_with_answer_marked_all_shuffled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "def findKMostFrequentWords(k):\n",
    "    ctr = Counter([item for sublist in X_train_comp_all_shuffled for item in sublist] + [item for sublist in Y_train_ques_all_shuffled for item in sublist])\n",
    "    sorted_ctr = sorted(ctr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return [item[0] for item in sorted_ctr[0:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToTake = 200000\n",
    "words = findKMostFrequentWords(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_word_to_idx_reduced = {}\n",
    "_idx_to_word_reduced = []\n",
    "\n",
    "\n",
    "def _add_word_reduced(word):\n",
    "    idx = len(_idx_to_word_reduced)\n",
    "    _word_to_idx_reduced[word] = idx\n",
    "    _idx_to_word_reduced.append(word)\n",
    "    return idx\n",
    "\n",
    "\n",
    "\n",
    "PAD_TOKEN = _add_word_reduced(PAD_WORD)\n",
    "START_TOKEN = _add_word_reduced(START_WORD)\n",
    "END_TOKEN = _add_word_reduced(END_WORD)\n",
    "UNKNOWN_TOKEN = _add_word_reduced(UNKNOWN_WORD)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dimensions = glove.shape[1]\n",
    "reduced_glove = []\n",
    "reduced_glove.append(np.zeros(dimensions))\n",
    "reduced_glove.append(-np.ones(dimensions))\n",
    "reduced_glove.append(np.ones(dimensions))\n",
    "\n",
    "for word in words:\n",
    "    l = look_up_word(word)\n",
    "    if(l != UNKNOWN_TOKEN):\n",
    "        idx = _add_word_reduced(word)\n",
    "        reduced_glove.append(glove[l])\n",
    "        if(len(reduced_glove) == wordToTake):\n",
    "            break\n",
    "        \n",
    "def look_up_word_reduced(word):\n",
    "    return _word_to_idx_reduced.get(word, UNKNOWN_TOKEN)\n",
    "\n",
    "\n",
    "def look_up_token_reduced(token):\n",
    "    return _idx_to_word_reduced[token]\n",
    "\n",
    "reduced_glove = np.array(reduced_glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_set_tokens = set([look_up_word_reduced(i) for i in set(stopwords.words('english'))]) - {UNKNOWN_TOKEN, START_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words_set_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda2.cims.nyu.edu\n",
      "Invalid =  2429\n",
      "Glove shape =  (78658, 300)\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "print(\"Invalid = \",invalid)\n",
    "print(\"Glove shape = \", reduced_glove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_take_train = 32\n",
    "\n",
    "X_train_comp = X_train_comp_all_shuffled[0:examples_to_take_train]\n",
    "X_train_ans = X_train_ans_all_shuffled[0:examples_to_take_train]\n",
    "Y_train_ques = Y_train_ques_all_shuffled[0:examples_to_take_train]\n",
    "X_train_comp_with_answer_marked = X_train_comp_with_answer_marked_all_shuffled[0:examples_to_take_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_len = len(max(X_train_comp,key=len))\n",
    "max_answer_len = len(max(X_train_ans,key=len))\n",
    "max_question_len = len(max(Y_train_ques,key=len)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = np.full((examples_to_take_train, max_document_len), PAD_TOKEN,dtype=np.int32)\n",
    "document_lengths = np.zeros(examples_to_take_train, dtype=np.int32)\n",
    "\n",
    "answer_labels = np.zeros((examples_to_take_train, max_document_len), dtype=np.int32)\n",
    "answer_lengths = np.zeros(examples_to_take_train, dtype=np.int32)\n",
    "\n",
    "question_input_tokens = np.full((examples_to_take_train, max_question_len), PAD_TOKEN, dtype=np.int32)\n",
    "question_output_tokens = np.full((examples_to_take_train, max_question_len), PAD_TOKEN, dtype=np.int32)\n",
    "question_lengths = np.zeros(examples_to_take_train, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(examples_to_take_train):\n",
    "    answer_labels[i, 0:len(X_train_comp_with_answer_marked[i])] = X_train_comp_with_answer_marked[i]\n",
    "    for j, word in enumerate(X_train_comp[i]):\n",
    "        document_tokens[i, j] = look_up_word_reduced(word)\n",
    "    document_lengths[i] = len(X_train_comp[i])\n",
    "\n",
    "    answer_lengths[i] = len(X_train_ans[i])\n",
    "    \n",
    "    question_input_words = ([START_WORD] + Y_train_ques[i])\n",
    "    question_output_words = (Y_train_ques[i] + [END_WORD])\n",
    "\n",
    "    for j, word in enumerate(question_input_words):\n",
    "            question_input_tokens[i, j] = look_up_word_reduced(word)\n",
    "    for j, word in enumerate(question_output_words):\n",
    "        question_output_tokens[i, j] = look_up_word_reduced(word)\n",
    "    question_lengths[i] = len(question_input_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_to_indices_glove(X,max_len):\n",
    "    \n",
    "    m = len(X)                                 \n",
    "    \n",
    "    X_indices = np.full([m,max_len],look_up_word_reduced(PAD_WORD))\n",
    "    \n",
    "    for i in range(m):\n",
    "        j = 0\n",
    "        for w in X[i]:\n",
    "            if(j>=max_len):\n",
    "                break;\n",
    "            \n",
    "            X_indices[i, j] = look_up_word_reduced(w)\n",
    "            j = j+1\n",
    "        if(j < max_len):\n",
    "            X_indices[i, j] = look_up_word_reduced(END_WORD)\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_valid_tokens_vocab(X, Y):\n",
    "    \n",
    "    m = len(X)                                 \n",
    "    \n",
    "    X_indices = np.full([m,reduced_glove.shape[0]],PAD_TOKEN)\n",
    "    lengths = np.zeros(m)\n",
    "    \n",
    "    for i in range(m):\n",
    "        #s = set(X[i]).union(common_words_set_tokens) - {UNKNOWN_TOKEN}\n",
    "        s = set(X[i]).union(set(Y[i])) - {UNKNOWN_TOKEN}\n",
    "        for w in s:\n",
    "            X_indices[i, w] = 1\n",
    "        lengths[i] = len(s)\n",
    "    return X_indices, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = context_to_indices_glove(X_train_comp, max_document_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens, valid_tokens_length = generate_valid_tokens_vocab(document_tokens, question_output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tokens_length[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def createBatch(inputs,batch_size,shuffle=False):\n",
    "    outputs = []\n",
    "    start = 0\n",
    "    while start < len(inputs[0]):\n",
    "        end = min(len(inputs[0]), start + batch_size)\n",
    "        output = {'document_tokens':[],\n",
    "                    'document_lengths':[],\n",
    "                    'answer_labels':[],\n",
    "                    'answer_lengths': [],\n",
    "                    'question_input_tokens':[],\n",
    "                    'question_output_tokens':[],\n",
    "                    'question_lengths':[],\n",
    "                    'valid_tokens': [],\n",
    "                    'valid_tokens_length': []}\n",
    "        \n",
    "        for index,inp in enumerate(inputs):\n",
    "            #maxD = max(inputs[1][start:start+batch_size])\n",
    "            maxD = max_document_len\n",
    "            maxA = max(inputs[3][start:start+batch_size])\n",
    "            maxQ = max_question_len\n",
    "            \n",
    "            if index == 0:\n",
    "                output['document_tokens'].append(inp[start:end,0:maxD])\n",
    "            elif index==1:\n",
    "                output['document_lengths'].append(inp[start:end])\n",
    "            elif index==2:\n",
    "                output['answer_labels'].append(inp[start:end,0:maxD])\n",
    "            elif index==3:\n",
    "                output['answer_lengths'].append(inp[start:end])\n",
    "            elif index==4:\n",
    "                output['question_input_tokens'].append(inp[start:end, 0:maxQ])\n",
    "            elif index==5:\n",
    "                output['question_output_tokens'].append(inp[start:end, 0:maxQ])\n",
    "            elif index==6:\n",
    "                output['question_lengths'].append(inp[start:end])\n",
    "            elif index==7:\n",
    "                output['valid_tokens'].append(inp[start:end, 0:reduced_glove.shape[0]])\n",
    "            elif index == 8:\n",
    "                output['valid_tokens_length'].append(inp[start:end])\n",
    "        \n",
    "        p = np.argsort(np.array(output[\"document_lengths\"]) * -1)\n",
    "        output[\"document_tokens\"] = np.array(output[\"document_tokens\"])[:,p]\n",
    "        output[\"document_lengths\"] = np.array(output[\"document_lengths\"])[:,p]\n",
    "        output[\"answer_labels\"] = np.array(output[\"answer_labels\"])[:,p]\n",
    "        output[\"answer_lengths\"] = np.array(output[\"answer_lengths\"])[:,p]\n",
    "        output[\"question_input_tokens\"] = np.array(output[\"question_input_tokens\"])[:,p]\n",
    "        output[\"question_output_tokens\"] = np.array(output[\"question_output_tokens\"])[:,p]\n",
    "        output[\"question_lengths\"] = np.array(output[\"question_lengths\"])[:,p]\n",
    "        output[\"valid_tokens\"] = np.array(output[\"valid_tokens\"]).reshape(batch_size, -1)[:,p]\n",
    "        output[\"valid_tokens_length\"] = np.array(output[\"valid_tokens_length\"])[:,p]\n",
    "        outputs.append(output)\n",
    "        start = start + batch_size\n",
    "            \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches =  4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "batch_input = createBatch([document_tokens,document_lengths,answer_labels,answer_lengths,question_input_tokens,question_output_tokens,question_lengths,valid_tokens, valid_tokens_length]\n",
    "                    ,batch_size)\n",
    "for b in batch_input:\n",
    "    for k, v in b.items():\n",
    "        b[k] = v.squeeze()\n",
    "number_of_batches = len(batch_input)\n",
    "print(\"Number of batches = \", number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomShuffleBatch(batch):\n",
    "    random.sample(range(1, 100), 3)\n",
    "    p = random.sample(range(0 ,batch['document_tokens'].shape[0]),batch['document_tokens'].shape[0]) \n",
    "    batch['document_tokens'] = batch['document_tokens'][p]\n",
    "    batch['document_lengths'] = batch['document_lengths'][p]\n",
    "    batch['answer_labels'] = batch['answer_labels'][p]\n",
    "    batch['answer_lengths'] = batch['answer_lengths'][p]\n",
    "    batch['question_input_tokens'] = batch['question_input_tokens'][p]\n",
    "    batch['question_output_tokens'] = batch['question_output_tokens'][p]\n",
    "    batch['question_lengths'] = batch['question_lengths'][p]\n",
    "    batch['valid_tokens'] = batch['valid_tokens'][p]\n",
    "    batch['valid_tokens_length'] = batch['valid_tokens_length'][p]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomShuffleBatch(batch_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 32, 26, 22, 21, 23, 21, 21], dtype=int32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input[0]['document_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 32, 26, 22, 21, 23, 21, 21], dtype=int32)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input[0]['document_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<END>'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up_token_reduced(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use_CUDA=True\n",
      "current_device=0\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "#USE_CUDA = False\n",
    "print('Use_CUDA={}'.format(USE_CUDA))\n",
    "if USE_CUDA:\n",
    "    # You can change device by `torch.cuda.set_device(device_id)`\n",
    "    print('current_device={}'.format(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchwise_sample(gen, num_samples, batch_size, comp, documentEncoder, embedder):\n",
    "    \"\"\"\n",
    "    Sample num_samples samples batch_size samples at a time from gen.\n",
    "    Does not require gpu since gen.sample() takes care of that.\n",
    "    \"\"\"\n",
    "\n",
    "    samples = []\n",
    "    start = 0\n",
    "    for i in range(int(math.ceil(num_samples/float(batch_size)))):\n",
    "        batch_comp = comp[start:min(start+batch_size, num_samples)]\n",
    "        samples.append(gen.sample(batch_comp.shape[0], batch_comp, documentEncoder, embedder).transpose(1,0))\n",
    "        start+=batch_size\n",
    "\n",
    "    return torch.cat(samples, START_TOKEN)[:num_samples].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_generator_batch(samples, start_letter=START_TOKEN, gpu=False):\n",
    "    \"\"\"\n",
    "    Takes samples (a batch) and returns\n",
    "    Inputs: samples, start_letter, cuda\n",
    "        - samples: batch_size x seq_len (Tensor with a sample in each row)\n",
    "    Returns: inp, target\n",
    "        - inp: batch_size x seq_len (same as target, but with start_letter prepended)\n",
    "        - target: batch_size x seq_len (Variable same as samples)\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, seq_len = samples.size()\n",
    "\n",
    "    inp = torch.zeros(batch_size, seq_len)\n",
    "    target = samples\n",
    "    inp[:, 0] = start_letter\n",
    "    inp[:, 1:] = target[:, :seq_len-1]\n",
    "\n",
    "    inp = Variable(inp).type(torch.LongTensor)\n",
    "    target = Variable(target).type(torch.LongTensor)\n",
    "\n",
    "    if gpu:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, output_size)\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(reduced_glove).float())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(DocumentEncoderRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first= True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, lens, hidden):\n",
    "        #x = nn.utils.rnn.pack_padded_sequence(input = x, lengths = lens , batch_first=True)\n",
    "        \n",
    "        _, hidden = self.gru(x, hidden)\n",
    "        hidden = hidden.view(1, hidden.shape[1], hidden.shape[2]*2*self.num_layers)\n",
    "        return hidden\n",
    "    \n",
    "    def initHidden(self, num_samples):\n",
    "        result = Variable(torch.zeros(2 * self.num_layers, num_samples, self.hidden_size)) #2 for BiDirectional\n",
    "        if USE_CUDA:\n",
    "            result = result.cuda()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, embeddings,  hidden_dim, vocab_size, max_seq_len, gpu=False):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = embeddings\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first= False)\n",
    "        self.gru2out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def init_hidden(self, comp, comp_lens, num_examples, documentEncoder, embedder):\n",
    "        comp = embedder(comp).float()\n",
    "        h = documentEncoder.forward(comp, comp_lens, documentEncoder.initHidden(num_examples))\n",
    "        #h = Variable(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "        if self.gpu:\n",
    "            h = h.cuda()\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def forward(self, inp, hidden, doc_enc_hidden): #Make sure hidden comes from the DocumentEncoder...\n",
    "        \"\"\"\n",
    "        Embeds input and applies GRU one token at a time (seq_len = 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
    "        emb = emb.view(1, -1, self.embedding_dim).float()       # 1 x batch_size x embedding_dim\n",
    "        out, hidden = self.gru(emb, hidden) # 1 x batch_size x hidden_dim (out)\n",
    "        #out = torch.cat((out, doc_enc_hidden),dim=-1)\n",
    "        out = out.view(-1, self.hidden_dim)\n",
    "        out = self.gru2out(out)  # batch_size x vocab_size\n",
    "        out = F.log_softmax(out, dim=-1)\n",
    "        return out, hidden\n",
    "    \n",
    "    def batchNLLLoss(self, inp, target, comp, comp_lens, documentEncoder, embedder, num_samples = batch_size):\n",
    "        \"\"\"\n",
    "        Returns the NLL Loss for predicting target sequence.\n",
    "        Inputs: inp, target\n",
    "            - inp: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            inp should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)           # seq_len x batch_size\n",
    "        target = target.permute(1, 0)     # seq_len x batch_size\n",
    "        doc_enc_hidden = self.init_hidden(comp, comp_lens, num_samples, documentEncoder, embedder)\n",
    "        h = doc_enc_hidden\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h, doc_enc_hidden)\n",
    "            loss += loss_fn(out, target[i])\n",
    "\n",
    "        return loss     # per batch\n",
    "\n",
    "    def sample(self, num_samples, comp, comp_lens,  documentEncoder, embedder, start_letter=START_TOKEN):\n",
    "        \"\"\"\n",
    "        Samples the network and returns num_samples samples of length max_seq_len.\n",
    "        Outputs: samples, hidden\n",
    "            - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
    "        \"\"\"\n",
    "\n",
    "        samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
    "\n",
    "        doc_enc_hidden = self.init_hidden(comp, comp_lens, num_samples, documentEncoder, embedder)\n",
    "        inp = torch.autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
    "\n",
    "        if self.gpu:\n",
    "            samples = samples.cuda()\n",
    "            inp = inp.cuda()\n",
    "        h = doc_enc_hidden\n",
    "        for i in range(self.max_seq_len):\n",
    "            out, h = self.forward(inp, h, doc_enc_hidden)               # out: num_samples x vocab_size\n",
    "            _, out = torch.max(torch.exp(out), dim=-1)  # num_samples x 1 (sampling from each row)\n",
    "            # out = torch.multinomial(torch.exp(out), 1)  # num_samples x 1 (sampling from each row)\n",
    "            samples[:, i] = out.data\n",
    "\n",
    "            inp = out.view(-1)\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def randomSample(self, num_samples, comp, documentEncoder, embedder, start_letter=START_TOKEN, num_rand = 5, minProb = 0.3):\n",
    "        \n",
    "        samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
    "\n",
    "        doc_enc_hidden = self.init_hidden(comp, num_samples, documentEncoder, embedder)\n",
    "        inp = torch.autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
    "\n",
    "        if self.gpu:\n",
    "            samples = samples.cuda()\n",
    "            inp = inp.cuda()\n",
    "        h = doc_enc_hidden\n",
    "        for i in range(self.max_seq_len):\n",
    "            out, h = self.forward(inp, h, doc_enc_hidden)               # out: num_samples x vocab_size\n",
    "            out_sample = torch.multinomial(torch.exp(out), num_rand)  # num_samples x 1 (sampling from each row)\n",
    "            out = out_sample[random.randint(0,num_rand)]\n",
    "            samples[:, i] = out.data\n",
    "\n",
    "            inp = out.view(-1)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    \n",
    "\n",
    "    def batchSuppressionLoss(self, inp,valid_toks,valid_tok_len, comp,documentEncoder, embedder, num_samples = batch_size):\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)           # seq_len x batch_size\n",
    "        doc_enc_hidden = self.init_hidden(comp, num_samples, documentEncoder, embedder)\n",
    "        h = doc_enc_hidden\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h, doc_enc_hidden)\n",
    "            _, vocab_size_o = out.size()\n",
    "            #out = torch.exp(out)\n",
    "            #l1 = torch.sum(torch.mul(out, (1-valid_toks)).float(), dim = 1)\n",
    "            l2 = torch.sum(torch.mul(out, valid_toks.float()), dim = 1)\n",
    "            \n",
    "            #l1 = torch.div(l1, (vocab_size_o - valid_tok_len))\n",
    "            #loss += (torch.sum(l1) - torch.sum(l2))\n",
    "            loss += -l2\n",
    "        return loss\n",
    "    \n",
    "    def batchDegeneracyLoss(self, inp, comp,comp_lens,documentEncoder, embedder, num_samples = batch_size):\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)           # seq_len x batch_size\n",
    "        doc_enc_hidden = self.init_hidden(comp, comp_lens,  num_samples, documentEncoder, embedder)\n",
    "        h = doc_enc_hidden\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h, doc_enc_hidden)\n",
    "            out = torch.exp(out)\n",
    "            out = out.unsqueeze(2)\n",
    "            a1 = out.transpose(1,2)\n",
    "            a2 = torch.log(out)\n",
    "            loss += torch.bmm(a1, a2)\n",
    "        loss = torch.sum(loss) / (batch_size * seq_len)\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def batchPGLoss(self, inp, target, reward, comp, documentEncoder, embedder):\n",
    "        \"\"\"\n",
    "        Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
    "        Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
    "        Inputs: inp, target\n",
    "            - inp: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
    "                      sentence)\n",
    "            inp should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)          # seq_len x batch_size\n",
    "        target = target.permute(1, 0)    # seq_len x batch_size\n",
    "        h = self.init_hidden(comp, batch_size, documentEncoder, embedder)\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h)\n",
    "            # TODO: should h be detached from graph (.detach())?\n",
    "            for j in range(batch_size):\n",
    "                print(target.data[i][j], out[j][target.data[i][j]])\n",
    "                loss += -out[j][target.data[i][j]]*reward[j]     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
    "\n",
    "        return loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(input_size = reduced_glove.shape[0], output_size = reduced_glove.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "\n",
    "documentEncoder = DocumentEncoderRNN(reduced_glove.shape[1], hidden_size)\n",
    "\n",
    "gen = Generator(embedding_dim = reduced_glove.shape[1], \n",
    "                embeddings = embedder, \n",
    "                hidden_dim = hidden_size * 2, \n",
    "                vocab_size = reduced_glove.shape[0], \n",
    "                max_seq_len = max_question_len, \n",
    "                gpu=USE_CUDA)\n",
    "\n",
    "if USE_CUDA:\n",
    "    gen= gen.cuda()\n",
    "    documentEncoder = documentEncoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_MLE(gen, gen_opt, batch_input, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "        total_loss_2 = 0\n",
    "        total_loss_3 = 0\n",
    "        print(\" \")\n",
    "        for i in range(len(batch_input)):\n",
    "            print('batch %d/%d : ' % (i + 1, len(batch_input)), end='\\r')\n",
    "            randomShuffleBatch(batch_input[i])\n",
    "            inp = batch_input[i]['question_input_tokens']\n",
    "            target = batch_input[i]['question_output_tokens'] \n",
    "            comp =  batch_input[i]['document_tokens']\n",
    "            comp_lens = batch_input[i]['document_lengths']\n",
    "            valid_toks = batch_input[i]['valid_tokens']\n",
    "            valid_tok_len = batch_input[i]['valid_tokens_length']\n",
    "            if USE_CUDA:\n",
    "                inp = torch.from_numpy(inp).long().cuda()\n",
    "                target = Variable(torch.from_numpy(target).long().cuda())\n",
    "                comp = Variable(torch.from_numpy(comp).long().cuda())\n",
    "                valid_toks = Variable(torch.from_numpy(valid_toks).float().cuda())\n",
    "                valid_tok_len = Variable(torch.from_numpy(valid_tok_len).float().cuda())\n",
    "                #comp_lens = Variable(torch.from_numpy(comp_lens).float().cuda())\n",
    "            else:\n",
    "                inp = torch.from_numpy(inp).long()\n",
    "                target = Variable(torch.from_numpy(target).long())\n",
    "                comp = Variable(torch.from_numpy(comp).long())\n",
    "                valid_toks = Variable(torch.from_numpy(valid_toks).float())\n",
    "                valid_tok_len = Variable(torch.from_numpy(valid_tok_len).float())\n",
    "                #comp_lens = Variable(torch.from_numpy(comp_lens).float())\n",
    "                \n",
    "            gen_opt.zero_grad()\n",
    "            \n",
    "            #loss3 = gen.batchSuppressionLoss(inp,valid_toks,valid_tok_len,comp,documentEncoder, embedder, inp.shape[0])\n",
    "\n",
    "            #loss2 = gen.batchDegeneracyLoss(inp, comp, documentEncoder, embedder, inp.shape[0])\n",
    "            \n",
    "            loss = gen.batchNLLLoss(inp,target,comp,comp_lens.tolist(),documentEncoder, embedder, inp.shape[0])\n",
    "            \n",
    "            net_loss = loss\n",
    "            net_loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data[0]\n",
    "#            total_loss_2+= loss2.data[0]\n",
    "#            total_loss_3 += loss3.data[0] \n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "        print(' Total Loss = %.4f, Degeneracy Loss = %.4f, Suppression Loss = %.4f' % \n",
    "              (total_loss, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_param_gen = []\n",
    "train_param_disc = []\n",
    "\n",
    "for model in [gen, documentEncoder]:\n",
    "    train_param_gen += [p for p in model.parameters() if p.requires_grad]\n",
    "    \n",
    "gen_optimizer = optim.Adam(train_param_gen, lr=1e-2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Generator\n",
      "epoch 1 :  \n",
      " Total Loss = 823.7488, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 2 :  \n",
      " Total Loss = 402.5255, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 3 :  \n",
      " Total Loss = 263.8961, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 4 :  \n",
      " Total Loss = 231.1911, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 5 :  \n",
      " Total Loss = 210.7619, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 6 :  \n",
      " Total Loss = 197.8275, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 7 :  \n",
      " Total Loss = 186.3703, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 8 :  \n",
      " Total Loss = 174.9072, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 9 :  \n",
      " Total Loss = 163.2576, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 10 :  \n",
      " Total Loss = 153.0750, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 11 :  \n",
      " Total Loss = 139.8184, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 12 :  \n",
      " Total Loss = 128.1733, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 13 :  \n",
      " Total Loss = 116.7047, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 14 :  \n",
      " Total Loss = 106.0777, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 15 :  \n",
      " Total Loss = 95.9229, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 16 :  \n",
      " Total Loss = 86.9747, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 17 :  \n",
      " Total Loss = 78.4887, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 18 :  \n",
      " Total Loss = 70.7087, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 19 :  \n",
      " Total Loss = 63.9244, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 20 :  \n",
      " Total Loss = 57.9517, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 21 :  \n",
      " Total Loss = 52.7577, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 22 :  \n",
      " Total Loss = 47.8783, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 23 :  \n",
      " Total Loss = 44.4125, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 24 :  \n",
      " Total Loss = 40.6282, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 25 :  \n",
      " Total Loss = 37.7484, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 26 :  \n",
      " Total Loss = 34.7865, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 27 :  \n",
      " Total Loss = 33.3925, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 28 :  \n",
      " Total Loss = 31.2351, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 29 :  \n",
      " Total Loss = 29.5119, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 30 :  \n",
      " Total Loss = 27.8082, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 31 :  \n",
      " Total Loss = 26.8786, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 32 :  \n",
      " Total Loss = 25.7492, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 33 :  \n",
      " Total Loss = 24.7842, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 34 :  \n",
      " Total Loss = 23.3840, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 35 :  \n",
      " Total Loss = 23.1228, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 36 :  \n",
      " Total Loss = 22.1284, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 37 :  \n",
      " Total Loss = 21.9105, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 38 :  \n",
      " Total Loss = 21.1709, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 39 :  \n",
      " Total Loss = 20.5381, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 40 :  \n",
      " Total Loss = 19.6126, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 41 :  \n",
      " Total Loss = 19.3507, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 42 :  \n",
      " Total Loss = 18.9024, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 43 :  \n",
      " Total Loss = 18.4762, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 44 :  \n",
      " Total Loss = 18.3328, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 45 :  \n",
      " Total Loss = 18.1202, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 46 :  \n",
      " Total Loss = 17.8369, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 47 :  \n",
      " Total Loss = 17.1919, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 48 :  \n",
      " Total Loss = 16.7484, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 49 :  \n",
      " Total Loss = 17.1303, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 50 :  \n",
      " Total Loss = 16.0557, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 51 :  \n",
      " Total Loss = 16.3916, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 52 :  \n",
      " Total Loss = 15.6649, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 53 :  \n",
      " Total Loss = 15.5934, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 54 :  \n",
      " Total Loss = 15.8140, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 55 :  \n",
      " Total Loss = 15.5625, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 56 :  \n",
      " Total Loss = 15.7096, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 57 :  \n",
      " Total Loss = 15.2582, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 58 :  \n",
      " Total Loss = 15.1038, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 59 :  \n",
      " Total Loss = 14.1046, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 60 :  \n",
      " Total Loss = 14.4985, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 61 :  \n",
      " Total Loss = 13.8823, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 62 :  \n",
      " Total Loss = 15.0424, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 63 :  \n",
      " Total Loss = 14.2408, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 64 :  \n",
      " Total Loss = 14.6296, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 65 :  \n",
      " Total Loss = 14.0469, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 66 :  \n",
      " Total Loss = 14.0227, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 67 :  \n",
      " Total Loss = 13.7271, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 68 :  \n",
      " Total Loss = 13.8325, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 69 :  \n",
      " Total Loss = 13.3009, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 70 :  \n",
      " Total Loss = 13.0896, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 71 :  \n",
      " Total Loss = 13.6668, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 72 :  \n",
      " Total Loss = 13.3031, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 73 :  \n",
      " Total Loss = 13.3283, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 74 :  \n",
      " Total Loss = 13.6102, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 75 :  \n",
      " Total Loss = 13.1462, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 76 :  \n",
      " Total Loss = 13.0938, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 77 :  \n",
      " Total Loss = 12.7890, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 78 :  \n",
      " Total Loss = 12.9596, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 79 :  \n",
      " Total Loss = 12.5578, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 80 :  \n",
      " Total Loss = 12.8643, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 81 :  \n",
      " Total Loss = 12.4395, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 82 :  \n",
      " Total Loss = 12.0168, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 83 :  \n",
      " Total Loss = 12.5184, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 84 :  \n",
      " Total Loss = 13.0062, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 85 :  \n",
      " Total Loss = 12.2195, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 86 :  \n",
      " Total Loss = 12.1001, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 87 :  \n",
      " Total Loss = 12.7153, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 88 :  \n",
      " Total Loss = 12.1958, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 89 :  \n",
      " Total Loss = 12.2318, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 90 :  \n",
      " Total Loss = 11.8367, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 91 :  \n",
      " Total Loss = 12.5465, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 92 :  \n",
      " Total Loss = 12.1788, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 93 :  \n",
      " Total Loss = 11.8290, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 :  \n",
      " Total Loss = 12.0974, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 95 :  \n",
      " Total Loss = 11.8142, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 96 :  \n",
      " Total Loss = 11.6309, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 97 :  \n",
      " Total Loss = 11.5712, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 98 :  \n",
      " Total Loss = 11.2103, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 99 :  \n",
      " Total Loss = 11.8317, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 100 :  \n",
      " Total Loss = 11.1205, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 101 :  \n",
      " Total Loss = 11.7454, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 102 :  \n",
      " Total Loss = 11.4791, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 103 :  \n",
      " Total Loss = 12.1157, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 104 :  \n",
      " Total Loss = 11.6992, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 105 :  \n",
      " Total Loss = 10.8743, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 106 :  \n",
      " Total Loss = 11.6142, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 107 :  \n",
      " Total Loss = 11.3273, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 108 :  \n",
      " Total Loss = 11.1917, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 109 :  \n",
      " Total Loss = 11.1657, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 110 :  \n",
      " Total Loss = 10.5205, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 111 :  \n",
      " Total Loss = 11.2168, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 112 :  \n",
      " Total Loss = 11.4701, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 113 :  \n",
      " Total Loss = 11.4222, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 114 :  \n",
      " Total Loss = 10.9642, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 115 :  \n",
      " Total Loss = 10.9393, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 116 :  \n",
      " Total Loss = 10.3817, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 117 :  \n",
      " Total Loss = 10.4323, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 118 :  \n",
      " Total Loss = 10.6702, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 119 :  \n",
      " Total Loss = 10.9272, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 120 :  \n",
      " Total Loss = 10.4791, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 121 :  \n",
      " Total Loss = 10.6426, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 122 :  \n",
      " Total Loss = 10.9207, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 123 :  \n",
      " Total Loss = 10.5363, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 124 :  \n",
      " Total Loss = 10.4601, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 125 :  \n",
      " Total Loss = 10.7566, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 126 :  \n",
      " Total Loss = 11.0127, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 127 :  \n",
      " Total Loss = 10.3915, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 128 :  \n",
      " Total Loss = 10.5946, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 129 :  \n",
      " Total Loss = 10.5644, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 130 :  \n",
      " Total Loss = 9.9698, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 131 :  \n",
      " Total Loss = 10.9141, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 132 :  \n",
      " Total Loss = 10.2135, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 133 :  \n",
      " Total Loss = 9.8465, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 134 :  \n",
      " Total Loss = 10.5031, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 135 :  \n",
      " Total Loss = 10.0447, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 136 :  \n",
      " Total Loss = 9.6639, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 137 :  \n",
      " Total Loss = 9.7442, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 138 :  \n",
      " Total Loss = 9.8178, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 139 :  \n",
      " Total Loss = 10.2629, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 140 :  \n",
      " Total Loss = 10.0263, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 141 :  \n",
      " Total Loss = 10.2525, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 142 :  \n",
      " Total Loss = 9.5835, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 143 :  \n",
      " Total Loss = 10.5351, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 144 :  \n",
      " Total Loss = 10.3617, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 145 :  \n",
      " Total Loss = 10.3139, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 146 :  \n",
      " Total Loss = 9.2971, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 147 :  \n",
      " Total Loss = 9.7340, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 148 :  \n",
      " Total Loss = 9.7844, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 149 :  \n",
      " Total Loss = 9.4354, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 150 :  \n",
      " Total Loss = 9.2177, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 151 :  \n",
      " Total Loss = 9.6044, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 152 :  \n",
      " Total Loss = 10.1872, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 153 :  \n",
      " Total Loss = 9.4970, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 154 :  \n",
      " Total Loss = 9.8891, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 155 :  \n",
      " Total Loss = 9.8470, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 156 :  \n",
      " Total Loss = 10.1831, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 157 :  \n",
      " Total Loss = 10.0295, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 158 :  \n",
      " Total Loss = 9.7022, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 159 :  \n",
      " Total Loss = 9.2160, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 160 :  \n",
      " Total Loss = 9.4823, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 161 :  \n",
      " Total Loss = 9.1398, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 162 :  \n",
      " Total Loss = 8.9083, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 163 :  \n",
      " Total Loss = 9.4211, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 164 :  \n",
      " Total Loss = 10.0791, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 165 :  \n",
      " Total Loss = 9.8826, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 166 :  \n",
      " Total Loss = 9.6062, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 167 :  \n",
      " Total Loss = 10.6174, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 168 :  \n",
      " Total Loss = 9.8103, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 169 :  \n",
      " Total Loss = 9.8210, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 170 :  \n",
      " Total Loss = 9.9204, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 171 :  \n",
      " Total Loss = 9.7134, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 172 :  \n",
      " Total Loss = 9.6189, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 173 :  \n",
      " Total Loss = 9.7964, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 174 :  \n",
      " Total Loss = 9.4737, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 175 :  \n",
      " Total Loss = 9.8443, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 176 :  \n",
      " Total Loss = 9.9060, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 177 :  \n",
      " Total Loss = 9.7060, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 178 :  \n",
      " Total Loss = 9.6243, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 179 :  \n",
      " Total Loss = 9.4324, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 180 :  \n",
      " Total Loss = 9.4027, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 181 :  \n",
      " Total Loss = 9.2298, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 182 :  \n",
      " Total Loss = 9.7350, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 183 :  \n",
      " Total Loss = 9.4161, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 184 :  \n",
      " Total Loss = 9.2101, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 185 :  \n",
      " Total Loss = 9.5569, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 186 :  \n",
      " Total Loss = 9.4113, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187 :  \n",
      " Total Loss = 9.3317, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 188 :  \n",
      " Total Loss = 9.4532, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 189 :  \n",
      " Total Loss = 8.9493, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 190 :  \n",
      " Total Loss = 9.1360, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 191 :  \n",
      " Total Loss = 9.7589, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 192 :  \n",
      " Total Loss = 8.9335, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 193 :  \n",
      " Total Loss = 9.2254, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 194 :  \n",
      " Total Loss = 9.0575, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 195 :  \n",
      " Total Loss = 9.4537, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 196 :  \n",
      " Total Loss = 9.9477, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 197 :  \n",
      " Total Loss = 9.5717, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 198 :  \n",
      " Total Loss = 9.6731, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 199 :  \n",
      " Total Loss = 8.9142, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 200 :  \n",
      " Total Loss = 9.3684, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 201 :  \n",
      " Total Loss = 9.6413, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 202 :  \n",
      " Total Loss = 9.5821, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 203 :  \n",
      " Total Loss = 9.5932, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 204 :  \n",
      " Total Loss = 9.8726, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 205 :  \n",
      " Total Loss = 9.2159, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 206 :  \n",
      " Total Loss = 9.3779, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 207 :  \n",
      " Total Loss = 9.2020, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 208 :  \n",
      " Total Loss = 9.6053, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 209 :  \n",
      " Total Loss = 8.9333, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 210 :  \n",
      " Total Loss = 9.1681, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 211 :  \n",
      " Total Loss = 9.1098, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 212 :  \n",
      " Total Loss = 8.9735, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 213 :  \n",
      " Total Loss = 9.4363, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 214 :  \n",
      " Total Loss = 9.3945, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 215 :  \n",
      " Total Loss = 9.2247, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 216 :  \n",
      " Total Loss = 9.4564, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 217 :  \n",
      " Total Loss = 8.9768, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 218 :  \n",
      " Total Loss = 9.0492, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 219 :  \n",
      " Total Loss = 9.0122, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 220 :  \n",
      " Total Loss = 9.1045, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 221 :  \n",
      " Total Loss = 8.2648, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 222 :  \n",
      " Total Loss = 9.1803, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 223 :  \n",
      " Total Loss = 9.6042, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 224 :  \n",
      " Total Loss = 9.1948, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 225 :  \n",
      " Total Loss = 9.4505, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 226 :  \n",
      " Total Loss = 9.0025, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 227 :  \n",
      " Total Loss = 8.9771, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 228 :  \n",
      " Total Loss = 8.2934, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 229 :  \n",
      " Total Loss = 9.0986, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 230 :  \n",
      " Total Loss = 10.0657, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 231 :  \n",
      " Total Loss = 9.3293, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 232 :  \n",
      " Total Loss = 10.0344, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 233 :  \n",
      " Total Loss = 9.3443, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 234 :  \n",
      " Total Loss = 9.1727, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 235 :  \n",
      " Total Loss = 9.1276, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 236 :  \n",
      " Total Loss = 8.9877, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 237 :  \n",
      " Total Loss = 8.5984, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 238 :  \n",
      " Total Loss = 9.0875, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 239 :  \n",
      " Total Loss = 9.6407, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 240 :  \n",
      " Total Loss = 8.7625, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 241 :  \n",
      " Total Loss = 9.7661, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 242 :  \n",
      " Total Loss = 8.7401, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 243 :  \n",
      " Total Loss = 9.5021, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 244 :  \n",
      " Total Loss = 9.1948, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 245 :  \n",
      " Total Loss = 9.2095, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 246 :  \n",
      " Total Loss = 9.0213, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 247 :  \n",
      " Total Loss = 8.7978, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 248 :  \n",
      " Total Loss = 9.2437, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 249 :  \n",
      " Total Loss = 8.7974, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 250 :  \n",
      " Total Loss = 9.4498, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 251 :  \n",
      " Total Loss = 9.3212, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 252 :  \n",
      " Total Loss = 9.6182, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 253 :  \n",
      " Total Loss = 9.2276, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 254 :  \n",
      " Total Loss = 8.7170, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 255 :  \n",
      " Total Loss = 8.7447, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 256 :  \n",
      " Total Loss = 8.9981, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 257 :  \n",
      " Total Loss = 8.9057, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 258 :  \n",
      " Total Loss = 8.7805, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 259 :  \n",
      " Total Loss = 8.9556, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 260 :  \n",
      " Total Loss = 8.5540, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 261 :  \n",
      " Total Loss = 8.9232, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 262 :  \n",
      " Total Loss = 8.7292, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 263 :  \n",
      " Total Loss = 8.8565, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 264 :  \n",
      " Total Loss = 9.6942, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 265 :  \n",
      " Total Loss = 9.2180, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 266 :  \n",
      " Total Loss = 8.8400, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 267 :  \n",
      " Total Loss = 8.8946, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 268 :  \n",
      " Total Loss = 8.4799, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 269 :  \n",
      " Total Loss = 9.0679, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 270 :  \n",
      " Total Loss = 8.8324, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 271 :  \n",
      " Total Loss = 9.1211, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 272 :  \n",
      " Total Loss = 9.0679, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 273 :  \n",
      " Total Loss = 9.1728, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 274 :  \n",
      " Total Loss = 9.1815, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 275 :  \n",
      " Total Loss = 8.9164, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 276 :  \n",
      " Total Loss = 8.4693, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 277 :  \n",
      " Total Loss = 9.0400, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 278 :  \n",
      " Total Loss = 9.1052, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 279 :  \n",
      " Total Loss = 8.6896, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 280 :  \n",
      " Total Loss = 8.9666, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 281 :  \n",
      " Total Loss = 8.6024, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 282 :  \n",
      " Total Loss = 8.9784, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 283 :  \n",
      " Total Loss = 9.5848, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 284 :  \n",
      " Total Loss = 8.9781, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 285 :  \n",
      " Total Loss = 9.0212, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 286 :  \n",
      " Total Loss = 9.1980, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 287 :  \n",
      " Total Loss = 9.7980, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 288 :  \n",
      " Total Loss = 8.9693, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 289 :  \n",
      " Total Loss = 8.9767, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 290 :  \n",
      " Total Loss = 8.9665, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 291 :  \n",
      " Total Loss = 9.5250, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 292 :  \n",
      " Total Loss = 9.1467, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 293 :  \n",
      " Total Loss = 8.9318, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 294 :  \n",
      " Total Loss = 8.7538, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 295 :  \n",
      " Total Loss = 8.6444, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 296 :  \n",
      " Total Loss = 8.9827, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 297 :  \n",
      " Total Loss = 9.4591, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 298 :  \n",
      " Total Loss = 9.0460, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 299 :  \n",
      " Total Loss = 8.9059, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 300 :  \n",
      " Total Loss = 8.5392, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 301 :  \n",
      " Total Loss = 9.3712, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 302 :  \n",
      " Total Loss = 8.9764, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 303 :  \n",
      " Total Loss = 9.0471, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 304 :  \n",
      " Total Loss = 10.4972, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 305 :  \n",
      " Total Loss = 9.5941, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 306 :  \n",
      " Total Loss = 8.9039, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 307 :  \n",
      " Total Loss = 8.7690, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 308 :  \n",
      " Total Loss = 9.1687, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 309 :  \n",
      " Total Loss = 8.7410, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 310 :  \n",
      " Total Loss = 9.0397, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 311 :  \n",
      " Total Loss = 8.9338, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 312 :  \n",
      " Total Loss = 8.6976, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 313 :  \n",
      " Total Loss = 8.8946, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 314 :  \n",
      " Total Loss = 8.6828, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 315 :  \n",
      " Total Loss = 8.9622, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 316 :  \n",
      " Total Loss = 8.9735, Degeneracy Loss = 0.0000, Suppression Loss = 0.0000\n",
      "epoch 317 :  \n",
      "batch 1/4 : \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-372-89fcb65daf73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Generator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_generator_MLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-370-508e85d74c3a>\u001b[0m in \u001b[0;36mtrain_generator_MLE\u001b[0;34m(gen, gen_opt, batch_input, epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mnet_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mnet_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mgen_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Generator\")\n",
    "train_generator_MLE(gen,gen_optimizer, batch_input, 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "for more than 1,500 years . important contributions from the medieval muslim world include ibn wahshiyya 's nabatean agriculture , abū ḥanīfa dīnawarī <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "<START> besides the greeks , what other culture contributed to the study of botany ? <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Generated Question : \n",
      "what does a lush environment allow hunter-gatherers to be ? <END> ? <END> ? <END> ? <END> ? <END> ?  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "foreign cultures . around 1906 , picasso met matisse through gertrude stein , at a time when both artists had recently acquired an <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "<START> who did picasso meet around 1906 that had also recenelty learned about primitivism ? <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Generated Question : \n",
      "who did picasso meet around 1906 that had also recenelty learned about primitivism ? <END> ? <END> ? <END> ?  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "sacrosanctity . one consequence was that it was considered a capital offense to harm a tribune , to disregard his veto , <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "<START> what type of offense was the harm of a tribute treated as ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Generated Question : \n",
      "what does a lush environment allow hunter-gatherers to be ? <END> ? <END> ? <END> ? <END> ? <END> ?  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "off protests during the torch relay , with prime minister nguyễn tấn dũng warning government agencies that `` hostile forces '' may try <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "<START> who was the prime minister of vietnam ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Generated Question : \n",
      "there was a marked trend towards what type of approach to political issues ? <END> ? <END> ? <END> ?  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "lived in particularly rich environments that allowed them to be sedentary or semi-sedentary . <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "<START> what does a lush environment allow hunter-gatherers to be ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>  \n",
      "*****************************************************************************************************\n",
      "Generated Question : \n",
      "who was the prime minister of vietnam ? <END> ? <END> ? <END> ? <END> ? <END> ? <END> ?  \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_num = 2\n",
    "num_examples = 5\n",
    "start = 0\n",
    "end = start + num_examples\n",
    "x = gen.sample(\n",
    "    num_examples, \n",
    "    torch.from_numpy(batch_input[batch_num]['document_tokens'][start:end]).cuda(),\n",
    "    batch_input[batch_num]['document_lengths'][start:end],\n",
    "    documentEncoder, \n",
    "    embedder)\n",
    "#loss2 = gen.batchSuppressionLoss(inp,valid_toks,comp,documentEncoder, embedder, inp.shape[0]) \n",
    "#loss = gen.batchNLLLoss(inp,target,comp,documentEncoder, embedder, inp.shape[0])\n",
    "for i in range(x.shape[0]):\n",
    "    print(\"----------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Comprehension : \")\n",
    "    printTokens(batch_input[batch_num]['document_tokens'][i])\n",
    "    print(\"*****************************************************************************************************\")\n",
    "    print(\"Ground Truth Question : \")\n",
    "    printTokens(batch_input[batch_num]['question_input_tokens'][i])\n",
    "    print(\"*****************************************************************************************************\")\n",
    "    print(\"Generated Question : \")\n",
    "    printTokens(x[i])\n",
    "    print(\"----------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<reversed at 0x7f70e6f0da20>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed(np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_test = inp_l.permute(1, 0)           # seq_len x batch_size\n",
    "h = gen.init_hidden(comp_l, inp_l.shape[0], documentEncoder, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "seq_len = max_question_len\n",
    "for i in range(2,3):\n",
    "    out, h = gen.forward(inp_test[i], h)\n",
    "    x = 0\n",
    "    for j in torch.multinomial(torch.exp(out), 5) : \n",
    "        for k in j:\n",
    "            print(torch.exp(out[x][k]).data[0],look_up_token_reduced(k.data[0]), sep = ' ', end = ' ')\n",
    "        print(\" \")\n",
    "        x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 0\n",
    "num_examples_l = batch_input[batch_num]['document_tokens'].shape[0],  #Number of examples\n",
    "comp_l = Variable(torch.from_numpy(batch_input[batch_num]['document_tokens']).long()).cuda() #Document to torch Variable\n",
    "inp_l = Variable(torch.from_numpy(batch_input[batch_num]['question_input_tokens']).long()).cuda()\n",
    "target_l = Variable(torch.from_numpy(batch_input[batch_num]['question_output_tokens']).long()).cuda()\n",
    "valid_toks_l = Variable(torch.from_numpy(batch_input[batch_num]['valid_tokens']).float()).cuda()\n",
    "valid_toks_length_l = Variable(torch.from_numpy(batch_input[batch_num]['valid_tokens_length']).float()).cuda()\n",
    "#documentEncoder, \n",
    "#embedder\n",
    "\n",
    "#supLoss = gen.batchSuppressionLoss(inp_l,valid_toks_l,valid_toks_length_l,comp_l,documentEncoder, embedder, inp_l.shape[0])\n",
    "#degenLoss = gen.batchDegeneracyLoss(inp_l, comp_l, documentEncoder, embedder, inp_l.shape[0])\n",
    "nllLoss = gen.batchNLLLoss(inp_l,target_l,comp_l,documentEncoder, embedder, inp_l.shape[0])\n",
    "\n",
    "print(supLoss)\n",
    "print(degenLoss)\n",
    "print(nllLoss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_PG(gen, gen_opt, dis, documentEncoder, embedder):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_loss = 0\n",
    "    for batch in batch_input:\n",
    "        comp = Variable(torch.from_numpy(batch['document_tokens']))\n",
    "        if USE_CUDA:\n",
    "            comp = comp.cuda()\n",
    "            \n",
    "        s = gen.sample(batch['document_tokens'].shape[0], comp, documentEncoder, embedder)\n",
    "        inp, target = prepare_generator_batch(s, start_letter=START_TOKEN, gpu=USE_CUDA)\n",
    "        rewards = disc.batchClassify(target, target.shape[0], comp, documentEncoderDisc, embedder)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards, comp, documentEncoder, embedder)\n",
    "        total_loss += pg_loss.data[0]\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "    \n",
    "\n",
    "    print('Total PG Loss : ',  total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
