{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8427b5c736de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'embedding'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import re\n",
    "import numpy as np\n",
    "from embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('train-v1.1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.softmax_cross_entropy_with_logits??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(data):\n",
    "    contexts = []\n",
    "    qas = []\n",
    "    for i in range(len(data[\"data\"])):\n",
    "        for j in range(len(data[\"data\"][i][\"paragraphs\"])):\n",
    "            contexts.append(data[\"data\"][i][\"paragraphs\"][j][\"context\"])\n",
    "            qas.append(data[\"data\"][i][\"paragraphs\"][j][\"qas\"])\n",
    "    return (contexts,qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapPassage = False\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "contexts,qas = extractor(data)\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            return ind,ind+sll\n",
    "    return (-1,-1)\n",
    "\n",
    "def find_sub_list_2(sl ,l):\n",
    "    start = 0\n",
    "    end = len(sl)\n",
    "    while end < len(l):\n",
    "        if l[start:end] == sl:\n",
    "            return (start,right)\n",
    "        start,end = start+1,end+1\n",
    "    return (-1,-1)\n",
    "    \n",
    "\n",
    "def capPassage(passage,answer,cap_length = 30):\n",
    "    y = np.zeros(cap_length)\n",
    "    left,right = find_sub_list(answer,passage)\n",
    "    if(left==-1):\n",
    "        return passage[0:cap_length]\n",
    "    left = left - int((cap_length - len(answer))/2)\n",
    "    right = right + int((cap_length + len(answer))/2)\n",
    "    if(left < 0):\n",
    "        left = 0\n",
    "    if(right > len(passage)):\n",
    "        right = len(passage)\n",
    "    return passage[left:right]\n",
    "    \n",
    "def findAnsVec(answer,passage):\n",
    "    ans = np.zeros((len(passage)))\n",
    "    start,end = find_sub_list(answer,passage)\n",
    "    if(start==-1):\n",
    "        start = passage.index(answer[0])\n",
    "        end = start + len(answer)\n",
    "    ans[start:end] = 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_comp_all = []\n",
    "X_train_comp_ans_all = []\n",
    "X_train_ans_all = []\n",
    "Y_train_ques_all = []\n",
    "invalid = 0\n",
    "X_train_ans_label_all = []\n",
    "for i,context in enumerate(contexts):\n",
    "    passage = word_tokenize(context.lower())\n",
    "    \n",
    "    a_lab = np.zeros(len(passage))\n",
    "    for j,_ in enumerate(qas[i]):\n",
    "        answer = word_tokenize(qas[i][j][\"answers\"][0]['text'].lower())\n",
    "        start,end = find_sub_list(answer,passage)\n",
    "        if start == -1:\n",
    "            continue\n",
    "        a_lab[start:end+1] = 1\n",
    "            \n",
    "            \n",
    "    for j,_ in enumerate(qas[i]):\n",
    "        try:\n",
    "            question = word_tokenize(qas[i][j]['question'].lower())\n",
    "            answer = word_tokenize(qas[i][j][\"answers\"][0]['text'].lower())\n",
    "            \n",
    "            if CapPassage:\n",
    "                cappedPassage = capPassage(passage,answer)\n",
    "            else:\n",
    "                cappedPassage = passage\n",
    "            \n",
    "            X_train_comp_ans_all.append(findAnsVec(answer,passage))\n",
    "            X_train_ans_label_all.append(a_lab)\n",
    "            X_train_comp_all.append(cappedPassage)\n",
    "            X_train_ans_all.append(answer)\n",
    "            Y_train_ques_all.append(question)\n",
    "        except Exception as e:\n",
    "            invalid = invalid+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n",
      "rev\n",
      ".\n",
      "john\n",
      "j.\n",
      "cavanaugh\n",
      ",\n",
      "c.s.c\n",
      ".\n",
      "served\n",
      "more\n",
      "than\n",
      "half\n",
      ",\n",
      "lobund\n",
      "institute\n",
      "for\n",
      "animal\n",
      "studies\n",
      "and\n",
      "medieval\n",
      "institute\n",
      ".\n",
      "hall\n",
      "of\n",
      "liberal\n",
      "arts\n",
      "(\n"
     ]
    }
   ],
   "source": [
    "print(invalid)\n",
    "for i in np.where(X_train_ans_label_all[110] == 1)[0]:\n",
    "    print(X_train_comp_all[110][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['architecturally', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'s\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '``', 'venite', 'ad', 'me', 'omnes', \"''\", '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'grotto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'lourdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputedly', 'appeared', 'to', 'saint', 'bernadette', 'soubirous', 'in', '1858.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.']\n",
      "['saint', 'bernadette', 'soubirous']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_comp_all[0])\n",
    "print(X_train_ans_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 105)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sub_list(X_train_ans_all[0] , X_train_comp_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n",
      "['the', 'success', 'of', 'its', 'football', 'team', 'made', 'notre', 'dame', 'a', 'household', 'name', '.', 'the', 'success', 'of', 'note', 'dame', 'reflected', 'rising', 'status', 'of', 'irish', 'americans', 'and', 'catholics', 'in', 'the', '1920s', '.', 'catholics', 'rallied', 'up', 'around', 'the', 'team', 'and', 'listen', 'to', 'the', 'games', 'on', 'the', 'radio', ',', 'especially', 'when', 'it', 'knocked', 'off', 'the', 'schools', 'that', 'symbolized', 'the', 'protestant', 'establishment', 'in', 'america', '—', 'harvard', ',', 'yale', ',', 'princeton', ',', 'and', 'army', '.', 'yet', 'this', 'role', 'as', 'high-profile', 'flagship', 'institution', 'of', 'catholicism', 'made', 'it', 'an', 'easy', 'target', 'of', 'anti-catholicism', '.', 'the', 'most', 'remarkable', 'episode', 'of', 'violence', 'was', 'the', 'clash', 'between', 'notre', 'dame', 'students', 'and', 'the', 'ku', 'klux', 'klan', 'in', '1924.', 'nativism', 'and', 'anti-catholicism', ',', 'especially', 'when', 'directed', 'towards', 'immigrants', ',', 'were', 'cornerstones', 'of', 'the', 'kkk', \"'s\", 'rhetoric', ',', 'and', 'notre', 'dame', 'was', 'seen', 'as', 'a', 'symbol', 'of', 'the', 'threat', 'posed', 'by', 'the', 'catholic', 'church', '.', 'the', 'klan', 'decided', 'to', 'have', 'a', 'week-long', 'klavern', 'in', 'south', 'bend', '.', 'clashes', 'with', 'the', 'student', 'body', 'started', 'on', 'march', '17', ',', 'when', 'students', ',', 'aware', 'of', 'the', 'anti-catholic', 'animosity', ',', 'blocked', 'the', 'klansmen', 'from', 'descending', 'from', 'their', 'trains', 'in', 'the', 'south', 'bend', 'station', 'and', 'ripped', 'the', 'kkk', 'clothes', 'and', 'regalia', '.', 'on', 'may', '19', 'thousands', 'of', 'students', 'massed', 'downtown', 'protesting', 'the', 'klavern', ',', 'and', 'only', 'the', 'arrival', 'of', 'college', 'president', 'fr', '.', 'matthew', 'walsh', 'prevented', 'any', 'further', 'clashes', '.', 'the', 'next', 'day', ',', 'football', 'coach', 'knute', 'rockne', 'spoke', 'at', 'a', 'campus', 'rally', 'and', 'implored', 'the', 'students', 'to', 'obey', 'the', 'college', 'president', 'and', 'refrain', 'from', 'further', 'violence', '.', 'a', 'few', 'days', 'later', 'the', 'klavern', 'broke', 'up', ',', 'but', 'the', 'hostility', 'shown', 'by', 'the', 'students', 'was', 'an', 'omen', 'and', 'a', 'contribution', 'to', 'the', 'downfall', 'of', 'the', 'kkk', 'in', 'indiana', '.']\n",
      "['the', 'ku', 'klux', 'klan']\n",
      "['notre', 'dame', 'students', 'had', 'a', 'showdown', 'in', '1924', 'with', 'which', 'anti-catholic', 'group', '?']\n",
      "['in', 'the', 'byzantine', 'rite', 'of', 'the', 'eastern', 'orthodox', 'church', 'and', 'the', 'eastern', 'catholic', 'churches', ',', 'the', 'music', 'performed', 'in', 'the', 'liturgies', 'is', 'exclusively', 'sung', 'without', 'instrumental', 'accompaniment', '.', 'bishop', 'kallistos', 'ware', 'says', ',', '``', 'the', 'service', 'is', 'sung', ',', 'even', 'though', 'there', 'may', 'be', 'no', 'choir', '...', 'in', 'the', 'orthodox', 'church', 'today', ',', 'as', 'in', 'the', 'early', 'church', ',', 'singing', 'is', 'unaccompanied', 'and', 'instrumental', 'music', 'is', 'not', 'found', '.', \"''\", 'this', 'a', 'cappella', 'behavior', 'arises', 'from', 'strict', 'interpretation', 'of', 'psalms', '150', ',', 'which', 'states', ',', 'let', 'every', 'thing', 'that', 'hath', 'breath', 'praise', 'the', 'lord', '.', 'praise', 'ye', 'the', 'lord', '.', 'in', 'keeping', 'with', 'this', 'philosophy', ',', 'early', 'russian', 'musika', 'which', 'started', 'appearing', 'in', 'the', 'late', '17th', 'century', ',', 'in', 'what', 'was', 'known', 'as', 'khorovïye', 'kontsertï', '(', 'choral', 'concertos', ')', 'made', 'a', 'cappella', 'adaptations', 'of', 'venetian-styled', 'pieces', ',', 'such', 'as', 'the', 'treatise', ',', 'grammatika', 'musikiyskaya', '(', '1675', ')', ',', 'by', 'nikolai', 'diletsky', '.', 'divine', 'liturgies', 'and', 'western', 'rite', 'masses', 'composed', 'by', 'famous', 'composers', 'such', 'as', 'peter', 'tchaikovsky', ',', 'sergei', 'rachmaninoff', ',', 'alexander', 'arkhangelsky', ',', 'and', 'mykola', 'leontovych', 'are', 'fine', 'examples', 'of', 'this', '.']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "['nikolai', 'diletsky']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "['who', 'composed', 'a', 'popular', 'venetian-styled', 'piece', 'in', '1675', '?']\n"
     ]
    }
   ],
   "source": [
    "print(invalid)\n",
    "print(X_train_comp_all[101])\n",
    "print(X_train_ans_all[101])\n",
    "print(Y_train_ques_all[101])\n",
    "\n",
    "c = list(zip(X_train_comp_all,X_train_comp_ans_all, X_train_ans_all, X_train_ans_label_all,Y_train_ques_all))\n",
    "np.random.shuffle(c)\n",
    "X_train_comp_all_shuffled,X_train_comp_ans_all_shuffled, X_train_ans_shuffled, X_train_ans_label_shuffled,Y_train_ques_all_shuffled = zip(*c)\n",
    "\n",
    "print(X_train_comp_all_shuffled[101])\n",
    "print(X_train_comp_ans_all_shuffled[101])\n",
    "print(X_train_ans_shuffled[101])\n",
    "print(X_train_ans_label_shuffled[101])\n",
    "print(Y_train_ques_all_shuffled[101])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_take_train = 100\n",
    "\n",
    "X_train_comp = X_train_comp_all_shuffled[0:examples_to_take_train]\n",
    "X_train_comp_ans = X_train_comp_ans_all_shuffled[0:examples_to_take_train]\n",
    "X_train_ans = X_train_ans_shuffled[0:examples_to_take_train]\n",
    "X_train_ans_label = X_train_ans_label_shuffled[0:examples_to_take_train]\n",
    "Y_train_ques = Y_train_ques_all_shuffled[0:examples_to_take_train]\n",
    "answer_indices = [np.where(x==1)[0].tolist() for x in X_train_comp_ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_len = len(max(X_train_comp,key=len))\n",
    "max_answer_len = len(max(X_train_ans,key=len))\n",
    "max_question_len = len(max(Y_train_ques,key=len)) + 1\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = np.zeros((batch_size, max_document_len), dtype=np.int32)\n",
    "document_lengths = np.zeros(batch_size, dtype=np.int32)\n",
    "answer_labels = np.zeros((batch_size, max_document_len), dtype=np.int32)\n",
    "answer_masks = np.zeros((batch_size, max_answer_len, max_document_len), dtype=np.int32)\n",
    "answer_lengths = np.zeros(batch_size, dtype=np.int32)\n",
    "question_input_tokens = np.zeros((batch_size, max_question_len), dtype=np.int32)\n",
    "question_output_tokens = np.zeros((batch_size, max_question_len), dtype=np.int32)\n",
    "question_lengths = np.zeros(batch_size, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 292)\n"
     ]
    }
   ],
   "source": [
    "print(answer_labels.shape)\n",
    "for i in range(batch_size):\n",
    "    answer_labels[i,0:len(X_train_ans_label[i])] = X_train_ans_label[i]\n",
    "    for j, word in enumerate(X_train_comp[i]):\n",
    "        document_tokens[i, j] = look_up_word(word)\n",
    "    document_lengths[i] = len(X_train_comp[i])\n",
    "\n",
    "    for j, index in enumerate(answer_indices[i]):\n",
    "        answer_masks[i, j, index] = 1\n",
    "    answer_lengths[i] = len(answer_indices[i])\n",
    "    \n",
    "    #print(Y_train_ques[i])\n",
    "    question_input_words = ([START_WORD] + Y_train_ques[i])\n",
    "    question_output_words = (Y_train_ques[i] + [END_WORD])\n",
    "\n",
    "    for j, word in enumerate(question_input_words):\n",
    "            question_input_tokens[i, j] = look_up_word(word)\n",
    "    for j, word in enumerate(question_output_words):\n",
    "        question_output_tokens[i, j] = look_up_word(word)\n",
    "    question_lengths[i] = len(question_input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(data):\n",
    "    flat_list = [item for sublist in data for item in sublist]\n",
    "    vocabulary = sorted(set(flat_list))\n",
    "    vocabulary.append(\"<UNK>\")\n",
    "    vocabulary.append(\"unk\")\n",
    "    vocabulary.append(\"eos\")\n",
    "    vocabulary = [\"<EOS>\"] + vocabulary\n",
    "    word_to_index = { word:i for i,word in enumerate(vocabulary) }\n",
    "    index_to_word = { i:word for i,word in enumerate(vocabulary) }\n",
    "    return (vocabulary,word_to_index,index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_to_index_glove, index_to_word_glove, word_to_vec_map_glove = read_glove_vecs('../Ex2+HW1/glove.6B/glove.6B.300d.txt')\n",
    "#word_to_index_glove[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,   105,   263,   948, 58511,  2813,   328,  2205,    22,\n",
       "         191,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_input_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400003, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982\n",
      "282\n",
      "3890\n"
     ]
    }
   ],
   "source": [
    "vocabulary_comp,word_to_index_comp,index_to_word_comp = create_vocabulary(X_train_comp + Y_train_ques)\n",
    "print(len(vocabulary_comp))\n",
    "print(word_to_index_comp[\"?\"])\n",
    "print(word_to_index_comp[\"what\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_vector(data,vocabulary,word_to_index,index_to_word, maxLen):\n",
    "    one_hot = np.zeros([maxLen,len(vocabulary)])\n",
    "    for i,word in enumerate(data):\n",
    "        if i >= maxLen:\n",
    "            break\n",
    "        if(word not in word_to_index):\n",
    "            word = \"<UNK>\"\n",
    "        one_hot[i][word_to_index[word]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def create_one_hot_vector_from_indices(data,maxLen,vocabulary):\n",
    "    one_hot = np.zeros([maxLen,len(vocabulary)])\n",
    "    for i,indice in enumerate(data):\n",
    "        if i >= maxLen:\n",
    "            break\n",
    "        one_hot[i][int(indice)] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def create_one_hot_training_Set(data,maxLen,vocabulary):\n",
    "    one_hot_data = np.zeros([data.shape[0],maxLen,len(vocabulary)])\n",
    "    for i in range(data.shape[0]):\n",
    "        one_hot_data[i] = create_one_hot_vector_from_indices(data[i],maxLen,vocabulary)\n",
    "    return one_hot_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices_glove(X,max_len):\n",
    "    \n",
    "    m = len(X)                                 \n",
    "    \n",
    "    X_indices = np.full([m,max_len],look_up_word(END_WORD))\n",
    "    \n",
    "    for i in range(m):\n",
    "        j = 0\n",
    "        for w in X[i]:\n",
    "            if(j>=max_len):\n",
    "                break;\n",
    "            \n",
    "            X_indices[i, j] = look_up_word(w)\n",
    "            j = j+1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = sentences_to_indices_glove(X_train_comp, max_document_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24547,   6289,     49, 327914,   2205,     17,   3729,     24,\n",
       "          948,     22,     31,     67,   1185,   1194,      7,  38646,\n",
       "           49,   1683,      3,   8308,      6,   5274,    328,    611,\n",
       "            5,     30,     42,    491,      0,      0,   4037,   1151,\n",
       "            4,    989,  15473,   1151,      4,   1628,      8,    427,\n",
       "         5192,      8,  12432,   1185,     26, 200631,      5,  11520,\n",
       "        15403,     27,      5,     23,    110,     33,    183,      7,\n",
       "         1511,   2813,      4,    820,      4,      8,    328,    343,\n",
       "            9,    133,   2047,      5,    215,      4,     13,     99,\n",
       "          255,      3,    447,    971,     34,  10087,      7,     33,\n",
       "            0,   2205,     60,      5,    948,   4668,      7,   8557,\n",
       "          328,   2205,     22, 327914,      8,   2813,    328,   2205,\n",
       "           22,  24547,   6289,      5,   2082,   2205,     17,     32,\n",
       "         3777,      6,    328,   2205,     22,     35,   5726,      7,\n",
       "        10235,    328,   2205,      7,      3,   2173,      6,  35066,\n",
       "          133,  28576,      9,   1251,      5,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2,      2,      2,      2,      2,\n",
       "            2,      2,      2,      2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/BiasAdd:0\", shape=(?, ?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding = tf.get_variable(\"embedding\", initializer=glove)\n",
    "\n",
    "EMBEDDING_DIMENS = glove.shape[1]\n",
    "EMBEDDING_DIMENS\n",
    "\n",
    "\n",
    "d_tokens = tf.placeholder(tf.int32, shape=[None, None], name=\"d_tokens\")\n",
    "d_lengths = tf.placeholder(tf.int32, shape=[None], name=\"d_lengths\")\n",
    "\n",
    "document_emb = tf.nn.embedding_lookup(embedding, d_tokens)\n",
    "document_emb = tf.cast(document_emb, dtype=tf.float64)\n",
    "\n",
    "forward_cell = tf.contrib.rnn.GRUCell(EMBEDDING_DIMENS)\n",
    "backward_cell = tf.contrib.rnn.GRUCell(EMBEDDING_DIMENS)\n",
    "\n",
    "# printdocument_emb, document_lengths, dtype=tf.float64,\n",
    "#     scope=\"answer_rnn\")\n",
    "answer_outputs, _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "    forward_cell, backward_cell, document_emb, d_lengths, dtype=tf.float64,\n",
    "    scope=\"answer_rnn\")\n",
    "\n",
    "answer_outputs = tf.concat(answer_outputs, 2)\n",
    "\n",
    "answer_outputs = tf.cast(answer_outputs,tf.float32)\n",
    "\n",
    "answer_tags = tf.layers.dense(inputs=answer_outputs, units=2)\n",
    "print(answer_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "\n",
    "a_labels = tf.placeholder(tf.int32, shape=[None, None], name=\"answer_labels\")\n",
    "\n",
    "answer_mask = tf.sequence_mask(d_lengths, dtype=tf.float32)\n",
    "\n",
    "answer_loss = seq2seq.sequence_loss(\n",
    "    logits=answer_tags, targets=a_labels, weights=answer_mask, name=\"answer_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_mask = tf.placeholder(\n",
    "    tf.float32, shape=[None, None, None], name=\"encoder_input_mask\")\n",
    "encoder_inputs = tf.matmul(encoder_input_mask, answer_outputs, name=\"encoder_inputs\")\n",
    "encoder_lengths = tf.placeholder(tf.int32, shape=[None], name=\"encoder_lengths\")\n",
    "\n",
    "encoder_cell = tf.contrib.rnn.GRUCell(forward_cell.state_size + backward_cell.state_size)\n",
    "\n",
    "_, encoder_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs, encoder_lengths, dtype=tf.float32, scope=\"encoder_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "decoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"decoder_inputs\")\n",
    "decoder_lengths = tf.placeholder(tf.int32, shape=[None], name=\"decoder_lengths\")\n",
    "\n",
    "decoder_emb = tf.nn.embedding_lookup(embedding, decoder_inputs)\n",
    "decoder_emb = tf.cast(decoder_emb,tf.float32)\n",
    "helper = seq2seq.TrainingHelper(decoder_emb, decoder_lengths)\n",
    "\n",
    "projection = Dense(embedding.shape[0], use_bias=False)\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.GRUCell(encoder_cell.state_size)\n",
    "\n",
    "decoder = seq2seq.BasicDecoder(decoder_cell, helper, encoder_state, output_layer=projection)\n",
    "\n",
    "decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, scope=\"decoder\")\n",
    "decoder_outputs = decoder_outputs.rnn_output\n",
    "\n",
    "decoder_labels = tf.placeholder(tf.int64, shape=[None, None], name=\"decoder_labels\")\n",
    "question_mask = tf.sequence_mask(decoder_lengths, dtype=tf.float32)\n",
    "question_loss = seq2seq.sequence_loss(\n",
    "    logits=decoder_outputs, targets=decoder_labels, weights=question_mask,\n",
    "    name=\"question_loss\")\n",
    "\n",
    "loss = tf.add(answer_loss, question_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def createBatch(inputs,batch_size):\n",
    "    outputs = []\n",
    "    num_batches = math.ceil(len(inputs[0])/batch_size)\n",
    "    for inp in inputs:\n",
    "        start = 0\n",
    "        output = []\n",
    "        for i in range(num_batches-1):\n",
    "            output.append(inp[start:start+batch_size])\n",
    "            start = start + batch_size\n",
    "        output.append(inp[start:])\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss: 13.963656425476074\n",
      "Epoch 2\n",
      "Loss: 13.484329223632812\n",
      "Epoch 3\n",
      "Loss: 13.23073959350586\n",
      "Epoch 4\n",
      "Loss: 13.101560592651367\n",
      "Epoch 5\n",
      "Loss: 12.991990089416504\n",
      "Epoch 6\n",
      "Loss: 12.839831352233887\n",
      "Epoch 7\n",
      "Loss: 12.618654251098633\n",
      "Epoch 8\n",
      "Loss: 12.322699546813965\n",
      "Epoch 9\n",
      "Loss: 11.958627700805664\n",
      "Epoch 10\n",
      "Loss: 11.540685653686523\n",
      "Epoch 11\n",
      "Loss: 11.086235046386719\n",
      "Epoch 12\n",
      "Loss: 10.612228393554688\n",
      "Epoch 13\n",
      "Loss: 10.13328742980957\n",
      "Epoch 14\n",
      "Loss: 9.661137580871582\n",
      "Epoch 15\n",
      "Loss: 9.205367088317871\n",
      "Epoch 16\n",
      "Loss: 8.774435997009277\n",
      "Epoch 17\n",
      "Loss: 8.376317024230957\n",
      "Epoch 18\n",
      "Loss: 8.01809024810791\n",
      "Epoch 19\n",
      "Loss: 7.704444408416748\n",
      "Epoch 20\n",
      "Loss: 7.435925006866455\n",
      "Epoch 21\n",
      "Loss: 7.208330154418945\n",
      "Epoch 22\n",
      "Loss: 7.014032363891602\n",
      "Epoch 23\n",
      "Loss: 6.844691276550293\n",
      "Epoch 24\n",
      "Loss: 6.693664073944092\n",
      "Epoch 25\n",
      "Loss: 6.556618690490723\n",
      "Epoch 26\n",
      "Loss: 6.430759429931641\n",
      "Epoch 27\n",
      "Loss: 6.313986778259277\n",
      "Epoch 28\n",
      "Loss: 6.204593181610107\n",
      "Epoch 29\n",
      "Loss: 6.101380348205566\n",
      "Epoch 30\n",
      "Loss: 6.003833770751953\n",
      "Epoch 31\n",
      "Loss: 5.9121928215026855\n",
      "Epoch 32\n",
      "Loss: 5.827426910400391\n",
      "Epoch 33\n",
      "Loss: 5.750990867614746\n",
      "Epoch 34\n",
      "Loss: 5.684399604797363\n",
      "Epoch 35\n",
      "Loss: 5.6287736892700195\n",
      "Epoch 36\n",
      "Loss: 5.584403991699219\n",
      "Epoch 37\n",
      "Loss: 5.550491809844971\n",
      "Epoch 38\n",
      "Loss: 5.525238037109375\n",
      "Epoch 39\n",
      "Loss: 5.506341457366943\n",
      "Epoch 40\n",
      "Loss: 5.49172830581665\n",
      "Epoch 41\n",
      "Loss: 5.480063438415527\n",
      "Epoch 42\n",
      "Loss: 5.470704078674316\n",
      "Epoch 43\n",
      "Loss: 5.463273048400879\n",
      "Epoch 44\n",
      "Loss: 5.457252025604248\n",
      "Epoch 45\n",
      "Loss: 5.4518141746521\n",
      "Epoch 46\n",
      "Loss: 5.4459638595581055\n",
      "Epoch 47\n",
      "Loss: 5.4387969970703125\n",
      "Epoch 48\n",
      "Loss: 5.429759979248047\n",
      "Epoch 49\n",
      "Loss: 5.418752670288086\n",
      "Epoch 50\n",
      "Loss: 5.406096458435059\n",
      "Epoch 51\n",
      "Loss: 5.392486572265625\n",
      "Epoch 52\n",
      "Loss: 5.378808975219727\n",
      "Epoch 53\n",
      "Loss: 5.365817546844482\n",
      "Epoch 54\n",
      "Loss: 5.35391092300415\n",
      "Epoch 55\n",
      "Loss: 5.343121528625488\n",
      "Epoch 56\n",
      "Loss: 5.3332600593566895\n",
      "Epoch 57\n",
      "Loss: 5.324106693267822\n",
      "Epoch 58\n",
      "Loss: 5.315528392791748\n",
      "Epoch 59\n",
      "Loss: 5.307436943054199\n",
      "Epoch 60\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[100,24,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/TensorArrayStack/TensorArrayGatherV3, gradients/TrainingHelper/transpose_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1594_gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopgradients/Switch_10/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'decoder/transpose', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-5bca2d720020>\", line 16, in <module>\n    decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, scope=\"decoder\")\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 324, in dynamic_decode\n    final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 387, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 387, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 73, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1392, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5762, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,24,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/TensorArrayStack/TensorArrayGatherV3, gradients/TrainingHelper/transpose_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1594_gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopgradients/Switch_10/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,24,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/TensorArrayStack/TensorArrayGatherV3, gradients/TrainingHelper/transpose_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1594_gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopgradients/Switch_10/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1d0ef0b9343c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_input_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdecoder_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdecoder_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     })\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,24,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/TensorArrayStack/TensorArrayGatherV3, gradients/TrainingHelper/transpose_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1594_gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopgradients/Switch_10/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'decoder/transpose', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-5bca2d720020>\", line 16, in <module>\n    decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, scope=\"decoder\")\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 324, in dynamic_decode\n    final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 387, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 387, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 73, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1392, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5762, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100,24,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/TensorArrayStack/TensorArrayGatherV3, gradients/TrainingHelper/transpose_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1594_gradients/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/tuple/control_dependency\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopgradients/Switch_10/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "batch_input = createBatch([document_tokens,document_lengths,answer_labels,answer_masks,answer_lengths,question_input_tokens,question_output_tokens,question_lengths]\n",
    "                    ,32)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch {0}\".format(epoch))\n",
    "    _, loss_value = session.run([optimizer, loss], {\n",
    "        d_tokens: document_tokens,\n",
    "        d_lengths: document_lengths,\n",
    "        a_labels: answer_labels,\n",
    "        encoder_input_mask: answer_masks,\n",
    "        encoder_lengths: answer_lengths,\n",
    "        decoder_inputs: question_input_tokens,\n",
    "        decoder_labels: question_output_tokens,\n",
    "        decoder_lengths: question_lengths,\n",
    "    })\n",
    "    print(\"Loss: {0}\".format(loss_value))\n",
    "#    saver.save(session, \"model\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [9344] vs. [8448]\n\t [[Node: answer_loss/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](answer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits, answer_loss/Reshape_2)]]\n\t [[Node: gradients_1/Add/_78 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_502_gradients_1/Add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_11)]]\n\nCaused by op 'answer_loss/mul', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-c45035e5ebae>\", line 8, in <module>\n    logits=answer_tags, targets=a_labels, weights=answer_mask, name=\"answer_loss\")\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/loss.py\", line 95, in sequence_loss\n    crossent *= array_ops.reshape(weights, [-1])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 907, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2798, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [9344] vs. [8448]\n\t [[Node: answer_loss/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](answer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits, answer_loss/Reshape_2)]]\n\t [[Node: gradients_1/Add/_78 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_502_gradients_1/Add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_11)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9344] vs. [8448]\n\t [[Node: answer_loss/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](answer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits, answer_loss/Reshape_2)]]\n\t [[Node: gradients_1/Add/_78 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_502_gradients_1/Add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_11)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-66c38c110996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mdecoder_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdecoder_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         })\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9344] vs. [8448]\n\t [[Node: answer_loss/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](answer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits, answer_loss/Reshape_2)]]\n\t [[Node: gradients_1/Add/_78 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_502_gradients_1/Add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_11)]]\n\nCaused by op 'answer_loss/mul', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-c45035e5ebae>\", line 8, in <module>\n    logits=answer_tags, targets=a_labels, weights=answer_mask, name=\"answer_loss\")\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/loss.py\", line 95, in sequence_loss\n    crossent *= array_ops.reshape(weights, [-1])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 907, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2798, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [9344] vs. [8448]\n\t [[Node: answer_loss/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](answer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits, answer_loss/Reshape_2)]]\n\t [[Node: gradients_1/Add/_78 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_502_gradients_1/Add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_11)]]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "batch_input = createBatch([document_tokens,document_lengths,answer_labels,answer_masks,answer_lengths,question_input_tokens,question_output_tokens,question_lengths]\n",
    "                    ,32)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    for batchNum in range(len(batch_input[0])):\n",
    "        print(\"Epoch {0}\".format(epoch))\n",
    "        _, loss_value = session.run([optimizer, loss], {\n",
    "            d_tokens: batch_input[0][batchNum],\n",
    "            d_lengths: batch_input[1][batchNum],\n",
    "            a_labels: batch_input[2][batchNum],\n",
    "            encoder_input_mask: batch_input[3][batchNum],\n",
    "            encoder_lengths: batch_input[4][batchNum],\n",
    "            decoder_inputs: batch_input[5][batchNum],\n",
    "            decoder_labels: batch_input[6][batchNum],\n",
    "            decoder_lengths: batch_input[7][batchNum],\n",
    "        })\n",
    "        print(\"Loss: {0}\".format(loss_value))\n",
    "#    saver.save(session, \"model\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# session = tf.Session()\n",
    "\n",
    "# batch = next(test_data())\n",
    "# batch = collapse_documents(batch)\n",
    "\n",
    "answers = session.run(answer_tags, {\n",
    "    d_tokens: document_tokens,\n",
    "    d_lengths: document_lengths,\n",
    "})\n",
    "answers = np.argmax(answers, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 292)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "helper = seq2seq.GreedyEmbeddingHelper(embedding, tf.fill([100], START_TOKEN), END_TOKEN)\n",
    "decoder = seq2seq.BasicDecoder(decoder_cell, helper, encoder_state, output_layer=projection)\n",
    "decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, maximum_iterations=16)\n",
    "decoder_outputs = decoder_outputs.rnn_output\n",
    "\n",
    "\n",
    "questions = session.run(decoder_outputs, {\n",
    "    d_tokens: document_tokens,\n",
    "    d_lengths: document_lengths,\n",
    "    a_labels: answer_labels,\n",
    "    encoder_input_mask: answer_masks,\n",
    "    encoder_lengths: answer_lengths,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siddall\n",
      "systematised\n",
      "saint-inglevert\n",
      "hablar\n",
      "rechnitz\n",
      "3,374\n",
      "dainis\n",
      "eigenspaces\n",
      "sachse\n",
      "hemnes\n",
      "östermalm\n",
      "hombu\n",
      "imposture\n",
      "pdgf\n",
      "marriages\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,16):\n",
    "    print(look_up_token(np.argsort(questions[7][6])[-i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[:,:,UNKNOWN_TOKEN] = 0\n",
    "qs = np.argmax(questions, 2)\n",
    "# qs = np.argsort(questions, 2)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: gams oceanside oceanside scatological 14,250 incredulous incredulous buttala hanigan hanigan silverfish soupe soupe soupe amalgamated mantain\n",
      "Question: server-side krupin 1968/1969 wiliness kenesaw 89.02 groner chiropractors prrs kcie nudist dromaeosaurus castaño piaget oxenbridge oxenbridge\n",
      "Question: 8.44 belterra 8.44 chik postdocs baan baan baan baan t28 reppert rto reppert soldiered salzmann salzmann\n",
      "Question: server-side krupin 1968/1969 tultepec tultepec sako 17-ton nudist warmest hedgpeth vatican carders porte haselden manadel haselden\n",
      "Question: pretournament oceanside payloads wysiwyg kythera kythera cosey sednev leano kakira kakira serological sunchon sunchon benabdellah benabdellah\n",
      "Question: zero-one 6,500-strong air-breathing gear mid-1990 cytological 226-3347 intents kfa anglerfish intents 14,650 intents admm amalgamated 134.25\n",
      "Question: salvors oceanside payloads holtom mcguinness heston instilling x-33 cgg uii servites hallgren valikamam ferko ferko sednev\n",
      "Question: server-side gumbi chaan 8-kilometer seeped rm20 siddall sachse good sabhai bellybuttons anniversay anniversay zarein dmitriyevich dmitriyevich\n",
      "Question: undiscussed 10,000-per brookdale rodda thunter bhanumathi maragondon maragondon morabito bever kakira kakira methodists steffey soldiered advises\n",
      "Question: wagenfeld server-side krupin tultepec sako i-era tultepec kongantiyev celerier 44.25 230,000 assinger 230,000 assinger maunsell hindemith\n",
      "Question: 10,000-per sundstrand 5:18 psychoanalysts maskin soupe soupe soupe kornman nudist cesarean isolators actioner thai-cambodian resending dominy\n",
      "Question: zero-one 16e qayyim darity factbox relational buddhadev phrao sako generalizations dineen dineen flashdance tricolored tricolored prove\n",
      "Question: server-side 10,000-per chud anti-fascist podiatrist duckies duckies zh00r 350-room galoot devender ramdane pasni mejid canaccord worsen\n",
      "Question: wagenfeld 16e yijin reppert 8-kilometer 3.5-litre woob alzano benabdellah kakira benabdellah kakira kakira benabdellah kakira canaccord\n",
      "Question: zero-one eardrum 16e sensationalistic drug-resistant abbe meisters 23-percent rainone 414.00 sogdian mattioli ugueth ugueth maladie mattioli\n",
      "Question: server-side gumbi chaan anti-fascist liturgics iph omero cesarean midden haymaker isolators isolators haymaker pierantoni dyslexia zanardelli\n",
      "Question: appelfeld server-side krupin reliford 1968/1969 metier governement governement alcestis governement 8.3 woerns bonderman kachkar kachkar reppert\n",
      "Question: trepidation caunter 406 sibbald avra pythium corroborates timea straker canaccord worsen seraph belladonna seraph estadual edgemere\n",
      "Question: 16e qayyim gobar pzn saville kamloops vagenas kakira kakira serological serological sunchon zeneca 42-point sunchon sunchon\n",
      "Question: zero-one 15,800 89.02 89.02 contax mickaël kamloops lios lios lios sherbini sherbini consultancies sarath gai ugueth\n",
      "Question: wagenfeld sd1 anti-fascist widely bruhn 406 refereeing faceoffs ugur avici russo-turkish ugur qg4 andika colorimetric musō-ryū\n",
      "Question: 10,000-per 10,000-per anti-fascist brookdale 1,072 lordstown per-game per-game autumnalis triops triops benabdellah hayono callister obliges cognizant\n",
      "Question: 10,000-per 10,000-per brookdale rodda anti-fascist rainstorm ljusdal (650) presenter mid-state beachfronts beachfronts cochinchina balck nudist sarath\n",
      "Question: gams kongwa gattison benabdellah reppert benabdellah kakira kakira benabdellah kakira kakira fichter benabdellah mariann kakira fichter\n",
      "Question: 10,000-per 10,000-per anti-fascist brookdale 1,072 lordstown per-game per-game autumnalis ruzyne lion-o lion-o lion-o lion-o renos lion-o\n",
      "Question: 16e qayyim gobar pzn lubet khorafi barnicle eggplant succeeded soignies bubacar kakira kakira kakira serological skillets\n",
      "Question: 16e qayyim gobar pzn saville kamloops vagenas kakira kakira serological serological sunchon zeneca dubawi zeneca 1.500\n",
      "Question: grandeau server-side krupin chud climatically kujat eggplant lensky lensky hemlock swin roading roading inglewood fissurellidae indexical\n",
      "Question: 10,000-per brookdale rodda thunter bhanumathi maragondon maragondon morabito kakira kakira methodists wiznia watashi katy seraph prrs\n",
      "Question: zero-one clutterbuck holtom ulchi holtom vanishing anti-fascist barter norse-gaelic zooplankton iridium 112-109 hayono hayono cimorelli nudist\n",
      "Question: clutterbuck redecorate lebar gouger allotment 345 botsaris encyclical karges archrivals karges murasu adjutant-general kakira kakira then-reigning\n",
      "Question: 10,000-per sd1 sd1 anti-fascist blockings blockings 2,050-mile cesarean beryl podemos amenities haud actioner thai-cambodian cynda orangi\n",
      "Question: wagenfeld wagenfeld sd1 anti-fascist barter kaiserslautern technophile epigram demmin demmin mahender 2408 soldiered roseus drupes sager\n",
      "Question: wagenfeld wagenfeld pr4 jablin bekker soldiered soldiered crutches crutches errupted unionised hongxia segway earrings ijf ijf\n",
      "Question: flukes chaan chaan vii vii bathinda margerie 34-9 kwari quidam trieu anka mukomberanwa mukomberanwa mukomberanwa nyimpine\n",
      "Question: 16e qayyim gobar pzn saville kamloops vagenas kakira kakira serological serological sunchon zeneca 42-point sunchon sunchon\n",
      "Question: clutterbuck 16e redecorate contax kakira kakira kakira serological skillets camoys cluytens appletree appletree hemoglobinuria shifter anglerfish\n",
      "Question: server-side krupin parton prostitute inglehart montaño eggplant mao-b endzone thai-cambodian 25-50 sachse sachse triops triops triops\n",
      "Question: zero-one clutterbuck 16e benabdellah reppert benabdellah kakira kakira benabdellah kakira kakira fichter benabdellah mariann kakira kakira\n",
      "Question: 16e qayyim gobar pzn saville kamloops vagenas kakira kakira serological serological sunchon zeneca dubawi zeneca 1.500\n",
      "Question: undiscussed 48,400 6,500-strong serological 12.5-percent air-breathing cesium poque hayono mongrain offending göta 1,822 goemon pasifika pasifika\n",
      "Question: 16e qayyim gobar pzn saville kamloops vagenas kakira kakira serological serological sunchon zeneca dubawi zeneca 1.500\n",
      "Question: wagenfeld server-side avra pythium thai-cambodian 400-year 400-year 400-year demmin aunor 65.51 dalston turnpiked androgyny turnpiked poque\n",
      "Question: kosecki server-side flicked berset cimorelli kwasi eggplant u.s.-run passman passman maliana arzuiyeh featherless anka teochew oxenbridge\n",
      "Question: wagenfeld server-side krupin administered r.e.d. tailplane jacquie mcilvanney mcilvanney circles navision excite 144-nation lý nudist simatupang\n",
      "Question: wagenfeld 16e yoong 48,400 ramian reppert x0 x0 kaleme.com 480-seat prokopovich colorimetric poggibonsi heiden tomac sharna\n",
      "Question: flukes chaan redecorate sd1 mirallas farside olinger truan truan caledonia ml riffage ʻo kyōto 4.97 manavgat\n",
      "Question: danesi laroque 89.02 89.02 bouvard kakira kakira serological sunchon sunchon serological sunchon advising umrg 60.49 criss-cross\n",
      "Question: zero-one 15,800 walesa quadripartite bicyclist monoplane madcon golijov trebinje 1987-92 naral naral modulates modulates holding 1,475\n",
      "Question: wagenfeld ecuadoran multi-story whakaari sanlucar 1720 shaobin five-term 50-0 39.63 39.63 scheller x0 grenadines mapreduce 2,306\n",
      "Question: moratoriums 10,000-per moratoriums activating geveden botwood appletree appletree dramaturg dramaturg setyadi reoccupies stolzenberg canaccord worsen edgemere\n",
      "Question: server-side gumbi chaan benabdellah benabdellah reppert benabdellah reppert benabdellah reppert paluxy benabdellah reppert bakken vatutin vatutin\n",
      "Question: 10,000-per ratterman anti-fascist 25.1 interdental fallin serghei raciest salmo 2,306 big-headed xenophobic portchester ll.d rapino i860\n",
      "Question: wagenfeld server-side avra timea avra pythium mix pythium stipends umeed umeed umeed re-connect pasni pasni lml\n",
      "Question: kosecki oleksandr oleksandr quadripartite quadripartite skimps casaroli casaroli upmann upmann hayono ibuka hayono ibuka reppert air-breathing\n",
      "Question: wagenfeld 16e yoong 48,400 blackbushe kakira kakira kakira kakira fichter 345 sachse 345 obrenovic binnenhof homers\n",
      "Question: 10,000-per brookdale sadar kcynia 121.70 glatfelter glatfelter glatfelter good 47,700 rainstorm zoysa dki 32,250 hanner polyptych\n",
      "Question: episkopi 10,000-per 1720 benefitted sagala modlin kakira serological yung-jan terron mariann kakira kakira kakira methodists ilbe\n",
      "Question: 10,000-per geotagging multitrillion barnicle hakkar rainbo jtm nudist sachse eggplant nitrofurans humorless vatican tsusho oxenbridge boonjong\n",
      "Question: moratoriums sun shiism petrossian koroškem 140kg grigoris shui-bian dmelvin upmann serological oxenbridge tunings mbongo sunchon benabdellah\n",
      "Question: 10,000-per 10,000-per brookdale rodda anti-fascist sfac yung-jan chessell ugueth ugueth maladie maladie ugueth maladie kayastha 12.5-percent\n",
      "Question: edges caunter temps bougouni bougouni memetics memetics 15-square nudist sarath flits halme 65.66 eisenstat vanishing us-64\n",
      "Question: clutterbuck 16e benabdellah bombyx execution-style mid-1981 www.chron.com appletree appletree hemoglobinuria nudist littlest littlest salads ouston yarrow\n",
      "Question: server-side gumbi avra pythium imts umeed umeed murph 345 cavafy cavafy port-city yagüe 41-30 hayono hayono\n",
      "Question: server-side krupin egerszegi cumpston cumpston morrígan morrígan morrígan morrígan morrígan morrígan cellophane heleno chrisostomides chrisostomides mukomberanwa\n",
      "Question: danesi limning 89.02 89.02 eeriest stepover stepover maragondon yung-jan zhupina produces triumvirs triumvirs triumvirs 149.5 149.5\n",
      "Question: wagenfeld 16e yoong 48,400 ramian reppert lundstrom antipasto reppert rto reppert mbongo mbongo villingen benabdellah reppert\n",
      "Question: undiscussed 10,000-per brookdale barnicle comyns factbox shahbandar podemos pendennis sager eggplant steffey soldiered soldiered directs 2-liter\n",
      "Question: server-side gumbi avra pythium nonresistance 8-kilometer pythium nudist photoshop swizz particular climactic climactic courtesan crossbreed crossbreed\n",
      "Question: 15,800 caunter 89.02 tedrow 89.02 eeriest stepover stepover maragondon yung-jan zhupina ugueth ugueth maladie maladie mattioli\n",
      "Question: zero-one sompit 89.02 89.02 harket 89.02 eeriest svartzman stepover udp amicability amicability pasni pasni knute knute\n",
      "Question: zero-one 10,000-per toomas bicyclist zhenyu .0208 .0208 .0208 mais etchecolatz 2408 2408 intramuros intramuros bonins nsca\n",
      "Question: 16e payerne payerne eap glenfiddich contreras 182-nation antipasto unresponsive beachfronts participates yanzhao haavard hgtv leano annigoni\n",
      "Question: 10,000-per 10,000-per brookdale rodda anti-fascist rainstorm ljusdal rovin news.release 95.46 tondena pasni pasni steamrolled pasni lml\n",
      "Question: 17:16 gobar play-out alfre 80.64 sensed idleness fifty-fourth co-co x0 x0 colorimetric michalik ayodele m41 qutab\n",
      "Question: wagenfeld sd1 rutsweiler anti-fascist timea expansionists 202-383-7824 53.62 202-383-7824 lambeg 4.97 polychlorinated polychlorinated bensayah fgd fgd\n",
      "Question: wagenfeld 10,000-per brookdale rodda intersession appletree appletree porte blather blather blather saehan 11-4 52.01 khasi glatfelter\n",
      "Question: server-side krupin parton lyft alouette imposture ilhéu cd34 hemoglobinuria 3,429 3,429 shifter cicala cicala cicala cicala\n",
      "Question: server-side gumbi 1968/1969 pythium nonresistance produces chillies calfo 2007-11 2007-11 2007-11 nudist ugueth ugueth ugueth maladie\n",
      "Question: 15,800 dekabank dekabank dekabank orona longwang female rank pskov-747 hypnotics yousry matsusaka matsusaka makallah inba benabdellah\n",
      "Question: danesi mattoli kwanwoo slv slv retranslated mantz mantz parfait eggplant orchestrates keatley rapidkl balabagan buschbacher balabagan\n",
      "Question: zero-one 15,800 relational trichomes andover 67.13 strophic cholistan mitrajaya povich pagnotta 5:14 tice turman 413 kaleme.com\n",
      "Question: wagenfeld server-side 1968/1969 songo 89.02 groner groner 345 sachse ahrt ahrt 20-storey morrisette kohonen reppert vanishing\n",
      "Question: grandeau sd1 sd1 anti-fascist blockings blockings sayar ibuka 3,026 pan-hellenic triumvirs triumvirs woodborough watashi falsetti divebomb\n",
      "Question: zero-one 15,800 walesa asme asme 200-yard 200-yard kultur crusts chkalovsky yuchen yagüe yagüe headlocks yagüe headlocks\n",
      "Question: wagenfeld sd1 wexham beetham anti-fascist 18:15 bagot kwip watashi coldly tufano vovinam endomorphisms aeschylus unequalled unequalled\n",
      "Question: episkopi 16e gobar 2710 sensed timea 28.85 avra podemos colorimetric oncogene lovable brazenness mdfm oishi faysal\n",
      "Question: server-side 10,000-per scienze multitrillion 1980s-1990s 3,374 3,374 3,374 pasni pasni pasni verbose kulikowski kulikowski .909 soldiered\n",
      "Question: pretournament newspapers auric diacritic strikeouts_clemens strikeouts_clemens strikeouts_clemens strikeouts_clemens strikeouts_clemens kamehameha fragilis 9in kilkivan 9in sachse sachse\n",
      "Question: schildkraut 10,000-per anti-fascist cracklings 18:15 18:15 championship giffard boose meandering x0 x0 x0 39.88 x0 39.88\n",
      "Question: server-side krupin 1968/1969 tultepec sako snout-vent kakira kakira kakira fichter kakira 345 sachse obrenovic glatfelter soldiered\n",
      "Question: 10,000-per 10,000-per brookdale rodda factbox overage bitless salmo kayastha kayastha 12.5-percent air-breathing realdvd altoon hayono sasi\n",
      "Question: clutterbuck 16e benabdellah benabdellah machine-gunners reppert kakira benabdellah kakira kakira benabdellah kakira fichter benabdellah mariann kakira\n",
      "Question: 11-run geertruidenberg wanka barnicle karpov astrology vols inflaming bendahara 444-2364 444-2364 12-fold simitsek whimper polluter zhelyu\n",
      "Question: zero-one 10,000-per anti-fascist 25.1 whitbourne ecos thai-cambodian reppert antipasto steffey mid-1942 mid-1942 chegwidden nakpil soldiered segway\n",
      "Question: danesi caughman caughman barnicle eggplant soignies eggplant preciso succeeded flyleaf silverheels tonie yolande conservatoire 88-87 95.93\n",
      "Question: undiscussed 10,000-per brookdale rodda factbox briber benabdellah reppert locard benabdellah eggplant beachfronts 4.97 reppert villingen 4.97\n",
      "Question: zero-one 16e 6,500-strong apud katy katy 355,000 prrs caerphilly américo américo surman jurcic hairier faroe bernis\n",
      "Question: flukes chaan chaan gudea benabdellah reppert benabdellah reppert rs500 vatutin chagos ugueth ugueth maladie maladie ugueth\n",
      "Question: zero-one 15,800 revolution otmuchów thorne uncontested duels sedoc uson uson 110.60 shots keeve ihedigbo kodam kodam\n"
     ]
    }
   ],
   "source": [
    "# q = set()\n",
    "l = []\n",
    "for i in range(100):\n",
    "    question = itertools.takewhile(lambda t: t != END_TOKEN, qs[i])\n",
    "#     l.append([look_up_token(token) for token in question])\n",
    "#     a =  \" \".join(look_up_token(token) for token in question)\n",
    "    print(\"Question: \" + \" \".join(look_up_token(token) for token in question))\n",
    "#     print(\"Answer: \" + batch[\"answer_text\"][i])\n",
    "# q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
