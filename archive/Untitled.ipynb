{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"/home/ra2630/NLU/nlu-qgen-project/src/models.py\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, wt_params):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        self.input_size, self.output_size = wt_params.shape\n",
    "        self.embedding = nn.Embedding(self.input_size, self.output_size)\n",
    "        \n",
    "        # TODO: Verify\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(wt_params).float())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "class BaseRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(BaseRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first= True, bidirectional=self.bidirectional)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "class DocumentEncoder(BaseRNN):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(DocumentEncoder, self).__init__(input_size, hidden_size, num_layers, bidirectional)\n",
    "        self.output_size = self.hidden_size*2\n",
    "        self.fc = nn.Linear(self.output_size, 1)\n",
    "\n",
    "    def forward(self,x ,h):\n",
    "        o, h = self.gru(x, h)\n",
    "        x = self.fc(o)\n",
    "        x = F.sigmoid(x)\n",
    "        return x, o, h\n",
    "\n",
    "class QuestionDecoder(BaseRNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, bidirectional=False):\n",
    "        super(QuestionDecoder, self).__init__(input_size, hidden_size, num_layers, bidirectional)\n",
    "        self.fc = nn.Linear(input_size, output_size) \n",
    "\n",
    "    def forward(self, x, h):\n",
    "        o, h = self.gru(x, h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"/home/ra2630/NLU/nlu-qgen-project/src/main.py\"\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# Core modules\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# 3rd party modules\n",
    "import torch\n",
    "\n",
    "# Custom modules\n",
    "from models import *\n",
    "from data_utils import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch QGen')\n",
    "parser.add_argument('--num_epochs', default=100, type=int,\n",
    "                    help='number of training epochs')\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help='Random Seed')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='Batch Size')\n",
    "parser.add_argument('--gpu', action='store_true', default=False,\n",
    "                    help='Use GPU')\n",
    "# Dataset related\n",
    "parser.add_argument('--train_data', default='../train-v1.1.json', type=str,\n",
    "                    help='path to train data')\n",
    "parser.add_argument('--words_to_take', type=int, default=2000,\n",
    "                    help='Size of reduced Glove (use 0 for full)')\n",
    "parser.add_argument('--load_data', default='', type=str,\n",
    "                    help='Load pickled data')\n",
    "parser.add_argument('--save_data', default='', type=str,\n",
    "                    help='save pickled data')\n",
    "parser.add_argument('--reduced_glove', action='store_true', default=False,\n",
    "                    help='whether to use reduced_glove')\n",
    "parser.add_argument('--example_to_train', type=int, default=1000,\n",
    "                    help='example taken to train')\n",
    "parser.add_argument('--split_ratio', type=float, default=0.8,\n",
    "                    help='ratio of training data')\n",
    "\n",
    "# Hyperparameters\n",
    "parser.add_argument('--hidden_size', type=int, default=300,\n",
    "                    help='RNN hidden size')\n",
    "parser.add_argument('--lr', type=float, default=3e-4,\n",
    "                    help='Learning rate')\n",
    "parser.add_argument('--tf_ratio', type=float, default=1.0,\n",
    "                    help='Teacher Forcing Ratio')\n",
    "# Model\n",
    "parser.add_argument('--save', default='', type=str,\n",
    "                    help='save the model after training')\n",
    "parser.add_argument('--load', default='', type=str,\n",
    "                    help='load the model')\n",
    "parser.add_argument('--no_train', action='store_true', default=False,\n",
    "                    help=\"don't start training\")\n",
    "parser.add_argument('--no_eval', action='store_true', default=False,\n",
    "                    help=\"don't evaluate\")\n",
    "parser.add_argument('--gen', action='store_true', default=False,\n",
    "                    help=\"Generate Questions\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "args.gpu = args.gpu and torch.cuda.is_available()\n",
    "\n",
    "_word_to_idx = {}\n",
    "_idx_to_word = []\n",
    "\n",
    "if args.load_data != '':\n",
    "    batches, num_batches, glove, _word_to_idx, _idx_to_word = load_obj(args.load_data)\n",
    "else:\n",
    "    batches, num_batches, glove, _word_to_idx, _idx_to_word = data_parse(args)\n",
    "    if args.save_data != '':\n",
    "        save_obj((batches, num_batches, glove, _word_to_idx, _idx_to_word), args.save_data)\n",
    "\n",
    "print(\"Number of batches = \", num_batches)\n",
    "def look_up_word(word):\n",
    "    return _word_to_idx.get(word, UNKNOWN_TOKEN)\n",
    "\n",
    "def look_up_token(token):\n",
    "    return _idx_to_word[token]\n",
    "\n",
    "\n",
    "# Input: word token -> embedding\n",
    "embedder = WordEmbedder(glove)\n",
    "# embedding +ans -> ans_pred, encoded_doc, encoded_doc_h (2 * given hidden due to biLSTM)\n",
    "doc_encoder = DocumentEncoder(embedder.output_size + 1, args.hidden_size, num_layers=1, bidirectional=True)\n",
    "# encoded_doc, encoded_doc_h -> doubly encoded_doc, doubly_encoded_doc_h\n",
    "q_encoder = BaseRNN(doc_encoder.output_size, 2*args.hidden_size)\n",
    "# Most experimentation would be in input to DECODER\n",
    "# doubly_encoded_doc_h + (context vec + encoder hidden), q_embedding -> qgen_dec_pred, qgen_dec_h\n",
    "q_decoder = QuestionDecoder(embedder.output_size, 2*args.hidden_size, embedder.input_size)\n",
    "\n",
    "\n",
    "train_params = [ *list(doc_encoder.parameters()), *list(q_encoder.parameters()), *list(q_decoder.parameters()) ]\n",
    "optimizer = torch.optim.Adam(train_params, lr=args.lr)\n",
    "a_criterion = nn.BCELoss()\n",
    "q_criterion = nn.NLLLoss()\n",
    "\n",
    "def train_epoch(train_data, epoch):\n",
    "    doc_encoder.train()\n",
    "    q_encoder.train()\n",
    "    q_decoder.train()\n",
    "\n",
    "    print(\"No. of batches in training data: {}, with batch_size: {} \".format(len(train_data), len(train_data[0]['document_tokens'])))\n",
    "    epoch_begin_time = time.time()\n",
    "    avg_loss= 0\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # assert batch size\n",
    "        batch_size = len(batch['document_tokens'])\n",
    "        if  batch_size != args.batch_size:\n",
    "            print(\"Skipping batch {} due batch size mismatch.\".format(i))\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make hidden zero for doc encoder\n",
    "        dim1 = 2 if doc_encoder.bidirectional else 1\n",
    "        doc_encoder_h = Variable(torch.zeros(dim1, batch_size, doc_encoder.hidden_size))\n",
    "\n",
    "        # TODO: Doc mask & Question Mask\n",
    "        # t_document_mask = Variable(torch.from_numpy(mask)).float()\n",
    "        # mask for extra length of doc\n",
    "        # doc_mask = torch.from_numpy(batch['doc_mask'])\n",
    "\n",
    "        # Supervised Learning of \"part of Answer\" prediction\n",
    "        doc_token = Variable(torch.from_numpy(batch['document_tokens']))\n",
    "        answer_target = Variable(torch.from_numpy(batch['answer_labels']).float())\n",
    "\n",
    "        doc_embeddings = embedder(doc_token)\n",
    "        # Adding additional dim. with answer tags\n",
    "        doc_ans_embedding = torch.cat((doc_embeddings,answer_target.unsqueeze(-1)),dim=-1)\n",
    "\n",
    "        answer_pred, doc_encoded, doc_encoder_h = doc_encoder(doc_ans_embedding, doc_encoder_h)\n",
    "        a_loss = a_criterion(answer_pred.squeeze(), answer_target)\n",
    "\n",
    "        q_embedded_in = embedder(torch.from_numpy(batch[\"question_input_tokens\"]).long())\n",
    "        q_target = Variable(torch.from_numpy(batch[\"question_output_tokens\"]).long())\n",
    "\n",
    "        # Pass encoder hidden\n",
    "        q_decoder_h = doc_encoder_h.view(1, batch_size, -1)\n",
    "\n",
    "        # Set q_loss = 0 for batch\n",
    "        q_loss = 0\n",
    "        for q_len in range(q_embedded_in.shape[1]):\n",
    "            q_decoder_out, q_decoder_h =  q_decoder(q_embedded_in[:,q_len:q_len+1,:], q_decoder_h)\n",
    "            q_loss += q_criterion(q_decoder_out.squeeze(), q_target[:,q_len:q_len+1].squeeze())\n",
    "\n",
    "        # loss = q_loss + a_loss\n",
    "        loss = q_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss+= loss.data[0]\n",
    "\n",
    "        print ('Batch: %d \\t Epoch : %d\\tNet Loss: %.4f \\tAnswer Loss: %.4f \\tQuestion Loss: %.4f'\n",
    "               %(i, epoch, loss.data[0], a_loss.data[0], q_loss.data[0]))\n",
    "\n",
    "    print('Average Loss after Epoch %d : %.4f' %(epoch, avg_loss/num_batches))\n",
    "    print(\"Epoch time: {:.2f}s\".format(time.time() - epoch_begin_time))\n",
    "\n",
    "\n",
    "def evaluate(data, generate=False):\n",
    "    print(\"Evaluating:\")\n",
    "    doc_encoder.eval()\n",
    "    q_encoder.eval()\n",
    "    q_decoder.eval()\n",
    "\n",
    "    if generate:\n",
    "        max_q_len = data[0][\"question_input_tokens\"].shape[1]\n",
    "        q_gen = {'gt':np.full((len(data),args.batch_size,max_q_len),'<END>',dtype=object),\n",
    "                 'tf_gen':np.full((len(data),args.batch_size,max_q_len),'<END>',dtype=object),\n",
    "                'full_gen':np.full((len(data),args.batch_size,max_q_len),'<END>',dtype=object),\n",
    "                 }\n",
    "\n",
    "    eval_begin_time = time.time()\n",
    "    batch_loss = 0\n",
    "    for i, batch in enumerate(data):\n",
    "        # assert batch size\n",
    "        batch_size = len(batch['document_tokens'])\n",
    "        if batch_size != args.batch_size:\n",
    "            continue\n",
    "\n",
    "        # make hidden zero for doc encoder\n",
    "        dim1 = 2 if doc_encoder.bidirectional else 1\n",
    "        doc_encoder_h = Variable(torch.zeros(dim1, batch_size, doc_encoder.hidden_size))\n",
    "\n",
    "        # Supervised Learning of \"part of Answer\" prediction\n",
    "        doc_token = Variable(torch.from_numpy(batch['document_tokens']))\n",
    "        answer_target = Variable(torch.from_numpy(batch['answer_labels']).float())\n",
    "        doc_embeddings = embedder(doc_token)\n",
    "        # Adding additional dim. with answer tags\n",
    "        doc_ans_embedding = torch.cat((doc_embeddings,answer_target.unsqueeze(-1)),dim=-1)\n",
    "\n",
    "        answer_pred, doc_encoded, doc_encoder_h = doc_encoder(doc_ans_embedding, doc_encoder_h)\n",
    "        a_loss = a_criterion(answer_pred.squeeze(), answer_target)\n",
    "\n",
    "        # setting up decoder inputs and outputs\n",
    "        q_in_tf = batch[\"question_input_tokens\"]\n",
    "        q_in_gen = np.full(q_in_tf[:,0].shape, look_up_word(\"<START>\"))\n",
    "\n",
    "        q_embedded_in_tf = embedder(torch.from_numpy(q_in_tf).long())\n",
    "        q_embedded_in_gen = embedder(torch.from_numpy(q_in_gen).long()).unsqueeze(1)\n",
    "        q_target = Variable(torch.from_numpy(batch[\"question_output_tokens\"]).long())\n",
    "\n",
    "        # Pass encoder hidden\n",
    "        q_decoder_h = doc_encoder_h.view(1, batch_size, -1)\n",
    "        # 2 hidden vectors for teacher forcing and fully generated\n",
    "        q_decoder_h_tf = q_decoder_h.clone()\n",
    "        q_decoder_h_gen = q_decoder_h.clone()\n",
    "\n",
    "        # Set q_loss = 0 for batch\n",
    "        q_loss_tf = 0\n",
    "        q_loss_gen = 0\n",
    "        for q_len in range(q_embedded_in_tf.shape[1]):\n",
    "            # teacher forcing\n",
    "            q_decoder_out_tf, q_decoder_h_tf =  q_decoder(q_embedded_in_tf[:,q_len:q_len+1,:], q_decoder_h_tf)\n",
    "            # full gen:\n",
    "            q_decoder_out_gen, q_decoder_h_gen =  q_decoder(q_embedded_in_gen, q_decoder_h_gen)\n",
    "            q_out = np.argmax(q_decoder_out_gen.squeeze().data.numpy(), axis=1)\n",
    "            q_in_gen = torch.from_numpy(q_out).long()\n",
    "            q_embedded_in_gen = embedder(q_in_gen).unsqueeze(1)\n",
    "\n",
    "            # losses\n",
    "            q_loss_tf += q_criterion(q_decoder_out_tf.squeeze(), q_target[:,q_len:q_len+1].squeeze())\n",
    "            q_loss_gen += q_criterion(q_decoder_out_gen.squeeze(), q_target[:,q_len:q_len+1].squeeze())\n",
    "\n",
    "            # storing for printing later\n",
    "            if generate:\n",
    "                q_gen['gt'][i,:,q_len] = np.array([look_up_token(j) for j in q_in_tf[:,q_len]])\n",
    "                q_gen['full_gen'][i,:,q_len] = np.array([look_up_token(j) for j in q_out])\n",
    "\n",
    "                q_out = np.argmax(q_decoder_out_tf.squeeze().data.numpy(), axis=1)\n",
    "                q_gen['tf_gen'][i,:,q_len] = np.array([look_up_token(j) for j in q_out])\n",
    "\n",
    "\n",
    "        print ('Batch: %d\\tQuestion Loss (teacher forcing): %.4f\\tQuestion Loss (full generated): %.4f'\n",
    "                   %(i, q_loss_tf.data[0], q_loss_gen.data[0]))\n",
    "\n",
    "        batch_loss+= q_loss_gen.data[0]\n",
    "\n",
    "    print('Average loss (full gen): %.4f' %( batch_loss/len(data)))\n",
    "        # TODO: Eval Gen\n",
    "    print(\"Eval time: {:.2f}s\".format(time.time() - eval_begin_time))\n",
    "    if generate:\n",
    "        display_generated(q_gen)\n",
    "\n",
    "\n",
    "def save(path):\n",
    "    d = dict()\n",
    "    # d['log'] = log\n",
    "    d['doc_encoder'] = doc_encoder.state_dict()\n",
    "    d['q_encoder'] = q_encoder.state_dict()\n",
    "    d['q_decoder'] = q_decoder.state_dict()\n",
    "    d['optimizer'] = optimizer.state_dict()\n",
    "    torch.save(d, path)\n",
    "\n",
    "def load(path):\n",
    "    d = torch.load(path)\n",
    "    # log.clear()\n",
    "    doc_encoder.load_state_dict(d['doc_encoder'])\n",
    "    q_encoder.load_state_dict(d['q_encoder'])\n",
    "    q_decoder.load_state_dict(d['q_decoder'])\n",
    "    optimizer.load_state_dict(d['optimizer'])\n",
    "    # log.update(d['log'])\n",
    "    # trainer.load_state_dict(d['trainer'])\n",
    "\n",
    "\n",
    "if args.load != '':\n",
    "    load(args.load)\n",
    "\n",
    "split = int(args.split_ratio * len(batches))\n",
    "\n",
    "if not args.no_train:\n",
    "    for ep in range(args.num_epochs):\n",
    "        train_epoch(batches[:split], ep)\n",
    "        # Eval after each epoch from randomly chosen batch of val set\n",
    "        b = [np.random.choice(batches[split:-1])]\n",
    "        evaluate(b, generate=False)\n",
    "\n",
    "if args.save != '':\n",
    "    save(args.save)\n",
    "\n",
    "# Eval & generate questions\n",
    "if not args.no_eval:\n",
    "    evaluate(batches[split:], generate=args.gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
