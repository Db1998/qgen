{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LC_ALL=en_US.UTF-8\n",
    "!CUDA_VISIBLE_DEVICES=2\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from pprint import pprint\n",
    "import re\n",
    "import numpy as np\n",
    "from embedding import *\n",
    "import nltk\n",
    "import itertools\n",
    "import random\n",
    "np.random.seed(0)\n",
    "orig_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../train-v1.1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "nltkStopWords = stopwords.words('english')\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(data):\n",
    "    contexts = []\n",
    "    qas = []\n",
    "    for i in range(len(data[\"data\"])):\n",
    "        for j in range(len(data[\"data\"][i][\"paragraphs\"])):\n",
    "            contexts.append(data[\"data\"][i][\"paragraphs\"][j][\"context\"])\n",
    "            qas.append(data[\"data\"][i][\"paragraphs\"][j][\"qas\"])\n",
    "    return (contexts,qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapPassage = False\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "contexts,qas = extractor(data)\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            return ind,ind+sll\n",
    "    return (-1,-1)\n",
    "\n",
    "def capPassage(passage,answer,cap_length = 30):\n",
    "    y = np.zeros(cap_length)\n",
    "    left,right = find_sub_list(answer,passage)\n",
    "    if(left==-1):\n",
    "        return passage[0:cap_length]\n",
    "    left = left - int((cap_length - len(answer))/2)\n",
    "    right = right + int((cap_length + len(answer))/2)\n",
    "    if(left < 0):\n",
    "        left = 0\n",
    "    if(right > len(passage)):\n",
    "        right = len(passage)\n",
    "    return passage[left:right]\n",
    "    \n",
    "def findAnsVec(answer,passage):\n",
    "    ans = np.zeros((len(passage)))\n",
    "    start,end = find_sub_list(answer,passage)\n",
    "    if(start==-1):\n",
    "        start = passage.index(answer[0])\n",
    "        end = start + len(answer)\n",
    "    ans[start:end] = 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_comp_all = []\n",
    "X_train_comp_ans_all = []\n",
    "X_train_ans_all = []\n",
    "Y_train_ques_all = []\n",
    "invalid = 0\n",
    "X_train_ans_label_all = []\n",
    "for i,context in enumerate(contexts):\n",
    "    passage = word_tokenize(context.lower())\n",
    "    \n",
    "    a_lab = np.zeros(len(passage))\n",
    "    for j,_ in enumerate(qas[i]):\n",
    "        answer = word_tokenize(qas[i][j][\"answers\"][0]['text'].lower())\n",
    "        start,end = find_sub_list(answer,passage)\n",
    "        if start == -1:\n",
    "            continue\n",
    "        a_lab[start:end+1] = 1\n",
    "            \n",
    "            \n",
    "    for j,_ in enumerate(qas[i]):\n",
    "        try:\n",
    "            question = word_tokenize(qas[i][j]['question'].lower())\n",
    "            answer = word_tokenize(qas[i][j][\"answers\"][0]['text'].lower())\n",
    "            \n",
    "            if CapPassage:\n",
    "                cappedPassage = capPassage(passage,answer)\n",
    "            else:\n",
    "                cappedPassage = passage\n",
    "            \n",
    "            X_train_comp_ans_all.append(findAnsVec(answer,passage))\n",
    "            X_train_ans_label_all.append(a_lab)\n",
    "            X_train_comp_all.append(cappedPassage)\n",
    "            X_train_ans_all.append(answer)\n",
    "            Y_train_ques_all.append(question)\n",
    "        except Exception as e:\n",
    "            invalid = invalid+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "def findKMostFrequentWords(k):\n",
    "    ctr = Counter([item for sublist in X_train_comp_all for item in sublist] + [item for sublist in Y_train_ques_all for item in sublist])\n",
    "    sorted_ctr = sorted(ctr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return [item[0] for item in sorted_ctr[0:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsToTake = 80000\n",
    "words = findKMostFrequentWords(400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102979"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_word_to_idx_reduced = {}\n",
    "_idx_to_word_reduced = []\n",
    "\n",
    "\n",
    "def _add_word_reduced(word):\n",
    "    idx = len(_idx_to_word_reduced)\n",
    "    _word_to_idx_reduced[word] = idx\n",
    "    _idx_to_word_reduced.append(word)\n",
    "    return idx\n",
    "\n",
    "\n",
    "PAD_TOKEN = _add_word_reduced(PAD_WORD)\n",
    "UNKNOWN_TOKEN = _add_word_reduced(UNKNOWN_WORD)\n",
    "START_TOKEN = _add_word_reduced(START_WORD)\n",
    "END_TOKEN = _add_word_reduced(END_WORD)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dimensions = glove.shape[1]\n",
    "reduced_glove = []\n",
    "reduced_glove.append(np.zeros(dimensions))\n",
    "reduced_glove.append(-np.ones(dimensions))\n",
    "reduced_glove.append(np.ones(dimensions))\n",
    "\n",
    "for word in words:\n",
    "    l = look_up_word(word)\n",
    "    if(l != UNKNOWN_TOKEN):\n",
    "        idx = _add_word_reduced(word)\n",
    "        reduced_glove.append(glove[l])\n",
    "    if(len(reduced_glove) == wordsToTake):\n",
    "        break\n",
    "        \n",
    "def look_up_word_reduced(word):\n",
    "    return _word_to_idx_reduced.get(word, UNKNOWN_TOKEN)\n",
    "\n",
    "\n",
    "def look_up_token_reduced(token):\n",
    "    return _idx_to_word_reduced[token]\n",
    "\n",
    "reduced_glove = np.array(reduced_glove)\n",
    "reduced_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda2.cims.nyu.edu\n",
      "1493\n",
      "rev . john j. cavanaugh , c.s.c . served more than half , lobund institute for animal studies and medieval institute . hall of liberal arts ( "
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "print(invalid)\n",
    "for i in np.where(X_train_ans_label_all[110] == 1)[0]:\n",
    "    print(X_train_comp_all[110][i], end = ' ', sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['architecturally', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'s\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '``', 'ad', 'me', 'omnes', \"''\", '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'grotto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'lourdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputedly', 'appeared', 'to', 'saint', 'bernadette', 'soubirous', 'in', '1858.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.']\n",
      "['saint', 'bernadette', 'soubirous']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_comp_all[0])\n",
    "print(X_train_ans_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 104)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sub_list(X_train_ans_all[0] , X_train_comp_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n",
      "['the', 'success', 'of', 'its', 'football', 'team', 'made', 'notre', 'dame', 'a', 'household', 'name', '.', 'the', 'success', 'of', 'note', 'dame', 'reflected', 'rising', 'status', 'of', 'irish', 'americans', 'and', 'catholics', 'in', 'the', '1920s', '.', 'catholics', 'rallied', 'up', 'around', 'the', 'team', 'and', 'listen', 'to', 'the', 'games', 'on', 'the', 'radio', ',', 'especially', 'when', 'it', 'knocked', 'off', 'the', 'schools', 'that', 'symbolized', 'the', 'protestant', 'establishment', 'in', 'america', '—', 'harvard', ',', 'yale', ',', 'princeton', ',', 'and', 'army', '.', 'yet', 'this', 'role', 'as', 'high-profile', 'flagship', 'institution', 'of', 'catholicism', 'made', 'it', 'an', 'easy', 'target', 'of', 'anti-catholicism', '.', 'the', 'most', 'remarkable', 'episode', 'of', 'violence', 'was', 'the', 'clash', 'between', 'notre', 'dame', 'students', 'and', 'the', 'ku', 'klux', 'klan', 'in', '1924.', 'nativism', 'and', 'anti-catholicism', ',', 'especially', 'when', 'directed', 'towards', 'immigrants', ',', 'were', 'cornerstones', 'of', 'the', 'kkk', \"'s\", 'rhetoric', ',', 'and', 'notre', 'dame', 'was', 'seen', 'as', 'a', 'symbol', 'of', 'the', 'threat', 'posed', 'by', 'the', 'catholic', 'church', '.', 'the', 'klan', 'decided', 'to', 'have', 'a', 'week-long', 'klavern', 'in', 'south', 'bend', '.', 'clashes', 'with', 'the', 'student', 'body', 'started', 'on', 'march', '17', ',', 'when', 'students', ',', 'aware', 'of', 'the', 'anti-catholic', 'animosity', ',', 'blocked', 'the', 'klansmen', 'from', 'descending', 'from', 'their', 'trains', 'in', 'the', 'south', 'bend', 'station', 'and', 'ripped', 'the', 'kkk', 'clothes', 'and', 'regalia', '.', 'on', 'may', '19', 'thousands', 'of', 'students', 'massed', 'downtown', 'protesting', 'the', 'klavern', ',', 'and', 'only', 'the', 'arrival', 'of', 'college', 'president', 'fr', '.', 'matthew', 'walsh', 'prevented', 'any', 'further', 'clashes', '.', 'the', 'next', 'day', ',', 'football', 'coach', 'knute', 'rockne', 'spoke', 'at', 'a', 'campus', 'rally', 'and', 'implored', 'the', 'students', 'to', 'obey', 'the', 'college', 'president', 'and', 'refrain', 'from', 'further', 'violence', '.', 'a', 'few', 'days', 'later', 'the', 'klavern', 'broke', 'up', ',', 'but', 'the', 'hostility', 'shown', 'by', 'the', 'students', 'was', 'an', 'omen', 'and', 'a', 'contribution', 'to', 'the', 'downfall', 'of', 'the', 'kkk', 'in', 'indiana', '.']\n",
      "['the', 'ku', 'klux', 'klan']\n",
      "['notre', 'dame', 'students', 'had', 'a', 'showdown', 'in', '1924', 'with', 'which', 'anti-catholic', 'group', '?']\n",
      "['when', 'link', 'enters', 'the', 'twilight', 'realm', ',', 'the', 'void', 'that', 'corrupts', 'parts', 'of', 'hyrule', ',', 'he', 'transforms', 'into', 'a', 'wolf', '.', '[', 'h', ']', 'he', 'is', 'eventually', 'able', 'to', 'transform', 'between', 'his', 'hylian', 'and', 'wolf', 'forms', 'at', 'will', '.', 'as', 'a', 'wolf', ',', 'link', 'loses', 'the', 'ability', 'to', 'use', 'his', 'sword', ',', 'shield', ',', 'or', 'any', 'secondary', 'items', ';', 'he', 'instead', 'attacks', 'by', 'biting', ',', 'and', 'defends', 'primarily', 'by', 'dodging', 'attacks', '.', 'however', ',', '``', 'wolf', 'link', \"''\", 'gains', 'several', 'key', 'advantages', 'in', 'return—he', 'moves', 'faster', 'than', 'he', 'does', 'as', 'a', 'human', '(', 'though', 'riding', 'epona', 'is', 'still', 'faster', ')', 'and', 'digs', 'holes', 'to', 'create', 'new', 'passages', 'and', 'uncover', 'buried', 'items', ',', 'and', 'has', 'improved', 'senses', ',', 'including', 'the', 'ability', 'to', 'follow', 'scent', 'trails', '.', '[', 'i', ']', 'he', 'also', 'carries', 'midna', ',', 'a', 'small', 'imp-like', 'creature', 'who', 'gives', 'him', 'hints', ',', 'uses', 'an', 'energy', 'field', 'to', 'attack', 'enemies', ',', 'helps', 'him', 'jump', 'long', 'distances', ',', 'and', 'eventually', 'allows', 'link', 'to', '``', 'warp', \"''\", 'to', 'any', 'of', 'several', 'preset', 'locations', 'throughout', 'the', 'overworld', '.', '[', 'j', ']', 'using', 'link', \"'s\", 'wolf', 'senses', ',', 'the', 'player', 'can', 'see', 'and', 'listen', 'to', 'the', 'wandering', 'spirits', 'of', 'those', 'affected', 'by', 'the', 'twilight', ',', 'as', 'well', 'as', 'hunt', 'for', 'enemy', 'ghosts', 'named', 'poes', '.', '[', 'k', ']']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "['human']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "['link', \"'s\", 'wolf', 'form', 'is', 'faster', 'than', 'what', 'other', 'form', '?']\n"
     ]
    }
   ],
   "source": [
    "print(invalid)\n",
    "print(X_train_comp_all[101])\n",
    "print(X_train_ans_all[101])\n",
    "print(Y_train_ques_all[101])\n",
    "\n",
    "c = list(zip(X_train_comp_all,X_train_comp_ans_all, X_train_ans_all, X_train_ans_label_all,Y_train_ques_all))\n",
    "np.random.shuffle(c)\n",
    "X_train_comp_all_shuffled,X_train_comp_ans_all_shuffled, X_train_ans_shuffled, X_train_ans_label_shuffled,Y_train_ques_all_shuffled = zip(*c)\n",
    "\n",
    "print(X_train_comp_all_shuffled[101])\n",
    "print(X_train_comp_ans_all_shuffled[101])\n",
    "print(X_train_ans_shuffled[101])\n",
    "print(X_train_ans_label_shuffled[101])\n",
    "print(Y_train_ques_all_shuffled[101])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_take_train = 72000\n",
    "\n",
    "X_train_comp = X_train_comp_all_shuffled[0:examples_to_take_train]\n",
    "X_train_comp_ans = X_train_comp_ans_all_shuffled[0:examples_to_take_train]\n",
    "X_train_ans = X_train_ans_shuffled[0:examples_to_take_train]\n",
    "X_train_ans_label = X_train_ans_label_shuffled[0:examples_to_take_train]\n",
    "Y_train_ques = Y_train_ques_all_shuffled[0:examples_to_take_train]\n",
    "answer_indices = [np.where(x==1)[0].tolist() for x in X_train_comp_ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_len = len(max(X_train_comp,key=len))\n",
    "max_answer_len = len(max(X_train_ans,key=len))\n",
    "max_question_len = len(max(Y_train_ques,key=len)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = np.zeros((examples_to_take_train, max_document_len), dtype=np.int32)\n",
    "document_lengths = np.zeros(examples_to_take_train, dtype=np.int32)\n",
    "answer_labels = np.zeros((examples_to_take_train, max_document_len), dtype=np.int32)\n",
    "answer_masks = np.zeros((examples_to_take_train, max_answer_len, max_document_len), dtype=np.int32)\n",
    "answer_lengths = np.zeros(examples_to_take_train, dtype=np.int32)\n",
    "question_input_tokens = np.zeros((examples_to_take_train, max_question_len), dtype=np.int32)\n",
    "question_output_tokens = np.zeros((examples_to_take_train, max_question_len), dtype=np.int32)\n",
    "question_lengths = np.zeros(examples_to_take_train, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72000, 766)\n"
     ]
    }
   ],
   "source": [
    "print(answer_labels.shape)\n",
    "for i in range(examples_to_take_train):\n",
    "    answer_labels[i,0:len(X_train_ans_label[i])] = X_train_ans_label[i]\n",
    "    for j, word in enumerate(X_train_comp[i]):\n",
    "        document_tokens[i, j] = look_up_word_reduced(word)\n",
    "    document_lengths[i] = len(X_train_comp[i])\n",
    "\n",
    "    for j, index in enumerate(answer_indices[i]):\n",
    "        answer_masks[i, j, index] = 1\n",
    "    answer_lengths[i] = len(answer_indices[i])\n",
    "    \n",
    "    #print(Y_train_ques[i])\n",
    "    question_input_words = ([START_WORD] + Y_train_ques[i])\n",
    "    question_output_words = (Y_train_ques[i] + [END_WORD])\n",
    "\n",
    "    for j, word in enumerate(question_input_words):\n",
    "            question_input_tokens[i, j] = look_up_word_reduced(word)\n",
    "    for j, word in enumerate(question_output_words):\n",
    "        question_output_tokens[i, j] = look_up_word_reduced(word)\n",
    "    question_lengths[i] = len(question_input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(reduced_glove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices_glove(X,max_len):\n",
    "    \n",
    "    m = len(X)                                 \n",
    "    \n",
    "    X_indices = np.full([m,max_len],look_up_word_reduced(PAD_WORD))\n",
    "    \n",
    "    for i in range(m):\n",
    "        j = 0\n",
    "        for w in X[i]:\n",
    "            if(j>=max_len):\n",
    "                break;\n",
    "            \n",
    "            X_indices[i, j] = look_up_word_reduced(w)\n",
    "            j = j+1\n",
    "        if(j<max_len):\n",
    "            X_indices[i,j] = look_up_word_reduced(END_WORD)\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = sentences_to_indices_glove(X_train_comp, max_document_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1085,     5,     9,     4,  3448,  1092,     5,    12,  9790,\n",
       "          19,  2485,     5,    29,   567,     9,  5244,    19,     4,\n",
       "        1579,     5,    74,     4,  1745,  1085,     8,     4,  2992,\n",
       "       20350,     5,     6,    50, 15469,  3559,    29, 58149,     4,\n",
       "         943,  5791,     5,   615,  2628,     5,     8,  2380,     7,\n",
       "          37,   309,    12,    91,    14,  1352,   468,    46,    31,\n",
       "          12,     4,   337,     6,  1465,   647,     9,     4, 11209,\n",
       "       22045,     5,    11, 10903, 36483,     5,     8,  1413,  1130,\n",
       "           6,     4,    50,  1205,     7,    89,    77,    28,  1557,\n",
       "        1514,     5,   468,    67,  1251,     9,    11,  6173,   673,\n",
       "          33,  4615,  2159,     5,   571,    10,   468,  6573,    46,\n",
       "          75,    67,   279,    35,    57,  3513,   553,    23,     4,\n",
       "         186,     6,    11,  9415,     5,    52,    28,    41,  2083,\n",
       "          23,     4,    47,  6021,     7,   175,    75,  1514,    28,\n",
       "         673,    75,   468,  6573,    28,   607,    10,    14,   673,\n",
       "        6573,     7,    89,    77,    12,   115,  4615,  2109,   468,\n",
       "        6573,    28,  1021,    10,    35, 31996,    33,  6289,     7,\n",
       "           3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 766)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def createBatch(inputs,batch_size,shuffle=False):\n",
    "    outputs = []\n",
    "    start = 0\n",
    "    while start < len(inputs[0]):\n",
    "        end = min(len(inputs[0]), start + batch_size)\n",
    "        output = {'document_tokens':[],\n",
    "                    'document_lengths':[],\n",
    "                    'answer_labels':[],\n",
    "                    'answer_mask': [],\n",
    "                    'answer_lengths': [],\n",
    "                    'question_input_tokens':[],\n",
    "                    'question_output_tokens':[],\n",
    "                    'question_lengths':[],\n",
    "                 }\n",
    "        \n",
    "        for index,inp in enumerate(inputs):\n",
    "            maxD = max(inputs[1][start:start+batch_size])\n",
    "            maxA = max(inputs[4][start:start+batch_size])\n",
    "            maxQ = max(inputs[7][start:start+batch_size])\n",
    "            \n",
    "            if index == 0:\n",
    "                output['document_tokens'].append(inp[start:end,0:maxD])\n",
    "            elif index==1:\n",
    "                output['document_lengths'].append(inp[start:end])\n",
    "            elif index==2:\n",
    "                output['answer_labels'].append(inp[start:end,0:maxD])\n",
    "            elif index==3:\n",
    "                output['answer_mask'].append(inp[start:end,0:maxA,0:maxD])\n",
    "            elif index==4:\n",
    "                output['answer_lengths'].append(inp[start:end])\n",
    "            elif index==5:\n",
    "                output['question_input_tokens'].append(inp[start:end, 0:maxQ])\n",
    "            elif index==6:\n",
    "                output['question_output_tokens'].append(inp[start:end, 0:maxQ])\n",
    "            elif index==7:\n",
    "                output['question_lengths'].append(inp[start:end])\n",
    "            \n",
    "        output[\"document_tokens\"] = np.array(output[\"document_tokens\"])\n",
    "        output[\"document_lengths\"] = np.array(output[\"document_lengths\"])\n",
    "        output[\"answer_labels\"] = np.array(output[\"answer_labels\"])\n",
    "        output[\"answer_mask\"] = np.array(output[\"answer_mask\"])\n",
    "        output[\"answer_lengths\"] = np.array(output[\"answer_lengths\"])\n",
    "        output[\"question_input_tokens\"] = np.array(output[\"question_input_tokens\"])\n",
    "        output[\"question_output_tokens\"] = np.array(output[\"question_output_tokens\"])\n",
    "        output[\"question_lengths\"] = np.array(output[\"question_lengths\"])\n",
    "        outputs.append(output)\n",
    "        start = start + batch_size\n",
    "            \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_input = createBatch([document_tokens,document_lengths,answer_labels,answer_masks,answer_lengths,question_input_tokens,question_output_tokens,question_lengths]\n",
    "                    ,batch_size)\n",
    "\n",
    "for b in batch_input:\n",
    "    for k, v in b.items():\n",
    "        b[k] = v.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of features: 8\n",
      "No of batches: 2250\n"
     ]
    }
   ],
   "source": [
    "print(\"No of features:\",len(batch_input[0]))\n",
    "print(\"No of batches:\",len(batch_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches =  2025\n",
      "Number of test batches =  225\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.9\n",
    "split = int(len(batch_input) * split_ratio)\n",
    "batch_input_train = batch_input[0:split]\n",
    "batch_input_test = batch_input[split:]\n",
    "\n",
    "if len(batch_input_train[-1]['document_tokens'] < batch_size):\n",
    "    batch_input_train = batch_input_train[:-1]\n",
    "\n",
    "if len(batch_input_test) > 0 and len(batch_input_test[-1]['document_tokens'] < batch_size):\n",
    "    batch_input_test = batch_input_test[:-1]\n",
    "    \n",
    "print(\"Number of train batches = \", len(batch_input_train))\n",
    "print(\"Number of test batches = \", len(batch_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelperFunctions:\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def getDoc(self, batch, batch_num, example_num):\n",
    "        document = itertools.takewhile(lambda t: t != END_TOKEN, batch[batch_num]['document_tokens'][example_num])\n",
    "        doc = \" \".join(look_up_token_reduced(token) for token in document)\n",
    "        return doc\n",
    "\n",
    "    def getQues(self, batch, batch_num, example_num):\n",
    "        question = itertools.takewhile(lambda t: t != END_TOKEN, batch[batch_num]['question_output_tokens'][example_num])\n",
    "        ques = \" \".join(look_up_token_reduced(token) for token in question)\n",
    "        return ques\n",
    "    \n",
    "    def getAns(self, batch, batch_num, example_num):\n",
    "        ans = ''\n",
    "        for i in range(batch[batch_num]['answer_lengths'][example_num]):\n",
    "            ans = ans + look_up_token_reduced(batch[batch_num]['document_tokens'][example_num][np.where(batch[batch_num]['answer_mask'][example_num][i] == 1)[0][0]]) + ' '\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtils:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "    def clearFile(self):\n",
    "        open(self.filepath, 'w').close()\n",
    "    def appendString(self, string):\n",
    "        with open(self.filepath, \"a\") as myfile:\n",
    "            myfile.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityScoreUtils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        None\n",
    "    \n",
    "    def bleu_score(self, ground_truth_question, generated_question):\n",
    "        return nltk.translate.bleu_score.sentence_bleu(ground_truth_question,generated_question)\n",
    "    \n",
    "    def spacy_similarity_score(self, ground_truth_question, generated_question):\n",
    "        return nlp(ground_truth_question).similarity(nlp(generated_question))\n",
    "    \n",
    "    def aggregate_score(self, inference, key):\n",
    "        score = 0\n",
    "        for s in inference[key]:\n",
    "            score += s\n",
    "        score /= len(inference[key])\n",
    "        return score\n",
    "    \n",
    "    def find_similarity_score_from_inference(self, inferences, batch_size):\n",
    "        bleu_score = 0\n",
    "        spacy_score = 0\n",
    "        for inference in inferences:\n",
    "            bleu_score += self.aggregate_score(inference, 'bleu_score')\n",
    "            spacy_score += self.aggregate_score(inference, 'spacy_score')\n",
    "        bleu_score /= batch_size\n",
    "        spacy_score /= batch_size\n",
    "        return (bleu_score, spacy_score)\n",
    "\n",
    "    def find_similarity_on_batch(self, batch, batch_size, qgen, beam = False, beam_num = 5):\n",
    "\n",
    "        if beam :\n",
    "            inferences = qgen.generateQuestionsFromBatchWithBeam([batch], 0, batch_size, beam_num, shuffle = False, generateGroundTruthQuestion = True)\n",
    "        else:\n",
    "            inferences = qgen.generateQuestionsFromBatch([batch], 0, batch_size, shuffle = False, generateGroundTruthQuestion = True)\n",
    "            \n",
    "        \n",
    "        return self.find_similarity_score_from_inference(inferences, batch_size)\n",
    "            \n",
    "    def find_similarity_on_set(self, batch_input, batch_size, qgen, beam = False, beam_num = 5):\n",
    "        bleu_scores = 0\n",
    "        spacy_scores = 0\n",
    "        num_batches = len(batch_input)\n",
    "        \n",
    "        for batch in batch_input:\n",
    "            bleu_score, spacy_score = self.find_similarity_on_batch(batch, batch_size, qgen, beam, beam_num)\n",
    "            bleu_scores += bleu_score\n",
    "            spacy_scores += spacy_score\n",
    "        \n",
    "        bleu_scores /= num_batches\n",
    "        spacy_scores /= num_batches\n",
    "\n",
    "        return (bleu_scores, spacy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceUtils:\n",
    "    def __init__(self, batch_size, qgen):\n",
    "        self.batch_size = batch_size\n",
    "        self.qgen = qgen\n",
    "        \n",
    "    def printInferences(self, inferences, printGroundTruthQuestion = True, printSimilarityScores = True):\n",
    "        for inference in inferences:\n",
    "            print('----------------------------------------------------------------------------------------------------')\n",
    "            print('Comprehension : ')\n",
    "            print(inference['passage'])\n",
    "\n",
    "            if printGroundTruthQuestion:\n",
    "                print('*****************************************************************************************************')\n",
    "                print('Ground Truth Question : ')\n",
    "                print(inference['ground_truth_question'])\n",
    "            print('*****************************************************************************************************')\n",
    "            print('Ground Truth Answer: ')\n",
    "            print(inference['ground_truth_answer'])\n",
    "            print('*****************************************************************************************************')\n",
    "            for i,gen_ques in enumerate(inference['generated_questions']):\n",
    "                print('Generated Question Number :  ', i+1)\n",
    "                print(gen_ques)\n",
    "                if printSimilarityScores:\n",
    "                    print(\"BLEU Score : \", inference['bleu_score'][i])\n",
    "                    print(\"SpaCy Similarity Score : \", inference['spacy_score'][i])\n",
    "                print('*****************************************************************************************************')\n",
    "            print('----------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "    def createTokens(self, passage):\n",
    "        passage = word_tokenize(passage.lower())\n",
    "        passage_len = len(passage)\n",
    "        p = np.array(sentences_to_indices_glove([passage], passage_len))\n",
    "        p_len = np.array(passage_len).reshape((1,))\n",
    "        p_batch = np.repeat(p,repeats=self.batch_size, axis = 0)\n",
    "        p_len_batch = np.repeat(p_len,repeats=self.batch_size, axis = 0)\n",
    "        return p_batch, p_len_batch\n",
    "    \n",
    "    def makeInferenceOnText2(self, passage, use_beam = False):\n",
    "    \n",
    "        answers = self.qgen.generateAnswers(passage)\n",
    "        print(\"Answers = \", answers)\n",
    "        answers = np.nonzero(answers)[0]\n",
    "        outputs = []\n",
    "        for i in np.split(answers, np.where(np.diff(answers) != 1)[0]+1):\n",
    "            print(i)\n",
    "            left,right = i[0],i[-1]+1\n",
    "            answer = \" \".join(word_tokenize(passage.lower())[j] for j in range(left,right))\n",
    "            self.makeInferenceOnText(passage, answer, use_beam)\n",
    "            \n",
    "    \n",
    "    def makeInferenceOnText(self, passage, answer, use_beam = False):\n",
    "        passage = word_tokenize(passage.lower())\n",
    "        passage_len = len(passage)\n",
    "\n",
    "        answer = word_tokenize(answer.lower())\n",
    "        answer_len = len(answer)    \n",
    "\n",
    "        print(\"Passage Length = \", passage_len, \", Answer Length = \",answer_len)\n",
    "\n",
    "        left,right = find_sub_list(answer,passage)\n",
    "        if(left==-1):\n",
    "            print(\"Couldn't find answer in the passage !!\")\n",
    "            return\n",
    "        p = np.array(sentences_to_indices_glove([passage], passage_len))\n",
    "\n",
    "        p_len = np.array(passage_len).reshape((1,))\n",
    "        a_len = np.array(answer_len).reshape((1,))\n",
    "\n",
    "        ans_labels = np.zeros((1,passage_len))\n",
    "        ans_labels[0][left:right] = 1\n",
    "\n",
    "        enc_mask = np.zeros((1,answer_len, passage_len))\n",
    "        for i in range(left,right):\n",
    "            enc_mask[0,i-left,i] = 1\n",
    "\n",
    "        p_batch = np.repeat(p,repeats=self.batch_size, axis = 0)\n",
    "        p_len_batch = np.repeat(p_len,repeats=self.batch_size, axis = 0)\n",
    "        a_labels_batch = np.repeat(ans_labels,repeats=self.batch_size, axis = 0)\n",
    "        enc_mask_batch = np.repeat(enc_mask,repeats=self.batch_size, axis = 0)\n",
    "        a_len_batch = np.repeat(a_len,repeats=self.batch_size, axis = 0)\n",
    "        \n",
    "        output = {'document_tokens':p_batch,\n",
    "                    'document_lengths':p_len_batch,\n",
    "                    'answer_labels':a_labels_batch,\n",
    "                    'answer_mask': enc_mask_batch,\n",
    "                    'answer_lengths': a_len_batch\n",
    "                 }\n",
    "        if use_beam:\n",
    "            inferences = self.qgen.generateQuestionsFromBatch([output], 0, 1, 5, shuffle = False, generateGroundTruthQuestion = False)\n",
    "        else: \n",
    "            inferences = self.qgen.generateQuestionsFromBatchWithBeam([output], 0, 1, shuffle = False, generateGroundTruthQuestion = False)\n",
    "            \n",
    "        self.printInferences(inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGen:\n",
    "    def __init__(\n",
    "        self, learning_rate, cell_size , n_layers, reduced_glove, batch_size, \n",
    "            attention_type = 'Luong', cell_type = 'GRU', sess=tf.Session(), \n",
    "            helperFunctions = HelperFunctions(), fileUtils = FileUtils('/data/ra2630/tfLog64k'), similarityScoreUtils = SimilarityScoreUtils() ,\n",
    "            grad_clip=1.0, beam_width=10, force_teaching_ratio=0.5, dropout_probability = [0.4, 0.3, 0.3]):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.cell_size = cell_size\n",
    "        self.cell_type = cell_type\n",
    "        self.attention_type = attention_type\n",
    "        self.n_layers = n_layers\n",
    "        self.grad_clip = grad_clip\n",
    "        self.glove_embedding = reduced_glove\n",
    "        self.batch_size = batch_size\n",
    "        self.beam_width = beam_width\n",
    "        self.force_teaching_ratio = force_teaching_ratio\n",
    "        self.dropout_probability_document_encoder = dropout_probability[0]\n",
    "        self.dropout_probability_answer_encoder = dropout_probability[1]\n",
    "        self.dropout_probability_question_decoder = dropout_probability[2]\n",
    "        self.sess = sess\n",
    "        self.helperFunctions = helperFunctions\n",
    "        self.fileUtils = fileUtils\n",
    "        self.similarityScoreUtils = similarityScoreUtils\n",
    "        self.inferenceUtils = InferenceUtils(self.batch_size, self)\n",
    "        self.build_graph()\n",
    "        \n",
    "    def saveSession(self, filepath):\n",
    "        print(\"Saving Session to file : \", filepath)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.sess, filepath)\n",
    "        print(\"Session Saved !\")\n",
    "        \n",
    "    def loadFromSession(self, filepath):\n",
    "        print(\"Loading Session from file \", filepath)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, filepath)\n",
    "        print(\"Session restored !\")\n",
    "\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.add_embedding_layer()\n",
    "        self.add_document_encoder_layer()\n",
    "        self.add_answer_encoder_layer()\n",
    "        with tf.variable_scope('decode'):\n",
    "            self.add_decoder_for_training()\n",
    "        with tf.variable_scope('decode', reuse=True):\n",
    "            self.add_beam_decoder_for_inference()\n",
    "        self.add_decoder_for_inference()\n",
    "            \n",
    "        \n",
    "        self.add_backward_path()\n",
    "\n",
    "\n",
    "    def add_embedding_layer(self): \n",
    "        self.embedding = tf.get_variable(\"embedding\", initializer=self.glove_embedding)\n",
    "        self. embedding = tf.cast(self.embedding, dtype=tf.float32)\n",
    "        self.embedding_dimensions = reduced_glove.shape[1]\n",
    "        self.vocabulary_size = reduced_glove.shape[0]\n",
    "        \n",
    "    def add_document_encoder_layer(self):\n",
    "        self.d_tokens = tf.placeholder(tf.int32, shape=[None, None])\n",
    "        self.d_lengths = tf.placeholder(tf.int32, shape=[None])\n",
    "        \n",
    "        document_emb = tf.nn.embedding_lookup(self.embedding, self.d_tokens)\n",
    "        document_emb = tf.cast(document_emb, dtype=tf.float64)\n",
    "        \n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.document_forward_cell = tf.contrib.rnn.LSTMCell(self.cell_size)\n",
    "            self.document_backward_cell = tf.contrib.rnn.LSTMCell(self.cell_size)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.document_forward_cell = tf.contrib.rnn.GRUCell(self.cell_size)\n",
    "            self.document_backward_cell = tf.contrib.rnn.GRUCell(self.cell_size)\n",
    "        \n",
    "        self.document_forward_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "            self.document_forward_cell, \n",
    "            output_keep_prob = self.dropout_probability_document_encoder,\n",
    "            state_keep_prob = self.dropout_probability_document_encoder\n",
    "        )\n",
    "        \n",
    "        self.document_backward_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "            self.document_backward_cell, \n",
    "            output_keep_prob=self.dropout_probability_document_encoder,\n",
    "            state_keep_prob = self.dropout_probability_document_encoder\n",
    "        )\n",
    "        \n",
    "        self.document_encoder_outputs, self.document_encoder_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            self.document_forward_cell, \n",
    "            self.document_backward_cell, \n",
    "            document_emb, \n",
    "            self.d_lengths, \n",
    "            dtype=tf.float64\n",
    "        )\n",
    "        \n",
    "        self.document_encoder_outputs = tf.concat(self.document_encoder_outputs, 2)\n",
    "        self.document_encoder_outputs = tf.cast(self.document_encoder_outputs,tf.float32)\n",
    "        self.answer_tags = tf.layers.dense(inputs = self.document_encoder_outputs, units=2)\n",
    "\n",
    "\n",
    "        self.a_labels = tf.placeholder(tf.int32, shape=[None, None])\n",
    "        self.answer_mask = tf.sequence_mask(self.d_lengths, dtype=tf.float32)\n",
    "        self.answer_loss = seq2seq.sequence_loss(\n",
    "            logits=self.answer_tags, targets=self.a_labels, weights=self.answer_mask)\n",
    "        \n",
    "        self.answer_loss = tf.Print(self.answer_loss, [self.answer_loss], message=\"This is answer_loss: \")\n",
    "        \n",
    "\n",
    "\n",
    "    def add_answer_encoder_layer(self):\n",
    "        self.answer_encoder_input_mask = tf.placeholder(\n",
    "        tf.float32, shape=[None, None, None])\n",
    "        \n",
    "        self.answer_encoder_inputs = tf.matmul(self.answer_encoder_input_mask, self.document_encoder_outputs)\n",
    "        self.answer_encoder_lengths = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "        if self.cell_type == 'GRU':\n",
    "            self.answer_encoder_cell = tf.contrib.rnn.GRUCell(self.document_forward_cell.state_size + self.document_backward_cell.state_size)\n",
    "            self.question_decoder_cell = tf.contrib.rnn.GRUCell(self.answer_encoder_cell.state_size)\n",
    "        \n",
    "        elif self.cell_type == 'LSTM':\n",
    "            self.answer_encoder_cell = tf.contrib.rnn.LSTMCell(self.document_forward_cell.state_size[0] + self.document_backward_cell.state_size[0])\n",
    "            self.question_decoder_cell = tf.contrib.rnn.LSTMCell(self.answer_encoder_cell.state_size[0])\n",
    "            \n",
    "        self.answer_encoder_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "            self.answer_encoder_cell, \n",
    "            state_keep_prob=self.dropout_probability_answer_encoder\n",
    "        )\n",
    "        \n",
    "        self.question_decoder_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "            self.question_decoder_cell, \n",
    "            output_keep_prob=self.dropout_probability_question_decoder\n",
    "        )\n",
    "            \n",
    "        _, self.answer_encoder_state = tf.nn.dynamic_rnn(\n",
    "            self.answer_encoder_cell, self.answer_encoder_inputs, self.answer_encoder_lengths, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "    def add_attention_for_training(self):\n",
    "        if self.attention_type == 'Luong':\n",
    "            self.attention_function = tf.contrib.seq2seq.LuongAttention\n",
    "        else:\n",
    "            self.attention_function = tf.contrib.seq2seq.BahdanauAttention\n",
    "            \n",
    "        if self.cell_type == 'GRU':\n",
    "            attention_mechanism = self.attention_function(\n",
    "                num_units = self.answer_encoder_cell.state_size, \n",
    "                memory = self.document_encoder_outputs,\n",
    "                memory_sequence_length = self.d_lengths)\n",
    "\n",
    "            self.question_decoder_cell_attention = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = self.question_decoder_cell, \n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = self.question_decoder_cell.state_size)\n",
    "\n",
    "        elif self.cell_type == 'LSTM':\n",
    "            attention_mechanism = self.attention_function(\n",
    "                num_units = self.answer_encoder_cell.state_size[0], \n",
    "                memory = self.document_encoder_outputs,\n",
    "                memory_sequence_length = self.d_lengths)\n",
    "\n",
    "            self.question_decoder_cell_attention = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = self.question_decoder_cell, \n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = self.question_decoder_cell.state_size[0])\n",
    "        \n",
    "        self.question_decoder_cell_attention_without_beam = self.question_decoder_cell_attention\n",
    "\n",
    "\n",
    "    def add_decoder_for_training(self):\n",
    "        self.add_attention_for_training()\n",
    "        self.question_decoder_inputs = tf.placeholder(tf.int32, shape=[None, None])\n",
    "        self.question_decoder_lengths = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "        question_decoder_embedding = tf.nn.embedding_lookup(self.embedding, self.question_decoder_inputs)\n",
    "        question_decoder_embedding = tf.cast(question_decoder_embedding,tf.float32)\n",
    "\n",
    "        #helper = seq2seq.TrainingHelper(question_decoder_embedding , self.question_decoder_lengths)\n",
    "        helper = seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "            inputs = question_decoder_embedding,\n",
    "            sequence_length = self.question_decoder_lengths,\n",
    "            embedding = self.embedding,\n",
    "            sampling_probability = 1 - self.force_teaching_ratio,\n",
    "            time_major = False)\n",
    "\n",
    "        self.projection = Dense(self.vocabulary_size, use_bias=False)\n",
    "        \n",
    "        decoder = seq2seq.BasicDecoder(\n",
    "            self.question_decoder_cell_attention, \n",
    "            helper, \n",
    "            self.question_decoder_cell_attention.zero_state(self.batch_size, dtype=tf.float32).clone(\n",
    "              cell_state=self.answer_encoder_state),\n",
    "            output_layer = self.projection\n",
    "        )\n",
    "        \n",
    "        decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder)\n",
    "        self.training_question_decoder_outputs = decoder_outputs.rnn_output\n",
    "        \n",
    "    def add_decoder_for_inference(self):\n",
    "        helper = seq2seq.GreedyEmbeddingHelper(\n",
    "            self.embedding, \n",
    "            tf.fill([self.batch_size], START_TOKEN), \n",
    "            END_TOKEN\n",
    "        )\n",
    "        decoder = seq2seq.BasicDecoder(\n",
    "            self.question_decoder_cell_attention_without_beam, \n",
    "            helper, \n",
    "            self.question_decoder_cell_attention_without_beam.zero_state(self.batch_size, dtype=tf.float32).clone(\n",
    "                  cell_state=self.answer_encoder_state), output_layer=self.projection)\n",
    "        \n",
    "        decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, maximum_iterations=max_question_len)\n",
    "        self.decoder_outputs = decoder_outputs.rnn_output\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def add_beam_attention_for_inference(self):\n",
    "        self.document_encoder_output_tiled = tf.contrib.seq2seq.tile_batch(self.document_encoder_outputs, self.beam_width)\n",
    "        self.answer_encoder_state_tiled = tf.contrib.seq2seq.tile_batch(self.answer_encoder_state, self.beam_width)\n",
    "        self.document_lengths_tiled = tf.contrib.seq2seq.tile_batch(self.d_lengths, self.beam_width)\n",
    "\n",
    "        if self.cell_type == 'GRU':\n",
    "            attention_mechanism = self.attention_function(\n",
    "                num_units = self.answer_encoder_cell.state_size, \n",
    "                memory = self.document_encoder_output_tiled,\n",
    "                memory_sequence_length = self.document_lengths_tiled)\n",
    "\n",
    "            self.question_decoder_cell_attention = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = self.question_decoder_cell, \n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = self.question_decoder_cell.state_size)\n",
    "            \n",
    "\n",
    "        elif self.cell_type == 'LSTM':\n",
    "            attention_mechanism = self.attention_function(\n",
    "                num_units = self.answer_encoder_cell.state_size[0], \n",
    "                memory = self.document_encoder_output_tiled,\n",
    "                memory_sequence_length = self.document_lengths_tiled)\n",
    "\n",
    "            self.question_decoder_cell_attention = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = self.question_decoder_cell, \n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = self.question_decoder_cell.state_size[0])\n",
    "\n",
    "\n",
    "\n",
    "    def add_beam_decoder_for_inference(self):\n",
    "        self.add_beam_attention_for_inference()\n",
    "        \n",
    "        decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "            cell = self.question_decoder_cell_attention,\n",
    "            embedding = self.embedding,\n",
    "            start_tokens = tf.fill([self.batch_size], START_TOKEN),\n",
    "            end_token = END_TOKEN,\n",
    "            initial_state = self.question_decoder_cell_attention.zero_state(self.batch_size * self.beam_width,tf.float32).clone(\n",
    "                cell_state = self.answer_encoder_state_tiled),\n",
    "            beam_width = self.beam_width,\n",
    "            output_layer = self.projection,\n",
    "            length_penalty_weight = 0.0)\n",
    "        \n",
    "        \n",
    "        predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder = decoder,\n",
    "            maximum_iterations = max_question_len\n",
    "        )\n",
    "        self.predicting_question_ids = predicting_decoder_output.predicted_ids[:, :, :]\n",
    "\n",
    "\n",
    "    def add_backward_path(self):\n",
    "        self.decoder_labels = tf.placeholder(tf.int64, shape=[None, None])\n",
    "        question_mask = tf.sequence_mask(self.question_decoder_lengths ,dtype=tf.float32)\n",
    "        self.question_loss = seq2seq.sequence_loss(\n",
    "            logits = self.training_question_decoder_outputs, \n",
    "            targets = self.decoder_labels,\n",
    "            weights = question_mask)\n",
    "        self.question_loss = tf.Print(self.question_loss, [self.question_loss], message=\"This is question_loss: \")\n",
    "        \n",
    "        self.net_loss = self.question_loss + self.answer_loss\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        gvs = optimizer.compute_gradients(self.net_loss)\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -self.grad_clip, self.grad_clip), var) for grad, var in gvs]\n",
    "        self.train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "\n",
    "    def fit(self, batch_input_train, batch_input_test, path_to_save_file,save_after_every_epoch = 5, n_epoch=60, generateTrain = False, generateTest = False, clearFile = False, resumeTraining = False):\n",
    "\n",
    "        if not resumeTraining:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "        if clearFile:\n",
    "            self.fileUtils.clearFile()\n",
    "        \n",
    "        for epoch in range(1, n_epoch + 1):\n",
    "            batch_loss = 0\n",
    "            for batchNum in range(len(batch_input_train)):\n",
    "                t = self.sess.run([self.train_op, self.net_loss, self.question_loss, self.answer_loss], {\n",
    "                    self.d_tokens: batch_input_train[batchNum]['document_tokens'],\n",
    "                    self.d_lengths: batch_input_train[batchNum]['document_lengths'],\n",
    "                    self.a_labels: batch_input_train[batchNum]['answer_labels'],\n",
    "                    self.answer_encoder_input_mask: batch_input_train[batchNum]['answer_mask'],\n",
    "                    self.answer_encoder_lengths: batch_input_train[batchNum]['answer_lengths'],\n",
    "                    self.question_decoder_inputs: batch_input_train[batchNum]['question_input_tokens'],\n",
    "                    self.decoder_labels: batch_input_train[batchNum]['question_output_tokens'],\n",
    "                    self.question_decoder_lengths: batch_input_train[batchNum]['question_lengths']\n",
    "                })\n",
    "\n",
    "                print(\"Batch: {0}/{1}, Loss: {2}\".format(batchNum, len(batch_input_train), t[1]))\n",
    "                batch_loss += t[1]\n",
    "                sys.stdout.flush()\n",
    "            batch_loss /= len(batch_input_train)\n",
    "            print(\"Epochs: {0}/{1} Batch - Loss (Train): {2}\".format(epoch, n_epoch, batch_loss))\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            if generateTrain:\n",
    "                print(\"Train Samples Generated : \")\n",
    "                inferences = self.generateQuestionsFromBatch(batch_input_train, random.randint(0,len(batch_input_train)-1), 5)\n",
    "                self.inferenceUtils.printInferences(inferences)\n",
    "                bleu_score, spacy_score = self.similarityScoreUtils.find_similarity_on_batch(\n",
    "                    batch_input_train[random.randint(0, len(batch_input_train)-1)], self.batch_size, self, beam = False)\n",
    "                print(\"For Non-Beam Question Generation, Bleu Score = {0} and Spacy Score = {1}\".format(bleu_score, spacy_score))\n",
    "                \n",
    "                inferences = self.generateQuestionsFromBatchWithBeam(batch_input_train, random.randint(0,len(batch_input_train)-1), 5, 5)\n",
    "                self.inferenceUtils.printInferences(inferences)\n",
    "                bleu_score, spacy_score = self.similarityScoreUtils.find_similarity_on_batch(\n",
    "                    batch_input_train[random.randint(0, len(batch_input_train)-1)], self.batch_size, self, beam = True, beam_num = 5)\n",
    "                print(\"For Beam Question Generation, Bleu Score = {0} and Spacy Score = {1}\".format(bleu_score, spacy_score))\n",
    "                \n",
    "            if generateTest:\n",
    "                print(\"Test Samples Generated : \")\n",
    "                inferences = self.generateQuestionsFromBatch(batch_input_test, random.randint(0,len(batch_input_test)-1), 5)\n",
    "                self.inferenceUtils.printInferences(inferences)\n",
    "                bleu_score, spacy_score = self.similarityScoreUtils.find_similarity_on_batch(\n",
    "                    batch_input_test[random.randint(0, len(batch_input_test)-1)], self.batch_size, self, beam = False)\n",
    "                print(\"For Non-Beam Question Generation, Bleu Score = {0} and Spacy Score = {1}\".format(bleu_score, spacy_score))\n",
    "                \n",
    "                inferences = self.generateQuestionsFromBatchWithBeam(batch_input_test, random.randint(0,len(batch_input_test)-1), 5, 5)\n",
    "                self.inferenceUtils.printInferences(inferences)\n",
    "                bleu_score, spacy_score = self.similarityScoreUtils.find_similarity_on_batch(\n",
    "                    batch_input_test[random.randint(0, len(batch_input_test)-1)], self.batch_size, self, beam = True, beam_num = 5)\n",
    "                print(\"For Beam Question Generation, Bleu Score = {0} and Spacy Score = {1}\".format(bleu_score, spacy_score))\n",
    "                \n",
    "            if epoch % save_after_every_epoch == 0:\n",
    "                self.saveSession(path_to_save_file)\n",
    "    \n",
    "            \n",
    "    def generateAnswers(self, passage):\n",
    "        p_batch, p_len_batch = self.inferenceUtils.createTokens(passage)\n",
    "        answers = self.sess.run(qgen.answer_tags, {\n",
    "            qgen.d_tokens: p_batch,\n",
    "            qgen.d_lengths: p_len_batch,\n",
    "        })\n",
    "        answers = np.argmax(answers[0], 1)\n",
    "        return answers\n",
    "        \n",
    "        \n",
    "    def generateQuestionsFromBatch(self, batch, batchNum, numExamples, shuffle = True, generateGroundTruthQuestion = True):\n",
    "        \n",
    "        inferences = []\n",
    "        \n",
    "        if shuffle:\n",
    "            p = random.sample(range(0, self.batch_size), self.batch_size)\n",
    "        else:\n",
    "            p = range(0,self.batch_size)\n",
    "        j = 0\n",
    "        questions = self.sess.run(self.decoder_outputs, {\n",
    "            self.d_tokens: batch[batchNum]['document_tokens'][p],\n",
    "            self.d_lengths: batch[batchNum]['document_lengths'][p],\n",
    "            self.a_labels: batch[batchNum]['answer_labels'][p],\n",
    "            self.answer_encoder_input_mask: batch[batchNum]['answer_mask'][p],\n",
    "            self.answer_encoder_lengths: batch[batchNum]['answer_lengths'][p],\n",
    "        })\n",
    "        p = p[:numExamples]\n",
    "\n",
    "        qs = np.argmax(questions, 2)\n",
    "        for i in p:\n",
    "            inference = {\n",
    "                'passage' : '',\n",
    "                'ground_truth_question' : '',\n",
    "                'ground_truth_answer' : '',\n",
    "                'generated_questions' : [],\n",
    "                'bleu_score' : [],\n",
    "                'spacy_score' : []\n",
    "            }\n",
    "            question = itertools.takewhile(lambda t: t != END_TOKEN, qs[j])\n",
    "            inference['passage'] = self.helperFunctions.getDoc(batch, batchNum , i)\n",
    "            if generateGroundTruthQuestion:\n",
    "                inference['ground_truth_question'] = self.helperFunctions.getQues(batch, batchNum, i)\n",
    "            inference['ground_truth_answer'] = self.helperFunctions.getAns(batch, batchNum, i)\n",
    "            generated_question = \" \".join(look_up_token_reduced(token) for token in question)\n",
    "            inference['generated_questions'] = [generated_question]\n",
    "            inference['bleu_score'] = [self.similarityScoreUtils.bleu_score(inference['ground_truth_question'], generated_question)]\n",
    "            inference['spacy_score'] = [self.similarityScoreUtils.spacy_similarity_score(inference['ground_truth_question'], generated_question)]\n",
    "            j=j+1\n",
    "            inferences.append(inference)\n",
    "\n",
    "        return inferences\n",
    "        \n",
    "        \n",
    "    \n",
    "    def generateQuestionsFromBatchWithBeam(self, batch, batchNum, numExamples, numQuestions, shuffle = True, generateGroundTruthQuestion = True):\n",
    "        \n",
    "        inferences = []\n",
    "        if shuffle:\n",
    "            p = random.sample(range(0, self.batch_size), self.batch_size)\n",
    "        else:\n",
    "            p = range(0,self.batch_size)\n",
    "        j = 0\n",
    "        questions = self.sess.run(self.predicting_question_ids, {\n",
    "            self.d_tokens: batch[batchNum]['document_tokens'][p],\n",
    "            self.d_lengths: batch[batchNum]['document_lengths'][p],\n",
    "            self.a_labels: batch[batchNum]['answer_labels'][p],\n",
    "            self.answer_encoder_input_mask: batch[batchNum]['answer_mask'][p],\n",
    "            self.answer_encoder_lengths: batch[batchNum]['answer_lengths'][p],\n",
    "        })\n",
    "        p = p[:numExamples]\n",
    "        for i in p:\n",
    "            inference = {\n",
    "                'passage' : '',\n",
    "                'ground_truth_question' : '',\n",
    "                'ground_truth_answer' : '',\n",
    "                'generated_questions' : [],\n",
    "                'bleu_score' : [],\n",
    "                'spacy_score' : []\n",
    "            }\n",
    "            inference['passage'] = self.helperFunctions.getDoc(batch, batchNum ,i)\n",
    "            if generateGroundTruthQuestion:\n",
    "                inference['ground_truth_question'] = self.helperFunctions.getQues(batch, batchNum, i)\n",
    "            inference['ground_truth_answer'] = self.helperFunctions.getAns(batch, batchNum, i)\n",
    "            generated_questions = []\n",
    "            bleu_scores = []\n",
    "            spacy_scores = []\n",
    "            for k in range(numQuestions):\n",
    "                question = itertools.takewhile(lambda t: t != END_TOKEN, questions[j,:,k])\n",
    "                generated_question = \" \".join(look_up_token_reduced(token) for token in question)\n",
    "                generated_questions.append(generated_question)\n",
    "                bleu_scores.append(self.similarityScoreUtils.bleu_score(inference['ground_truth_question'], generated_question))\n",
    "                spacy_scores.append(self.similarityScoreUtils.spacy_similarity_score(inference['ground_truth_question'], generated_question))\n",
    "                \n",
    "            j=j+1\n",
    "            inference['bleu_score'] = bleu_scores\n",
    "            inference['spacy_score'] = spacy_scores\n",
    "            inference['generated_questions'] = generated_questions\n",
    "            inferences.append(inference)\n",
    "        return inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "qgen = QGen(learning_rate = 3e-4,\n",
    "            cell_size = 400,\n",
    "            n_layers = 1,\n",
    "            reduced_glove = reduced_glove,\n",
    "            batch_size = batch_size,\n",
    "            attention_type = 'Bahdanau',\n",
    "            cell_type = 'LSTM',\n",
    "            sess=session,\n",
    "            grad_clip=1.,\n",
    "            beam_width=10,\n",
    "            force_teaching_ratio=1.0,\n",
    "            dropout_probability = [0.7,0.7,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.stdout = open('/data/ra2630/tfLog64k-3', 'a', 1)\n",
    "qgen.fit(\n",
    "    batch_input_train, \n",
    "    batch_input_test, \n",
    "    n_epoch=12, \n",
    "    path_to_save_file = '/data/ra2630/tf64k-3',\n",
    "    save_after_every_epoch = 3,\n",
    "    generateTrain = True, \n",
    "    generateTest = True,\n",
    "    clearFile=False, \n",
    "    resumeTraining = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgen.loadFromSession(\"/data/ra2630/tf64k-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "it was principally the widespread introduction of a single feature , the pointed arch , which was to bring about the change that separates gothic from romanesque . the technological change permitted a stylistic change which broke the tradition of massive masonry and solid walls penetrated by small openings , replacing it with a style where light appears to triumph over substance . with its use came the development of many other architectural devices , previously put to the test in scattered buildings and then called into service to meet the structural , aesthetic and ideological needs of the new style . these include the flying buttresses , pinnacles and traceried windows which typify gothic ecclesiastical architecture . but while pointed arch is so strongly associated with the gothic style , it was first used in western architecture in buildings that were in other ways clearly romanesque , notably durham cathedral in the north of england , monreale cathedral and cathedral of cefalù in sicily , autun cathedral in france .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what was the most important single design aspect that separated the gothic style from the romanesque ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the pointed arch \n",
      "*****************************************************************************************************\n",
      "Generated Question :\n",
      "what was the design aspect that design design that separated gothic the the romanesque the from\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.668740304976422\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "lancashire had a lively culture of choral and classical music , with very large numbers of local church choirs from the 17th century , leading to the foundation of local choral societies from the mid-18th century , often particularly focused on performances of the music of handel and his contemporaries . it also played a major part in the development of brass bands which emerged in the county , particularly in the textile and coalfield areas , in the 19th century . the first open competition for brass bands was held at manchester in 1853 , and continued annually until the 1980s . the vibrant brass band culture of the area made an important contribution to the foundation and staffing of the hallé orchestra from 1857 , the oldest extant professional orchestra in the united kingdom . the same local musical tradition produced eminent figures such as sir william walton ( 1902–88 ) , son of an oldham choirmaster and music teacher , sir thomas beecham ( 1879–1961 ) , born in st. helens , who began his career by conducting local orchestras and alan rawsthorne ( 1905–71 ) born in haslingden . the conductor david atherton , co-founder of the london sinfonietta , was born in blackpool in 1944. lancashire also produced more populist figures , such as early musical theatre composer leslie stuart ( 1863–1928 ) , born in southport , who began his musical career as organist of salford cathedral .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "who began their musical career as organist of salford cathedral ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "leslie stuart \n",
      "*****************************************************************************************************\n",
      "Generated Question :\n",
      "who began their musical career as organist of salford cathedral ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7447819789879647\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "after nasser died in november 1970 , his successor , anwar sadat , suggested that rather than a unified state , they create a political federation , implemented in april 1971 ; in doing so , egypt , syria and sudan got large grants of libyan oil money . in february 1972 , gaddafi and sadat signed an unofficial charter of merger , but it was never implemented as relations broke down the following year . sadat became increasingly wary of libya 's radical direction , and the september 1973 deadline for implementing the federation passed by with no action taken .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "who did anwar sadat succeed ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "nasser \n",
      "*****************************************************************************************************\n",
      "Generated Question :\n",
      "who did anwar sadat succeed ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8480536257973762\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "architects such as mies van der rohe , philip johnson and marcel breuer worked to create beauty based on the inherent qualities of building materials and modern construction techniques , trading traditional historic forms for simplified geometric forms , celebrating the new means and methods made possible by the industrial revolution , including steel-frame construction , which gave birth to high-rise superstructures . by mid-century , modernism had morphed into the international style , an aesthetic epitomized in many ways by the twin towers of new york 's world trade center designed by minoru yamasaki .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what new type of construction allowed the making of skyscrapers ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "steel-frame construction \n",
      "*****************************************************************************************************\n",
      "Generated Question :\n",
      "what type of construction architecture was making making skyscrapers skyscrapers ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7027551482022703\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the most widely used class of antenna , a dipole antenna consists of two symmetrical <UNK> such as metal rods or wires , with one side of the balanced feedline from the transmitter or receiver attached to each . a horizontal dipole radiates in two lobes perpendicular to the antenna 's axis . a half-wave dipole the most common type , has two collinear elements each a quarter wavelength long and a gain of <UNK> dbi . used individually as low gain antennas , dipoles are also used as driven elements in many more complicated higher gain types of antennas .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what is the most <UNK> used antenna class ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "dipole antenna \n",
      "*****************************************************************************************************\n",
      "Generated Question :\n",
      "what is the most <UNK> used used for ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8296066547537364\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "qgen.inferFromBatch(\n",
    "    batch = batch_input_train, \n",
    "    batchNum = 2, \n",
    "    numExamples = 5, \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the alaska state troopers are alaska 's statewide police force . they have a long and storied history , but were not an official organization until 1941. before the force was officially organized , law enforcement in alaska was handled by various federal agencies . larger towns usually have their own local police and some villages rely on `` public safety officers '' who have police training but do not carry firearms . in much of the state , the troopers serve as the only police force available . in addition to enforcing traffic and criminal law , wildlife troopers enforce hunting and fishing regulations . due to the varied terrain and wide scope of the troopers ' duties , they employ a wide variety of land , air , and water patrol vehicles .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what type of vehicles do troopers operate ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "a wide variety of land , air , and water patrol vehicles \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what types of vehicles vehicles troopers helped ?\n",
      "Generated Question Number :  2\n",
      "what types of vehicles vehicles troopers helped\n",
      "Generated Question Number :  3\n",
      "what types of vehicles vehicles troopers helped\n",
      "Generated Question Number :  4\n",
      "what types of vehicles vehicles troopers operate ?\n",
      "Generated Question Number :  5\n",
      "what services do troopers vehicles troopers regulations ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7278825061958952\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in most bacteria , a cell wall is present on the outside of the cell membrane . the cell membrane and cell wall comprise the cell envelope . a common bacterial cell wall material is peptidoglycan ( called `` murein '' in older sources ) , which is made from polysaccharide chains cross-linked by peptides containing d-amino acids . bacterial cell walls are different from the cell walls of plants and fungi , which are made of cellulose and chitin , respectively . the cell wall of bacteria is also distinct from that of archaea , which do not contain peptidoglycan . the cell wall is essential to the survival of many bacteria , and the antibiotic penicillin is able to kill bacteria by inhibiting a step in the synthesis of peptidoglycan .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what composes the cell envelope ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "cell membrane and cell wall \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what is the cell envelope ?\n",
      "Generated Question Number :  2\n",
      "what are the cell envelope ?\n",
      "Generated Question Number :  3\n",
      "what composes the cell envelope ?\n",
      "Generated Question Number :  4\n",
      "what grows the cell envelope ?\n",
      "Generated Question Number :  5\n",
      "what is a cell envelope ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8650615454144222\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "translation is the process by which a mature mrna molecule is used as a template for synthesizing a new protein . :6.2 translation is carried out by ribosomes , large complexes of rna and protein responsible for carrying out the chemical reactions to add new amino acids to a growing polypeptide chain by the formation of peptide bonds . the genetic code is read three nucleotides at a time , in units called codons , via interactions with specialized rna molecules called transfer rna ( trna ) . each trna has three unpaired bases known as the anticodon that are complementary to the codon it reads on the mrna . the trna is also covalently attached to the amino acid specified by the complementary codon . when the trna binds to its complementary codon in an mrna strand , the ribosome attaches its amino acid cargo to the new polypeptide chain , which is synthesized from amino terminus to carboxyl terminus . during and after synthesis , most new proteins must folds to their active three-dimensional structure before they can carry out their cellular functions . :3\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what is the process by which a mature mrna molecule is used as a template for synthesizing a new protein called ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "translation \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what is the process by which a mature mrna molecule is used as a template for synthesizing a new protein ?\n",
      "Generated Question Number :  2\n",
      "what is the process by which a mature mrna molecule is known as a template for synthesizing a new protein ?\n",
      "Generated Question Number :  3\n",
      "what is the process by which a mature mrna molecule is used ?\n",
      "Generated Question Number :  4\n",
      "what is the process by which a mature mrna molecule is used ?\n",
      "Generated Question Number :  5\n",
      "what is the process by which a mature mrna molecule is used ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7567022758746456\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "uranium metal reacts with almost all non-metal elements ( with an exception of the noble gases ) and their compounds , with reactivity increasing with temperature . hydrochloric and nitric acids dissolve uranium , but non-oxidizing acids other than hydrochloric acid attack the element very slowly . when finely divided , it can react with cold water ; in air , uranium metal becomes coated with a dark layer of uranium oxide . uranium in ores is extracted chemically and converted into uranium dioxide or other chemical forms usable in industry .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what reacts with finely divided uranium ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "cold water \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what reacts with finely in uranium ?\n",
      "Generated Question Number :  2\n",
      "what reacts with finely in uranium particles ?\n",
      "Generated Question Number :  3\n",
      "what reacts with finely particles uranium ?\n",
      "Generated Question Number :  4\n",
      "what reacts with finely particles in uranium ?\n",
      "Generated Question Number :  5\n",
      "what reacts with finely in uranium ? ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8178362024635121\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "other notable new vaccines of the period include those for measles ( 1962 , john franklin enders of children 's medical center boston , later refined by maurice hilleman at merck ) , rubella ( 1969 , hilleman , merck ) and mumps ( 1967 , hilleman , merck ) the united states incidences of rubella , congenital rubella syndrome , measles , and mumps all fell by > 95 % in the immediate aftermath of widespread vaccination . the first 20 years of licensed measles vaccination in the u.s. prevented an estimated 52 million cases of the disease , 17,400 cases of mental retardation , and 5,200 deaths .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "in what year was the mumps vaccine made ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "1967 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "in what year was the mumps vaccine of\n",
      "Generated Question Number :  2\n",
      "in what year was the mumps vaccine of\n",
      "Generated Question Number :  3\n",
      "in what year was the mumps vaccine of ?\n",
      "Generated Question Number :  4\n",
      "in what year was the mumps vaccine ?\n",
      "Generated Question Number :  5\n",
      "in what year was the mumps vaccine of ? ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8024468307724723\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the pacific war saw the allied powers pitted against the empire of japan , the latter briefly aided by thailand and to a much lesser extent by its axis allies , germany and italy . the war culminated in the atomic bombings of hiroshima and nagasaki , and other large aerial bomb attacks by the united states army air forces , accompanied by the soviet invasion of manchuria on 8 august 1945 , resulting in the japanese announcement of intent to surrender on 15 august 1945. the formal and official surrender of japan took place aboard the battleship uss missouri in tokyo bay on 2 september 1945. following its defeat , japan 's shinto emperor stepped down as the divine leader through the shinto directive , because the allied powers believed this was the major political cause of japan 's military aggression and deconstruction process soon took place to install a new liberal-democratic constitution to the japanese public as the current constitution of japan .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "when did the soviet union invade manchuria ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "8 august 1945 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "when did the soviet invade invade ?\n",
      "Generated Question Number :  2\n",
      "when did the soviet invasion of manchuria occur ?\n",
      "Generated Question Number :  3\n",
      "when did the soviet invade invade manchuria ?\n",
      "Generated Question Number :  4\n",
      "when did the soviets invade manchuria ?\n",
      "Generated Question Number :  5\n",
      "when did the soviets invade manchuria ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8125424861344327\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "following their basic and advanced training at the individual-level , soldiers may choose to continue their training and apply for an `` additional skill identifier '' ( asi ) . the asi allows the army to take a wide ranging mos and focus it into a more specific mos . for example , a combat <UNK> , whose duties are to provide pre-hospital emergency treatment , may receive asi training to become a cardiovascular specialist , a <UNK> specialist , or even a licensed practical nurse . for commissioned officers , asi training includes <UNK> training either at <UNK> , or via rotc , or by completing <UNK> . after commissioning , officers undergo branch specific training at the basic officer leaders course , ( formerly called officer basic course ) , which varies in time and location according their future assignments . further career development is available through the army correspondence course program .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what is are combat medics duties ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "provide pre-hospital emergency treatment \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what is necessary combat medics duties ?\n",
      "Generated Question Number :  2\n",
      "what is of combat medics duties ?\n",
      "Generated Question Number :  3\n",
      "what are of combat medics duties ?\n",
      "Generated Question Number :  4\n",
      "what is necessary combat medics duties for\n",
      "Generated Question Number :  5\n",
      "what is a combat medics duties ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.8274377299117183\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "on 22 september 2003 the newspaper appeared to misjudge the public mood surrounding mental health , as well as its affection for former world heavyweight champion boxer frank bruno , who had been admitted to hospital , when the headline `` bonkers bruno locked up '' appeared on the front page of early editions . the adverse reaction , once the paper had hit the streets on the evening of 21 september , led to the headline being changed for the paper 's second edition to the more sympathetic `` sad bruno in mental home '' .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what was the headline changed to after public backlash ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "sad bruno in mental home \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what was the headline changed for the backlash ?\n",
      "Generated Question Number :  2\n",
      "what was the first changed for the backlash ?\n",
      "Generated Question Number :  3\n",
      "what was the cause of the cause of ?\n",
      "Generated Question Number :  4\n",
      "what was the cause of the cause of ?\n",
      "Generated Question Number :  5\n",
      "what was the first changed for the cause of ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7839874343080119\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "there is a theory that vinyl records can audibly represent higher frequencies than compact discs . according to red book specifications , the compact disc has a frequency response of 20 hz up to <UNK> hz , and most cd players measure flat within a fraction of a decibel from at least 20 hz to 20 khz at full output . turntable rumble obscures the low-end limit of vinyl but the upper end can be , with some cartridges , reasonably flat within a few decibels to 30 khz , with gentle roll-off . carrier signals of quad lps popular in the 1970s were at 30 khz to be out of the range of human hearing . the average human auditory system is sensitive to frequencies from 20 hz to a maximum of around 20,000 hz . the upper and lower frequency limits of human hearing vary per person .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "does the hearing range of the human vary ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the upper and lower frequency limits of human hearing vary per person \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "does the among human indicate vary vary in the ?\n",
      "Generated Question Number :  2\n",
      "does the among human indicate vary vary in the\n",
      "Generated Question Number :  3\n",
      "does the among human indicate vary vary to the ?\n",
      "Generated Question Number :  4\n",
      "does the among human indicate vary vary in the range ?\n",
      "Generated Question Number :  5\n",
      "does the studies human indicate vary vary in the range ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7422756664604733\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "youtube does not usually offer a download link for its videos , and intends for them to be viewed through its website interface . a small number of videos , such as the weekly addresses by president barack obama , can be downloaded as mp4 files . numerous third-party web sites , applications and browser plug-ins allow users to download youtube videos . in february 2009 , youtube announced a test service , allowing some partners to offer video downloads for free or for a fee paid through google checkout . in june 2012 , google sent cease and desist letters threatening legal action against several websites offering online download and conversion of youtube videos . in response , zamzar removed the ability to download youtube videos from its site . the default settings when uploading a video to youtube will retain a copyright on the video for the uploader , but since july 2012 it has been possible to select a creative commons license as the default , allowing other users to reuse and remix the material if it is free of copyright .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "which videos are often available for download straight from youtube ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the weekly addresses by president barack obama \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "which videos were not available to download straight videos ?\n",
      "Generated Question Number :  2\n",
      "which videos can not available to be straight videos ?\n",
      "Generated Question Number :  3\n",
      "which videos can not available to use ?\n",
      "Generated Question Number :  4\n",
      "which videos can not available to use ?\n",
      "Generated Question Number :  5\n",
      "which videos is not available to the straight videos ?\n",
      "*****************************************************************************************************\n",
      "Bleu Score =  0.7598356856515925\n",
      "Bleu Score =  None\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "qgen.inferFromBatchBeam(\n",
    "            batch = batch_input_train, \n",
    "            batchNum = 700, \n",
    "            numExamples = 10, \n",
    "            numQuestions = 5, \n",
    "            shuffle = True,\n",
    "            printGroundTruthQuestion = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in the 1990s two icons by the russian icon painter sergei fyodorov were hung in the abbey . on 6 september 1997 the funeral of diana , princess of wales , was held at the abbey . on 17 september 2010 pope benedict xvi became the first pope to set foot in the abbey .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what nationality was sergei fyodorov ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "russian \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "by what radio was the abbey made the abbey in the abbey in\n",
      "Bleu Score =  0.6880640060880959\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "by what radio was the abbey made the abbey in the abbey ?\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "by what radio was the abbey by the abbey in the abbey in\n",
      "Bleu Score =  0.6941268297866866\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "by what radio was the abbey by the abbey in the abbey in\n",
      "Bleu Score =  0.6941268297866866\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "by what football was the abbey made the abbey in the abbey in\n",
      "Bleu Score =  0.6921489273129074\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "by what radio was the abbey by the abbey in the abbey ?\n",
      "Bleu Score =  0.7102992180127422\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "by what football was the abbey made the abbey in the abbey ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "by what radio was the abbey made the abbey in the abbey in ?\n",
      "Bleu Score =  0.6950150297221263\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "by what radio was the abbey made the abbey in the abbey in ?\n",
      "Bleu Score =  0.6950150297221263\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "by what radio was the abbey made the abbey in the abbey ? ? ? ?\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "a uniquely creole tradition is the touloulous . these women wear decorative gowns , gloves , masks and headdresses that cover them completely , making them unrecognisable , even to the colour of their skin . on friday and saturday nights of carnival , touloulou balls are held in so-called universities ; in reality , large dance halls that open only at carnival time . touloulous get in free , and are even given condoms in the interest of the sexual health of the community . men attend the balls , but they pay admittance and are not disguised . the touloulous pick their dance partners , who may not refuse . the setup is designed to make it easy for a woman to create a temporary liaison with a man in total anonymity . undisguised women are not welcomed . by tradition , if such a woman gets up to dance , the orchestra stops playing . alcohol is served at bars – the disguised women whisper to the men `` touloulou thirsty '' , at which a round of drinks is expected , to be drunk through a straw protect their anonymity .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "why do the women drink through a straw ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "protect their anonymity \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what did the touloulous remove to to to the ?\n",
      "Bleu Score =  0.7468422531048421\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what did the da give the to to the ?\n",
      "Bleu Score =  0.7434855737622396\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what did the touloulous remove to to to ? ?\n",
      "Bleu Score =  0.7553789791604315\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what did the touloulous remove to to to ? ?\n",
      "Bleu Score =  0.7553789791604315\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what did the touloulous remove to to to the\n",
      "Bleu Score =  0.7415129228605242\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what did the touloulous give to to to the ?\n",
      "Bleu Score =  0.7415129228605242\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what did the touloulous remove to to to the\n",
      "Bleu Score =  0.7415129228605242\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what did the da give the to to ? ?\n",
      "Bleu Score =  0.7541859578343534\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what did the touloulous remove to to to ?\n",
      "Bleu Score =  0.7644270467420534\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what did the <UNK> to the help to the ?\n",
      "Bleu Score =  0.7115965735877551\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in september 2014 , professor stefan grimm , of the department of medicine , was found dead after being threatened with dismissal for failure to raise enough grant money . the college made its first public announcement of his death on 4 december 2014. grimm 's last email accused his employers of bullying by demanding that he should get grants worth at least £200,000 per year . his last email was viewed more than 100,000 times in the first four days after it was posted . the college has announced an internal inquiry into stefan grimm 's death . the inquest on his death has not yet reported .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "when was professor stefan grimm found dead ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "september 2014 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "when did month grimm take occur occur in\n",
      "Bleu Score =  0.7691605673134586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "when did month edward occur occur in the place ?\n",
      "Bleu Score =  0.7476743906106103\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "when did month edward occur occur in the dame ?\n",
      "Bleu Score =  0.7387670965262431\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "when did month edward occur occur in the place ?\n",
      "Bleu Score =  0.7476743906106103\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "when did month edward occur occur in the dame ?\n",
      "Bleu Score =  0.7387670965262431\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "when did month edward occur occur in the dame ,\n",
      "Bleu Score =  0.725205974975922\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "when did month grimm take occur occur in\n",
      "Bleu Score =  0.7691605673134586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "when did month grimm grimm 's title occur in place\n",
      "Bleu Score =  0.7521206186172787\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "when did month grimm grimm 's title occur in place result ,\n",
      "Bleu Score =  0.721634009677548\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "when did month grimm grimm 's title occur in place ? ,\n",
      "Bleu Score =  0.7490551432883844\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the outbreak of world war i in 1914 was precipitated by the rise of nationalism in southeastern europe as the great powers took up sides . the allies defeated the central powers in 1918. during the paris peace conference the big four imposed their terms in a series of treaties , especially the treaty of versailles .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "at what event did the major allied powers assert their conditions at the end of the war ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the paris peace conference \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what two body economy caused the europe in its ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what two body had caused nuclear in in its treaty ?\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what two body had caused nuclear in in its goal of\n",
      "Bleu Score =  0.7400828044922853\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what two body had caused nuclear in in its treaty ?\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what two body economy caused the europe in its ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "what two body was caused nuclear in in its goal of the ?\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what two body was caused nuclear in in its goal of ? ?\n",
      "Bleu Score =  0.7377879464668811\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what two body had caused nuclear in in its ? of led ?\n",
      "Bleu Score =  0.7412437222633026\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what two body had caused nuclear in in its goal of\n",
      "Bleu Score =  0.7400828044922853\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what two body was caused europe in in europe ? of led ?\n",
      "Bleu Score =  0.745626883328766\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in 1853 , victoria gave birth to her eighth child , leopold , with the aid of the new anaesthetic , chloroform . victoria was so impressed by the relief it gave from the pain of childbirth that she used it again in 1857 at the birth of her ninth and final child , beatrice , despite opposition from members of the clergy , who considered it against biblical teaching , and members of the medical profession , who thought it dangerous . victoria may have suffered from post-natal depression after many of her pregnancies . letters from albert to victoria intermittently complain of her loss of self-control . for example , about a month after leopold 's birth albert complained in a letter to victoria about her `` continuance of hysterics '' over a `` miserable trifle '' .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "who was victoria 's eighth child ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "leopold \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who was victoria 's child child ?\n",
      "Bleu Score =  0.8210967436686386\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who was victoria 's child child ?\n",
      "Bleu Score =  0.8210967436686386\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who was victoria 's of child ?\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who was victoria 's of child 's\n",
      "Bleu Score =  0.8197691778984174\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who was victoria 's child child 's\n",
      "Bleu Score =  0.8010548969451144\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who was victoria 's of child 's birth child ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who was victoria 's of child ? birth child ?\n",
      "Bleu Score =  0.7641166194509462\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what was victoria 's of child 's eighth child ?\n",
      "Bleu Score =  0.7755106492019573\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who was victoria 's child child 's birth child ?\n",
      "Bleu Score =  0.7476743906106103\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who was victoria 's child child ? birth child ?\n",
      "Bleu Score =  0.7516200388933441\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "stems mainly provide support to the leaves and reproductive structures , but can store water in succulent plants such as cacti , food as in potato tubers , or reproduce vegetatively as in the stolons of strawberry plants or in the process of layering . leaves gather sunlight and carry out photosynthesis . large , flat , flexible , green leaves are called foliage leaves . gymnosperms , such as conifers , cycads , ginkgo , and gnetophytes are seed-producing plants with open seeds . angiosperms are seed-producing plants that produce flowers and have enclosed seeds . woody plants , such as azaleas and oaks , undergo a secondary growth phase resulting in two additional types of tissues : wood ( secondary xylem ) and bark ( secondary phloem and cork ) . all gymnosperms and many angiosperms are woody plants . some plants reproduce sexually , some asexually , and some via both means .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what are angiosperms ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "plants that produce flowers and have enclosed seeds \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what produces link plants study produce ?\n",
      "Bleu Score =  0.7503949002834928\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what are link plants temperatures produce ?\n",
      "Bleu Score =  0.7553789791604315\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what produces link plants ? produce ?\n",
      "Bleu Score =  0.7699019277569183\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what are up failure temperatures produce ?\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what are up link temperatures produce ?\n",
      "Bleu Score =  0.7740443718000138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what are link plants study produce ?\n",
      "Bleu Score =  0.7751936613371729\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "how are plants plants study ? ?\n",
      "Bleu Score =  0.7887781797427305\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what are link plants study about ?\n",
      "Bleu Score =  0.7863503941633413\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what are up failure temperatures produce when\n",
      "Bleu Score =  0.7331329005620809\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what are up failure temperatures produce when\n",
      "Bleu Score =  0.7331329005620809\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "traditionally , section 1983 was of limited use for a state prisoner under sentence of death because the supreme court has held that habeas corpus , not section 1983 , is the only vehicle by which a state prisoner can challenge his judgment of death . in the 2006 hill v. mcdonough case , however , the united states supreme court approved the use of section 1983 as a vehicle for challenging a state 's method of execution as cruel and unusual punishment in violation of the eighth amendment . the theory is that a prisoner bringing such a challenge is not attacking directly his judgment of death , but rather the means by which that the judgment will be carried out . therefore , the supreme court held in the hill case that a prisoner can use section 1983 rather than habeas corpus to bring the lawsuit . yet , as clarence hill 's own case shows , lower federal courts have often refused to hear suits challenging methods of execution on the ground that the prisoner brought the claim too late and only for the purposes of delay . further , the court 's decision in baze v. rees , upholding a lethal injection method used by many states , has drastically narrowed the opportunity for relief through section 1983 .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "in what year was hill v. mcdonough decided ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "2006 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "in what year was the national v. v. case enacted ?\n",
      "Bleu Score =  0.7745966692414834\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "in what year was the national national v. case enacted ?\n",
      "Bleu Score =  0.7529586373193689\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "in what year was the national v. v. case enacted as\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "in what year was the national v. v. case enacted as\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "in what year was the national v. v. case made ?\n",
      "Bleu Score =  0.7973774246489186\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "in what year was the v. v. case enacted ?\n",
      "Bleu Score =  0.7903765226488096\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "in what year was the national v. v. case made ?\n",
      "Bleu Score =  0.7973774246489186\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "in what year was the national national v. case enacted as\n",
      "Bleu Score =  0.7389984311706962\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "in what year was the national v. v. case enacted as a ? for ?\n",
      "Bleu Score =  0.7370308516304532\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "in what year was the national v. v. case enacted as a\n",
      "Bleu Score =  0.7525636942843138\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "adult contemporary tends to have lush , soothing and highly polished qualities where emphasis on melody and harmonies is accentuated . it is usually melodic enough to get a listener 's attention , and is <UNK> and pleasurable enough to work well as background music . like most of pop music , its songs tend to be written in a basic format employing a <UNK> structure .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what is the typical structure of an adult contemporary song ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "<UNK> structure \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what is the most type of adult contemporary to\n",
      "Bleu Score =  0.8016761109807073\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what is the most type of adult contemporary ?\n",
      "Bleu Score =  0.816496580927726\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what is the most type of adult adult structure ?\n",
      "Bleu Score =  0.7931915718197564\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what is the most type of adult contemporary ? ?\n",
      "Bleu Score =  0.8076682939508287\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what is the most type of adult contemporary to ? used\n",
      "Bleu Score =  0.7837698111269349\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what is the most type of adult contemporary to\n",
      "Bleu Score =  0.8016761109807073\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what is the most type of adult contemporary in ? used\n",
      "Bleu Score =  0.7837698111269349\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what is the first type of adult contemporary in adult used\n",
      "Bleu Score =  0.7565391407404769\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what is the most type of adult contemporary ? ?\n",
      "Bleu Score =  0.8076682939508287\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what is the most type of adult contemporary ?\n",
      "Bleu Score =  0.816496580927726\n",
      "*****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the sumerians were one of the first known beer drinking societies . cereals were plentiful and were the key ingredient in their early brew . they brewed multiple kinds of beer consisting of wheat , barley , and mixed grain beers . beer brewing was very important to the sumerians . it was referenced in the epic of gilgamesh when enkidu was introduced to the food and beer of gilgamesh 's people : `` drink the beer , as is the custom of the land ... he drank the beer-seven jugs ! and became expansive and sang with joy ! ''\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what did enkidu become and do after consuming seven jugs of beer ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "expansive and sang with joy \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what compared were beer properties of the brew ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what compared later were properties in the brew ?\n",
      "Bleu Score =  0.7559289460184544\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what compared were were properties in the brew ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what compared later were beer in the brew ?\n",
      "Bleu Score =  0.7685209321928833\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what compared later were beer during the brew ?\n",
      "Bleu Score =  0.7755106492019573\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what compared later were properties that the brew ?\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what compared were were beer in the brew ?\n",
      "Bleu Score =  0.7730551756939454\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what compared later were properties for the brew ?\n",
      "Bleu Score =  0.7521206186172787\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what compared were beer properties of the brew ? ?\n",
      "Bleu Score =  0.7521206186172787\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what compared later were properties in the sumerians brew ?\n",
      "Bleu Score =  0.7326545101601926\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the mahayana sutras often claim to articulate the buddha 's deeper , more advanced doctrines , reserved for those who follow the bodhisattva path . that path is explained as being built upon the motivation to liberate all living beings from unhappiness . hence the name mahāyāna ( <UNK> , the great vehicle ) .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what does mahayana mean ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the great vehicle \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what relative the `` <UNK> also mean ?\n",
      "Bleu Score =  0.733503637924837\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what relative the `` name <UNK> mean ?\n",
      "Bleu Score =  0.697613262053043\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what relative are `` name <UNK> in\n",
      "Bleu Score =  0.6964705665515708\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what relative are `` name <UNK> in\n",
      "Bleu Score =  0.6964705665515708\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what relative are `` name <UNK> in the great known as\n",
      "Bleu Score =  0.6590692245607205\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what relative the `` name <UNK> mean ?\n",
      "Bleu Score =  0.697613262053043\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what relative are `` name <UNK> in\n",
      "Bleu Score =  0.6964705665515708\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what relative are the name <UNK> in the great of ?\n",
      "Bleu Score =  0.668740304976422\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what relative are `` name <UNK> in\n",
      "Bleu Score =  0.6964705665515708\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what relative is `` name <UNK> in the great known as\n",
      "Bleu Score =  0.6622152291011697\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the soviet regime first came to power on november 7 , 1917 , immediately after the russian provisional government , which governed the russian republic , was overthrown in the october revolution . the state it governed , which did not have an official name , would be unrecognized by neighboring countries for another five months .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what event led to the assumption of power by the soviet government ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the october revolution \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "when was the soviet regime first into powerful ?\n",
      "Bleu Score =  0.7931915718197564\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "when had the soviet regime first into powerful ?\n",
      "Bleu Score =  0.8034284189446518\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "when was the soviet regime first into power ?\n",
      "Bleu Score =  0.7839874343080119\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "when had the soviet regime first into power ?\n",
      "Bleu Score =  0.7952707287670506\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "when was the soviet regime first to power ?\n",
      "Bleu Score =  0.7929487456557408\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "when had the soviet regime first to power ?\n",
      "Bleu Score =  0.8043610129914494\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "when did the soviet regime first into powerful ?\n",
      "Bleu Score =  0.7931915718197564\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "when had the soviet regime first into powerful powerful\n",
      "Bleu Score =  0.7666510377252865\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "when had the soviet regime first to powerful ?\n",
      "Bleu Score =  0.8120224586769673\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "when was the soviet regime first into powerful ? ?\n",
      "Bleu Score =  0.7851378224852613\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "according to the institute of russian language of the russian academy of sciences , an optional acute accent ( знак ударения ) may , and sometimes should , be used to mark stress . for example , it is used to distinguish between otherwise identical words , especially when context does not make it obvious : <UNK> ( <UNK> ) , <UNK> ( <UNK> ) , <UNK> ( this is <UNK> is <UNK> ) , <UNK> ( <UNK> young man ) , <UNK> ( i shall learn <UNK> recognize it ) , <UNK> ( to be <UNK> have cut ) ; to indicate the proper pronunciation of uncommon words , especially personal and family names ( <UNK> , <UNK> , <UNK> , <UNK> , <UNK> ) , and to show which is the stressed word in a sentence ( <UNK> съел печенье ? /ты <UNK> печенье ? /ты съел <UNK> ? – was it you who ate the cookie ? <UNK> you eat the cookie ? <UNK> it the cookie that you ate ? ) . stress marks are mandatory in lexical dictionaries and books for children or russian learners .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what can optional acute accents indicate ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "stress \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what can the russian language use be used to mark ?\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what can the russian language use be used to mark ? ?\n",
      "Bleu Score =  0.7293799946522604\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what can the russian language use be used instead mark ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what can the russian study use to be to mark ? ?\n",
      "Bleu Score =  0.7348889200874658\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what can the russian study use to be to mark ?\n",
      "Bleu Score =  0.7427498127683173\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what can the russian study use to be to mark ?\n",
      "Bleu Score =  0.7427498127683173\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what can the russian language use be used to mark\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what can the russian language use be used to mark\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what does the russian study use the be to mark ?\n",
      "Bleu Score =  0.7213989879855205\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what can the russian study use to be once mark ? ?\n",
      "Bleu Score =  0.727427152512826\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the women 's division of professional wrestling has maintained a recognized world champion since 1937 , when mildred burke won the original world women 's title . she then formed the world women 's wrestling association in the early 1950s and recognized herself as the first champion , although the championship would be vacated upon her retirement in 1956. the nwa , however , ceased to acknowledge burke as their women 's world champion in 1954 , and instead acknowledged june byers as champion after a controversial finish to a high-profile match between burke and byers that year . upon byers ' retirement in 1964 , the fabulous <UNK> , who won a junior heavyweight version of the nwa world women 's championship ( the predecessor to the wwe 's women 's championship ) in a tournament back in 1958 , was recognized by most nwa promoters as champion by default .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "who won the women 's title in 1937 ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "mildred burke \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who founded the world 's world 's in\n",
      "Bleu Score =  0.7434855737622396\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who founded the british world 's favorite ?\n",
      "Bleu Score =  0.726822222964718\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who founded the british world 's favorite ?\n",
      "Bleu Score =  0.726822222964718\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "which magazine won the world 's favorite 's ?\n",
      "Bleu Score =  0.7331329005620809\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "which magazine won the world world 's 's\n",
      "Bleu Score =  0.7400828044922853\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "which magazine won the world world 's 's ?\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "which magazine won the world 's favorite 's\n",
      "Bleu Score =  0.726822222964718\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who was nominated for world 's favorite 's ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score =  0.7372633901833245\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who was nominated for world world 's 's ?\n",
      "Bleu Score =  0.7503949002834928\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who founded the world 's world 's in ? ? ?\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "typically , the warmest day of the year ( 1971–2000 ) will achieve a temperature of 26.6 °c ( 80 °f ) , although in june 1976 the temperature reached 31.6 °c ( 89 °f ) , the site record . on average , 4.25 days of the year will report a maximum temperature of 25.1 °c ( 77 °f ) or above . during the winter half of the year , the coldest night will typically fall to −4.1 °c ( 25 °f ) although in january 1979 the temperature fell to −8.8 °c ( 16 °f ) . typically , 18.6 nights of the year will register an air frost .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "in degrees fahrenheit , what was the highest temperature achieved in plymouth between 1971 and 2000 ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "89 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "in average temperature temperature year are plymouth is plymouth temperature in degrees ?\n",
      "Bleu Score =  0.67973698143584\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "in average temperature temperature year how plymouth is plymouth temperature in degrees ?\n",
      "Bleu Score =  0.6885095955322462\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "in average temperature temperature year are plymouth temperature in temperature in degrees ?\n",
      "Bleu Score =  0.6741265679182159\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "in average temperature temperature year how plymouth is plymouth temperature in degrees ?\n",
      "Bleu Score =  0.6885095955322462\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "in average temperature temperature year are plymouth temperature in temperature in degrees ?\n",
      "Bleu Score =  0.6741265679182159\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "in average temperature temperature year are plymouth in plymouth temperature in degrees ?\n",
      "Bleu Score =  0.67973698143584\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "in average temperature temperature year are plymouth on plymouth temperature in degrees ?\n",
      "Bleu Score =  0.67973698143584\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "in average temperature temperature year are plymouth temperature in temperature in degrees ? ?\n",
      "Bleu Score =  0.6705118179915145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "in average temperature temperature year are plymouth in plymouth temperature in degrees ?\n",
      "Bleu Score =  0.67973698143584\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "in average temperature temperature year are plymouth in plymouth temperature in degrees ? ?\n",
      "Bleu Score =  0.6759709806875497\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "on 24 august , pravda and <UNK> carried news of the <UNK> portions of the pact , complete with the now infamous front-page picture of molotov signing the treaty , with a smiling stalin looking on . the news was met with utter shock and surprise by government leaders and media worldwide , most of whom were aware only of the <UNK> negotiations that had taken place for months . the molotov–ribbentrop pact was received with shock by nazi germany 's allies , notably japan , by the comintern and foreign communist parties , and by jewish communities all around the world . so , that day , german diplomat hans von <UNK> , whose grandmother was jewish , informed guido <UNK> , an italian diplomat , and american chargé d'affaires charles bohlen on the secret protocol regarding vital interests in the countries ' allotted `` spheres of influence '' , without revealing the annexation rights for `` territorial and political rearrangement '' .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "which ally of germany was most surprised by the signing of the agreement ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "japan \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who is a known the the the preventing ?\n",
      "Bleu Score =  0.7740443718000138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who is a known as the the investigation of\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who is a known by the the preventing of\n",
      "Bleu Score =  0.8003203203844999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who is a known the the the preventing of\n",
      "Bleu Score =  0.7691605673134586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who is a known as the the investigation that\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who is a known as the the preventing of\n",
      "Bleu Score =  0.7740443718000138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who is a known the the the preventing ''\n",
      "Bleu Score =  0.7550415303475492\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who is a known by the the time of\n",
      "Bleu Score =  0.8070557274927981\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who is a known as the the of of\n",
      "Bleu Score =  0.7718052844994459\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who is a known as the the time of\n",
      "Bleu Score =  0.7765453555044466\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the period between the foundation of the han dynasty and wang mang 's reign is known as the western han dynasty ( simplified chinese : 西汉 ; traditional chinese : 西漢 ; pinyin : xī hàn ) or former han dynasty ( simplified chinese : 前汉 ; traditional chinese : 前漢 ; pinyin : qiánhàn ) ( 206 bc – 9 ad ) . during this period the capital was at chang'an ( modern xi'an ) . from the reign of guangwu the capital was moved eastward to luoyang . the era from his reign until the fall of han is known as the eastern han dynasty ( simplified chinese : 东汉 ; traditional chinese : 東漢 ; pinyin : dōng hàn ) or the later han dynasty ( simplified chinese : 后汉 ; traditional chinese : 後漢 ; pinyin : hòu hàn ) ( 25–220 ad ) .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "where was the capital located during the western han dynasty ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "chang'an \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "where was the capital at ?\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "where was the capital at\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "where was the capital at\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "where did the capital at ?\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "where was the capital at ? ? ?\n",
      "Bleu Score =  0.8113449257895087\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "where was the capital at magadha\n",
      "Bleu Score =  0.8132882808488929\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "where was the capital at magadha ?\n",
      "Bleu Score =  0.8149915117073744\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "where is the capital at ?\n",
      "Bleu Score =  0.8491821094987799\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "where was the capital during ?\n",
      "Bleu Score =  0.8676247188209203\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "where was the capital at in\n",
      "Bleu Score =  0.8329997998131278\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in the 1960s , downtown houston consisted of a collection of mid-rise office structures . downtown was on the threshold of an energy industry–led boom in 1970. a succession of skyscrapers were built throughout the 1970s—many by real estate developer gerald d. hines—culminating with houston 's tallest skyscraper , the 75-floor , 1,002-foot ( 305 m ) -tall jpmorgan chase tower ( formerly the texas commerce tower ) , completed in 1982. it is the tallest structure in texas , 15th tallest building in the united states , and the 85th tallest skyscraper in the world , based on highest architectural feature . in 1983 , the 71-floor , 992-foot ( 302 m ) -tall wells fargo plaza ( formerly allied bank plaza ) was completed , becoming the second-tallest building in houston and texas . based on highest architectural feature , it is the 17th tallest in the united states and the 95th tallest in the world . in 2007 , downtown houston had over 43 million square feet ( 4,000,000 m² ) of office space .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "when were skyscrapers first built in houston ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "throughout the 1970s—many \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "where was houston 's tallest oil located in the us states\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "where was houston 's tallest oil located in the states states\n",
      "Bleu Score =  0.6921489273129074\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "houston was houston houston tallest construction houston houston in what ? ?\n",
      "Bleu Score =  0.6665295629747561\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "houston was houston houston tallest construction houston houston , what ? ?\n",
      "Bleu Score =  0.668740304976422\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "where was houston 's tallest oil located in the us states ?\n",
      "Bleu Score =  0.710084138739636\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "where was downtown houston tallest construction primarily the the of tall ?\n",
      "Bleu Score =  0.6999271023161167\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "where was houston 's tallest oil located in the us states\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "where was downtown houston tallest construction primarily the the of tall ?\n",
      "Bleu Score =  0.6999271023161167\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "where was houston 's tallest oil primarily compared to the oil ? ?\n",
      "Bleu Score =  0.7124038313502759\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "where was houston 's tallest oil located in the states states\n",
      "Bleu Score =  0.6921489273129074\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "genetic studies on ashkenazim have been conducted to determine how much of their ancestry comes from the levant , and how much derives from european populations . these <UNK> both their paternal and maternal <UNK> to a significant prevalence of ancient <UNK> origins . but they have arrived at diverging conclusions regarding both the degree and the sources of their european ancestry . these diverging conclusions focus particularly on the extent of the european genetic origin observed in ashkenazi maternal lineages .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "genetic studies on the ashkenazim have tried to determine how much of their ancestry is derived from european populations and from where ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the levant \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "since studies on on origin on on been a significant came from what what ?\n",
      "Bleu Score =  0.7046726425521433\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "since studies on on origin on on been a significant came from what\n",
      "Bleu Score =  0.7124038313502759\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "since studies on on origin on on been a significant came from what\n",
      "Bleu Score =  0.7124038313502759\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "since studies on on origin on on been a significant came from what ? ?\n",
      "Bleu Score =  0.7121043131712586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "since studies on on origin on on been been significant came from what what ?\n",
      "Bleu Score =  0.697613262053043\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "since studies on on origin on on had been significant came from what what ?\n",
      "Bleu Score =  0.6999271023161167\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "since studies on on origin on on been a significant came from what\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score =  0.7124038313502759\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "since studies on on origin on on species been significant significant from what what\n",
      "Bleu Score =  0.6803749333171202\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "since studies on on origin on on species been significant significant from what ? ?\n",
      "Bleu Score =  0.6917017543042558\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "since studies on on origin on on species been significant significant what what ?\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "sony officially unveiled playstation 3 ( then marketed as playstation 3 ) to the public on may 16 , 2005 , at e3 2005 , along with a <UNK> ' shaped prototype design of the sixaxis controller . a functional version of the system was not present there , nor at the tokyo game show in september 2005 , although demonstrations ( such as metal gear solid 4 : guns of the patriots ) were held at both events on software development kits and comparable personal computer hardware . video footage based on the predicted playstation 3 specifications was also shown ( notably a final fantasy vii tech demo ) .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what event did sony choose for the ps3 unveiling ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "e3 2005 \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "where did sony before the ps3 ps3 ?\n",
      "Bleu Score =  0.8222672338010394\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "where did sony before the ps3 ps3 before\n",
      "Bleu Score =  0.7825422900366437\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "where did sony before the before ps3 ?\n",
      "Bleu Score =  0.8055344092731546\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "where did the before the enter ps3 before ps3\n",
      "Bleu Score =  0.7468422531048421\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "where did the before the before ps3 before ps3\n",
      "Bleu Score =  0.7291155827927387\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "where did sony before the ps3 ps3 before\n",
      "Bleu Score =  0.7825422900366437\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "where did sony before the before ps3 ?\n",
      "Bleu Score =  0.8055344092731546\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "where did the before the before ps3 before ps3 ?\n",
      "Bleu Score =  0.7348889200874658\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "where did the before the enter ps3 before ps3 ?\n",
      "Bleu Score =  0.7516200388933441\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "where did sony before the ps3 ps3 ? ps3\n",
      "Bleu Score =  0.8003203203844999\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "detroit 's protracted decline has resulted in severe urban decay and thousands of empty buildings around the city . some parts of detroit are so sparsely populated that the city has difficulty providing municipal services . the city has considered various solutions , such as demolishing abandoned homes and buildings ; removing street lighting from large portions of the city ; and encouraging the small population in certain areas to move to more populated locations . while some have estimated 20,000 stray dogs roam the city , studies have shown the true number to be around <UNK> roughly half of the owners of detroit 's <UNK> properties failed to pay their 2011 tax bills , resulting in about $ 246 million in taxes and fees going <UNK> , nearly half of which was due to detroit ; the rest of the money would have been earmarked for wayne county , detroit public schools , and the library system .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "how much in unpaid taxes did detroit fail to collect in 2011 ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "$ 246 million \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "how much has detroit detroit by detroit by 1975 ?\n",
      "Bleu Score =  0.7559289460184544\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "how much has detroit detroit by detroit in 1975 ?\n",
      "Bleu Score =  0.7674731847914632\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "how tall was detroit 's 1975 subsidy in detroit ?\n",
      "Bleu Score =  0.7559289460184544\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "how much was detroit detroit by detroit by 1975 ?\n",
      "Bleu Score =  0.7559289460184544\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "how much has detroit detroit by detroit 's 1975 ?\n",
      "Bleu Score =  0.7559289460184544\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "how much money detroit detroit by detroit in 1975 ?\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "how much detroit detroit detroit by detroit in 1975 ?\n",
      "Bleu Score =  0.7293799946522604\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "how tall was detroit 's 1975 subsidy in 1975 ?\n",
      "Bleu Score =  0.7679634266158699\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "how much detroit detroit detroit by detroit ? 1975 ?\n",
      "Bleu Score =  0.7203294535577252\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "how much detroit detroit detroit by detroit by 1975 ?\n",
      "Bleu Score =  0.7169073641343396\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in his dissent to the majority report of the financial crisis inquiry commission , american enterprise institute fellow peter j. wallison stated his belief that the roots of the financial crisis can be traced directly and primarily to affordable housing policies initiated by hud in the 1990s and to massive risky loan purchases by government-sponsored entities fannie mae and freddie mac . later , based upon information in the sec 's december 2011 securities fraud case against 6 ex-executives of fannie and freddie , peter wallison and edward pinto estimated that , in 2008 , fannie and freddie held 13 million substandard loans totaling over $ 2 trillion .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "peter j. wallison believes that the one of the roots of the financial crisis can be traced to affordable housing policies by which agency in the 1990s ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "hud \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who provided that french fear to substandard of issue in by fannie and\n",
      "Bleu Score =  0.7217950347929304\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who provided that french fear to substandard of issue in by fannie and\n",
      "Bleu Score =  0.7217950347929304\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who provided that french fear to substandard of issue in fannie million ?\n",
      "Bleu Score =  0.7234804230870479\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who provided that french fear to substandard of issue in fannie and ?\n",
      "Bleu Score =  0.7243961401283154\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who provided that french fear to substandard of issue in fannie fannie and\n",
      "Bleu Score =  0.7022798316312892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who provided that french fear to substandard of issue in fannie and ?\n",
      "Bleu Score =  0.7243961401283154\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who provided that french fear to substandard of issue in fannie million ? ?\n",
      "Bleu Score =  0.7186082239261684\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who provided that french fear to substandard of issue in fannie fannie and ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who provided that french fear to substandard of issue in fannie fannie and and\n",
      "Bleu Score =  0.6930977286178778\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who provided that french fear to substandard of issue in by fannie and ? ?\n",
      "Bleu Score =  0.721023747812814\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "geology existed as a cloud of isolated , disconnected ideas about rocks , minerals , and landforms long before it became a coherent science . theophrastus ' work on rocks , <UNK> <UNK> , remained authoritative for millennia : its interpretation of fossils was not overturned until after the scientific revolution . chinese polymath shen kua ( 1031–1095 ) first formulated hypotheses for the process of land formation . based on his observation of fossils in a geological stratum in a mountain hundreds of miles from the ocean , he deduced that the land was formed by erosion of the mountains and by deposition of silt .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what science did shen kua observe ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "land formation \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "why did neighborhoods suffer on the small of on what ?\n",
      "Bleu Score =  0.7259795291154771\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "why did efforts suffer on the land for on what ?\n",
      "Bleu Score =  0.7348889200874658\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "why did efforts suffer on the land of on what ?\n",
      "Bleu Score =  0.7387670965262431\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "why did neighborhoods suffer on the land of on what ?\n",
      "Bleu Score =  0.7293799946522604\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "why did efforts suffer on the small of on what ?\n",
      "Bleu Score =  0.7348889200874658\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "why did neighborhoods suffer on the land for on what ?\n",
      "Bleu Score =  0.7259795291154771\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "why did efforts suffer on the land for in what ?\n",
      "Bleu Score =  0.7348889200874658\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "why did efforts suffer on the land for on what\n",
      "Bleu Score =  0.7291155827927387\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "why did efforts suffer on the land of on what\n",
      "Bleu Score =  0.7331329005620809\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "why did neighborhoods suffer on the land of on what\n",
      "Bleu Score =  0.7238348098810832\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the neighbourhood of thamel is kathmandu 's primary `` traveller 's ghetto '' , packed with guest houses , restaurants , shops , and bookstores , catering to tourists . another neighbourhood of growing popularity is jhamel , a name for <UNK> coined to rhyme with thamel . <UNK> tol , also known as freak street , is kathmandu 's original traveler 's <UNK> , made popular by the <UNK> of the 1960s and 1970s ; it remains a popular alternative to thamel . <UNK> is a bazaar and ceremonial square on the old trade route to tibet , and provides a fine example of a traditional neighbourhood .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what neighborhood is also known as jhamel ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "<UNK> \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what type of street is apollo 's known as to his means in ?\n",
      "Bleu Score =  0.710084138739636\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what type of street is apollo 's known as to his means in\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what type of street is apollo 's known as to his means in\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what type of street is apollo 's for as to his means in ?\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what type of street is apollo 's own as to his means in ?\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what type of street is apollo 's known for to his means in ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what type of street is apollo 's known as to his means in\n",
      "Bleu Score =  0.7039848207052138\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what type of street is apollo 's for as to his means in ? ?\n",
      "Bleu Score =  0.6979414735115365\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what type of street is apollo 's known for to his means in ? ?\n",
      "Bleu Score =  0.7013339980622391\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what type of street is apollo 's known as to his means in in\n",
      "Bleu Score =  0.6950150297221263\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "beyoncé and her mother introduced house of deréon , a contemporary women 's fashion line , in 2005. the concept is inspired by three generations of women in their family , the name paying tribute to beyoncé 's grandmother , agnèz deréon , a respected seamstress . according to tina , the overall style of the line best reflects her and beyoncé 's taste and style . beyoncé and her mother founded their family 's company beyond productions , which provides the licensing and brand management for house of deréon , and its junior collection , deréon . house of deréon pieces were exhibited in destiny 's child 's shows and tours , during their destiny fulfilled era . the collection features sportswear , denim offerings with fur , outerwear and accessories that include handbags and footwear , and are available at department and specialty stores across the us and canada .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "who partnered with beyonce to start the clothing line , <UNK> ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "her mother \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who shares in the introduction of deréon fashion fashion line fashion\n",
      "Bleu Score =  0.6711502189982886\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who shares in the introduction of deréon fashion fashion line fashion\n",
      "Bleu Score =  0.6711502189982886\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who shares in the introduction of deréon fashion in fashion fashion\n",
      "Bleu Score =  0.6636928475745412\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who shares in the introduction of deréon fashion in fashion fashion\n",
      "Bleu Score =  0.6636928475745412\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who shares in the introduction of deréon fashion in fashion fashion\n",
      "Bleu Score =  0.6636928475745412\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who shares in the introduction of deréon fashion fashion 's fashion\n",
      "Bleu Score =  0.6636928475745412\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who shares in the introduction of deréon fashion in fashion fashion ?\n",
      "Bleu Score =  0.6711502189982886\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who shares in the introduction of deréon fashion fashion line ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score =  0.6985342056580097\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who shares in the introduction of deréon fashion fashion 's fashion\n",
      "Bleu Score =  0.6636928475745412\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who shares in the introduction of deréon fashion in fashion fashion ? ?\n",
      "Bleu Score =  0.6663730455134614\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in a tumbling pass , dismount or vault , landing is the final phase , following take off and flight this is a critical skill in terms of execution in competition scores , general performance , and injury occurrence . without the necessary magnitude of energy dissipation during impact , the risk of sustaining injuries during somersaulting increases . these injuries commonly occur at the lower extremities such as : <UNK> lesions , ligament tears , and bone <UNK> . to avoid such injuries , and to receive a high performance score , proper technique must be used by the gymnast . `` the subsequent ground contact or impact landing phase must be achieved using a safe , aesthetic and <UNK> double foot landing . '' a successful landing in gymnastics is classified as soft , meaning the knee and hip joints are at greater than 63 degrees of <UNK> .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what is a critical skill in terms of execution in scores ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "landing \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "where is the final phase of\n",
      "Bleu Score =  0.8329997998131278\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "where is the final phase of\n",
      "Bleu Score =  0.8329997998131278\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "where is the final phase ?\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "where is the final phase ?\n",
      "Bleu Score =  0.8408964152537145\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "where is the final phase found ?\n",
      "Bleu Score =  0.8274377299117183\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "where is the final phase found ?\n",
      "Bleu Score =  0.8274377299117183\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "where is the final phase ? gave operations ?\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "where is the final phase found gave operations ?\n",
      "Bleu Score =  0.7476743906106103\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "where is the final phase of all operations ?\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "where is the final phase in gave operations and\n",
      "Bleu Score =  0.725205974975922\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "on 11 july , nasser replaced amer with mohamed fawzi as general commander , over the protestations of amer 's loyalists in the military , 600 of whom marched on army headquarters and demanded amer 's reinstatement . after nasser sacked thirty of the loyalists in response , amer and his allies devised a plan to topple him on 27 august . nasser was tipped off about their activities and , after several invitations , he convinced amer to meet him at his home on 24 august . nasser confronted amer about the coup plot , which he denied before being arrested by mohieddin . amer committed suicide on 14 september . despite his <UNK> relationship with amer , nasser spoke of losing `` the person closest to [ him ] '' . thereafter , nasser began a process of depoliticizing the armed forces , arresting dozens of leading military and intelligence figures loyal to amer .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what loyalists did nasser target ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "figures loyal to amer \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what did nasser want nasser want to nasser a a him ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what did nasser want to want to nasser a him a him him\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what did nasser want nasser want to nasser a a him ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what did nasser want to want to nasser a him a him him\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what did nasser want nasser want to nasser a a him ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what did nasser want to want about nasser a a him him him him\n",
      "Bleu Score =  0.6659825542555479\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what did nasser want to want to nasser a a him him him him him\n",
      "Bleu Score =  0.6632807437760121\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what did nasser want to want to nasser a a him him him him\n",
      "Bleu Score =  0.6744322250214191\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what did nasser want to want about nasser a a him him him him\n",
      "Bleu Score =  0.6659825542555479\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what did nasser want to want to nasser a him a him him\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "in the united states , two of the wealthiest nonprofit organizations are the bill and melinda gates foundation , which has an endowment of us $ 38 billion , and the howard hughes medical institute originally funded by hughes aircraft prior to divestiture , which has an endowment of approximately $ 14.8 billion . outside the united states , another large npo is the british wellcome trust , which is a `` charity '' by british usage . see : list of wealthiest foundations . note that this assessment excludes universities , at least a few of which have assets in the tens of billions of dollars . for example ; list of u.s. colleges and universities by endowment .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what npo was <UNK> funded by hughes aircraft ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "howard hughes medical institute \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who is the the chartered of organizations as a as a ?\n",
      "Bleu Score =  0.7412437222633026\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who is the the chartered of organizations to to a a\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who is the the chartered of organizations to a a a ?\n",
      "Bleu Score =  0.7447819789879647\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who is the the chartered of a to a a a ?\n",
      "Bleu Score =  0.7691605673134586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who is the the chartered of a to a a a ?\n",
      "Bleu Score =  0.7691605673134586\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who is the the chartered of organizations to a as a ?\n",
      "Bleu Score =  0.7412437222633026\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who is the the chartered of organizations to to a a\n",
      "Bleu Score =  0.7364279629037999\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who is the the chartered of organizations as a a a ?\n",
      "Bleu Score =  0.7447819789879647\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who is the the chartered of organizations to a a a ? ?\n",
      "Bleu Score =  0.7377879464668811\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who is the the chartered of a to a a a ? ?\n",
      "Bleu Score =  0.7598356856515925\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "akbar 's son , jahangir more or less followed father 's policy . the mughal dynasty ruled most of the indian subcontinent by 1600. the reign of shah jahan was the golden age of mughal architecture . he erected several large monuments , the most famous of which is the taj mahal at agra , as well as the moti masjid , agra , the red fort , the jama masjid , delhi , and the lahore fort . the mughal empire reached the zenith of its territorial expanse during the reign of aurangzeb and also started its terminal decline in his reign due to maratha military resurgence under shivaji . historian sir . j.n . sarkar wrote , `` all seemed to have been gained by aurangzeb now , but in reality all was lost . '' the same was echoed by vincent smith : `` the deccan proved to be the <UNK> not only of aurangzeb 's body but also of his empire '' .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what actions caused the decline of the mughal empire ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "maratha military resurgence \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who was the main request to military loss in\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who was the main request to military loss in\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who was the main decline to military loss ?\n",
      "Bleu Score =  0.7810213065790322\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who was the main decline to military loss in\n",
      "Bleu Score =  0.7641166194509462\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who was the main city to military loss ?\n",
      "Bleu Score =  0.7825422900366437\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who was the main city to military loss after\n",
      "Bleu Score =  0.7641166194509462\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who was the main request to military loss ?\n",
      "Bleu Score =  0.7685209321928833\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who was the main city to military loss in\n",
      "Bleu Score =  0.7644270467420534\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who was the main city to military loss after the <UNK>\n",
      "Bleu Score =  0.7259795291154771\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who was the main city to military loss after the <UNK> ?\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "min nan texts , all hokkien , can be dated back to the 16th century . one example is the doctrina christiana en letra y lengua china , presumably written after 1587 by the spanish dominicans in the philippines . another is a ming dynasty script of a play called romance of the lychee mirror ( 1566 ) , supposedly the earliest southern min colloquial text . xiamen university has also developed an alphabet based on pinyin , which has been published in a dictionary called the minnan fangyan-putonghua cidian ( 閩南方言普通話詞典 ) and a language teaching book , which is used to teach the language to foreigners and chinese non-speakers . it is known as pumindian .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "when can min nan texts be dated back to ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "the 16th century \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "how far back the buddhist known ?\n",
      "Bleu Score =  0.8210967436686386\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "how far back the buddhist known ? ?\n",
      "Bleu Score =  0.8091067115702212\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "how far is the know known ?\n",
      "Bleu Score =  0.816496580927726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "how far is the know known ?\n",
      "Bleu Score =  0.816496580927726\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "how far back the machine known ?\n",
      "Bleu Score =  0.8132882808488929\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "how far back the know known ?\n",
      "Bleu Score =  0.8020396005825877\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "how far back the known for ?\n",
      "Bleu Score =  0.8091067115702212\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "how far back the buddhist known date ?\n",
      "Bleu Score =  0.7926416986492341\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "how far back the buddhist known back\n",
      "Bleu Score =  0.7896895367562644\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "how far back the buddhist known back\n",
      "Bleu Score =  0.7896895367562644\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "new haven lies in the transition between a humid continental climate ( köppen climate classification : dfa ) and humid subtropical climate ( köppen cfa ) , but having more characteristics of the former , as is typical of much of the new york metropolitan area . summers are humid and warm , with temperatures exceeding 90 °f ( 32 °c ) on 7–8 days per year . winters are cold with moderate snowfall interspersed with rainfall and occasionally mixed precipitation . the weather patterns that affect new haven result from a primarily offshore direction , thus reducing the marine influence of long island sound—although , like other marine areas , differences in temperature between areas right along the coastline and areas a mile or two inland can be large at times .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what season is typically characterized as humid and warm in new haven ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "summers \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "new what is is highly type to what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "new what is is highly type of what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "new what is is highly type to what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "new what is is highly type of what type of ? ?\n",
      "Bleu Score =  0.7427498127683173\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "new what is is highly type of what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "new what is is highly type to what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "new what is is highly type of what type of\n",
      "Bleu Score =  0.7458878201607712\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "new what is is highly type to to type of\n",
      "Bleu Score =  0.7550415303475492\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "new what is is highly type of what type of ?\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "new what is is highly type to what type of ?\n",
      "Bleu Score =  0.7510499815709779\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "ahmad ibn <UNK> , an arab traveler during the 10th century , provided one of the earliest written descriptions of the rus ' : `` they are as tall as a date palm , blond and <UNK> , so that they do not need to wear a tunic nor a cloak ; rather the men among them wear garments that only cover half of his body and leaves one of his hands free . '' liutprand of cremona , who was twice an envoy to the byzantine court ( 949 and 968 ) , identifies the `` russi '' with the norse ( `` the russi , whom we call norsemen by another name '' ) but explains the name as a greek term referring to their physical traits ( `` a certain people made up of a part of the norse , whom the greeks call [ ... ] the russi on account of their physical features , we designate as norsemen because of the location of their <UNK> '' ) . leo the deacon , a 10th-century byzantine historian and chronicler , refers to the rus ' as `` scythians '' and notes that they tended to adopt greek rituals and customs .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "which historian refered to the rus as `` scythians '' ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "leo the deacon \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "who believed a bomber white and : refer to the `` `` '' ?\n",
      "Bleu Score =  0.7162326270441588\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "who believed a bomber sutras and refer refer the police `` `` '' ?\n",
      "Bleu Score =  0.7226568811456053\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "who believed a bomber white and : refer to the `` `` '' ?\n",
      "Bleu Score =  0.7162326270441588\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "who believed a bomber white and : refer to the `` `` '' '' ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "who believed a bomber white and : refer the the `` `` '' '' ?\n",
      "Bleu Score =  0.7041908148225626\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "who believed a bomber white and : refer to the `` `` '' ? ? greek\n",
      "Bleu Score =  0.6930977286178778\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "who believed a bomber white and : refer to the `` `` '' '' ?\n",
      "Bleu Score =  0.7071067811865476\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "who believed a bomber white and : refer the the `` `` '' '' and\n",
      "Bleu Score =  0.6865890479690392\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "who believed a bomber sutras and refer refer the police `` `` '' ?\n",
      "Bleu Score =  0.7226568811456053\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "who believed a bomber white and : refer to the `` `` '' ? ? greek ? ? greek\n",
      "Bleu Score =  0.668740304976422\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "a microbrewery , or craft brewery , produces a limited amount of beer . the maximum amount of beer a brewery can produce and still be classed as a microbrewery varies by region and by authority , though is usually around 15,000 barrels ( 1.8 megalitres , 396 thousand imperial gallons or 475 thousand us gallons ) a year . a brewpub is a type of microbrewery that incorporates a pub or other eating establishment . the highest density of breweries in the world , most of them microbreweries , exists in the german region of franconia , especially in the district of upper franconia , which has about 200 breweries . the benedictine weihenstephan brewery in bavaria , germany , can trace its roots to the year 768 , as a document from that year refers to a hop garden in the area paying a tithe to the monastery . the brewery was licensed by the city of freising in 1040 , and therefore is the oldest working brewery in the world .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Question : \n",
      "what would you call a microbrewery that also has a restaurant or a pub ?\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "brewpub \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "what is the most of of a of a to to be a ?\n",
      "Bleu Score =  0.7311104457090247\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "what is the most of of a of a to to a a ?\n",
      "Bleu Score =  0.719701167348513\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "what is the most of of a of a that to be a ?\n",
      "Bleu Score =  0.7226568811456053\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "what is the most of of a of a that to be to ?\n",
      "Bleu Score =  0.7186082239261684\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "what is the most of of all of a that to be a ?\n",
      "Bleu Score =  0.7291155827927387\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  6\n",
      "what is the most of of number of a that to be a ?\n",
      "Bleu Score =  0.7438301789874407\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  7\n",
      "what is the most of of a of a that to be to ?\n",
      "Bleu Score =  0.7186082239261684\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  8\n",
      "what is the most of of all of a that to be a ?\n",
      "Bleu Score =  0.7291155827927387\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  9\n",
      "what is the most of of number of a that to be a ?\n",
      "Bleu Score =  0.7438301789874407\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  10\n",
      "what is the most of of a of a to to be a ? ? ?\n",
      "Bleu Score =  0.7146704964214272\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qgen.inferFromBatchBeam(\n",
    "            batch = batch_input_test, \n",
    "            batchNum = 7, \n",
    "            numExamples = 32, \n",
    "            numQuestions = 10, \n",
    "            shuffle = False,\n",
    "            printGroundTruthQuestion = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenceUtils = InferenceUtils(batch_size=batch_size, qgen=qgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage Length =  17 , Answer Length =  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "several college students find clues that lead them to an ancient tomb deep in the jungle .\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "students \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "several students , continues that make that started make art art field the\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "several students , continues that make that started make art field art in\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "several students , continues that make that started make art art in the\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "several students , continues that make that started make art field art in ?\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "several students , continues that make that started make art art field the\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "inferenceUtils.makeInferenceOnText(\n",
    "    passage = \"Several college students find clues that lead them to an ancient tomb deep in the jungle.\",\n",
    "    answer = 'students',\n",
    "    use_beam = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage Length =  26 , Answer Length =  3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Comprehension : \n",
      "the academy awards , also known as the oscars , are a set of 24 awards for artistic and technical merit in the american film industry\n",
      "*****************************************************************************************************\n",
      "Ground Truth Answer: \n",
      "american film industry \n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  1\n",
      "when does the aspect of a place processing industry place ?\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  2\n",
      "when does the aspect of the place processing industry place ?\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  3\n",
      "when did the aspect of a place processing industry place ?\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  4\n",
      "when does the aspect of the place processing industry place ?\n",
      "*****************************************************************************************************\n",
      "Generated Question Number :  5\n",
      "when does the aspect of a place processing industry place in\n",
      "*****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "inferenceUtils.makeInferenceOnText(\n",
    "    passage = \" The Academy Awards, also known as the Oscars, are a set of 24 awards for artistic and technical merit in the American film industry\",\n",
    "    answer = 'American film industry',\n",
    "    use_beam = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value embedding\n\t [[Node: embedding/read = Identity[T=DT_DOUBLE, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding)]]\n\t [[Node: decode_1/BahdanauAttention/memory_layer/Tensordot/add_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_551_decode_1/BahdanauAttention/memory_layer/Tensordot/add_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'embedding/read', defined at:\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-288-a73301e6aa31>\", line 17, in <module>\n    dropout_probability = [0.4,0.3,0.4])\n  File \"<ipython-input-287-2fec6fab8c04>\", line 24, in __init__\n    self.build_graph()\n  File \"<ipython-input-287-2fec6fab8c04>\", line 43, in build_graph\n    self.add_embedding_layer()\n  File \"<ipython-input-287-2fec6fab8c04>\", line 57, in add_embedding_layer\n    self.embedding = tf.get_variable(\"embedding\", initializer=self.glove_embedding)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 330, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1400, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value embedding\n\t [[Node: embedding/read = Identity[T=DT_DOUBLE, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding)]]\n\t [[Node: decode_1/BahdanauAttention/memory_layer/Tensordot/add_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_551_decode_1/BahdanauAttention/memory_layer/Tensordot/add_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value embedding\n\t [[Node: embedding/read = Identity[T=DT_DOUBLE, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding)]]\n\t [[Node: decode_1/BahdanauAttention/memory_layer/Tensordot/add_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_551_decode_1/BahdanauAttention/memory_layer/Tensordot/add_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-2ed519f55731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnumQuestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mprintGroundTruthQuestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-287-2fec6fab8c04>\u001b[0m in \u001b[0;36minferFromBatchBeam\u001b[0;34m(self, batch, batchNum, numExamples, numQuestions, shuffle, printGroundTruthQuestion)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_encoder_input_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_encoder_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         })\n\u001b[1;32m    372\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumExamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value embedding\n\t [[Node: embedding/read = Identity[T=DT_DOUBLE, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding)]]\n\t [[Node: decode_1/BahdanauAttention/memory_layer/Tensordot/add_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_551_decode_1/BahdanauAttention/memory_layer/Tensordot/add_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'embedding/read', defined at:\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-288-a73301e6aa31>\", line 17, in <module>\n    dropout_probability = [0.4,0.3,0.4])\n  File \"<ipython-input-287-2fec6fab8c04>\", line 24, in __init__\n    self.build_graph()\n  File \"<ipython-input-287-2fec6fab8c04>\", line 43, in build_graph\n    self.add_embedding_layer()\n  File \"<ipython-input-287-2fec6fab8c04>\", line 57, in add_embedding_layer\n    self.embedding = tf.get_variable(\"embedding\", initializer=self.glove_embedding)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 330, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1400, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/data/ra2630/miniconda3/envs/qgen/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value embedding\n\t [[Node: embedding/read = Identity[T=DT_DOUBLE, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding)]]\n\t [[Node: decode_1/BahdanauAttention/memory_layer/Tensordot/add_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_551_decode_1/BahdanauAttention/memory_layer/Tensordot/add_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "qgen.inferFromBatchBeam(\n",
    "            batch = batch_input_test, \n",
    "            batchNum = 5, \n",
    "            numExamples = 2, \n",
    "            numQuestions = 10, \n",
    "            shuffle = True,\n",
    "            printGroundTruthQuestion = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
